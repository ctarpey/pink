{
 "metadata": {
  "name": "",
  "signature": "sha256:cdc56992e57dc9f2ca345f1cee6bb81f924b3f3c76f3b93680a38846bd1d5ed8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#LFMM\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "September 25\n",
      "\n",
      "\n",
      "Looking at the LFMM method for identifying outliers, I went to the website and see that they have a package in R and i used the isntructions to install LEA, the package for LFMM  http://www.bioconductor.org/packages/release/bioc/html/LEA.html\n",
      "\n",
      "and then it asked me if i wanted to update the packages and I said yes, so it went through and updated everything in my library, i think?\n",
      "\n",
      "\n",
      "looking at the LFMM website i found this curious little tidbit: \n",
      " Can I run STRUCTURE analyses from the R command line using LEA?\n",
      "    Answer: Yes. The \"snmf\" function is very similar to STRUCTURE but hundred times faster. The choice of the number of clusters is based on a cross-validation criterion, which may be more reliable than methods used for STRUCTURE. \n",
      "\t\n",
      "I wonder if i should look into that too? \n",
      "\n",
      "\n",
      "I cant really figure out how to run it right, so I also went into the Linux side and downloaded the command line version for linux, which is what they recommend that you use anyway. \n",
      "\n",
      "i put it in a file on the desktop and then compiled it: \n",
      "carolyn@ubuntu:~/Desktop/LFMM_CL_v1.4$ '/home/carolyn/Desktop/LFMM_CL_v1.4/install.command' \n",
      "rm -f obj/*.o obj/*/*.o lib/* \n",
      "\n",
      "\n",
      "and it says it worked, there was a ton of giberish on the screen before that, but it compiled:  \n",
      " SUCCESS: LFMM command-line program was compiled without error. \n",
      "\n",
      " so then the README says: \n",
      " 2. If no error, the executable is in the bin directory. \n",
      "\n",
      "INPUT FILEs FOR LFMM\n",
      " \n",
      "Input files are composed of two files:  a genotype file and a variable file.  The genotype file is a SNP matrix of n\n",
      "lines for n individuals and L columns for L loci.  Each element can be 0, 1 or 2.  A missing element will be notify\n",
      "by the value -9.  Each element of the matrix is separated by a single space.  There should be a single space after\n",
      "the last value of each line.  A line should not contain only missing data (-9).  Below, an example of genotype file\n",
      "for n = 3 individuals and L = 5 loci.\n",
      " \n",
      "1 0 0 0 1\n",
      "1 1 -9 2 0\n",
      "0 0 2 1 0\n",
      "\n",
      "The variable file is a vector composed of n lines and D columns.  Each line is the values of the D variables for\n",
      "the corresponding individual.  Below, an example of variable file for n = 3 individuals and D = 1 covariable.\n",
      "Warning:   If  you  set  several  covariables,  the  program  will  be  launched  for  each  covariable  sequentially  and\n",
      "independently.\n",
      "\n",
      "0.252477\n",
      "0.216618\n",
      "-0.47509\n",
      "\n",
      "HOW TO CHOSE K, the number of latent factors.\n",
      "The number of latent factors is the number of principal components (or latent factors) that should be required for the neutral structure of the data. Several values should be tested.  A too small value of K will do the model too liberal.  A too large value of K will do the model too conservative.  In our paper, we used the number of significative principal components in the Tracy-Widom test of SmartPCA (http://helix.nih.gov/Applications/eigensoft.html) [3].  This heuristic is a bit too conservative.  We also used the Bayesian clustering programs STRUCTURE (http://pritch.bsd.uchicago.edu/software/structure21.html) [5] and TESS (http://membres-timc.imag.fr/Olivier.Francois/tess.html) [1, 2] to find K the number of components which could better describe our simulated data.  We advise you too be really careful in the choice of K and to test several values of K\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I also am still caught up in how to conver the files that I have into the format of the input files that I need. :/ i looked at PGDspider, but Im not sure if they are what I need..... I could maybe get away with some kind of alteration of the genepop file since i need a file that has the genotypes per individual, one individual per line. \n",
      "\n",
      "I might try that really quick, see how it goes. \n",
      "\n",
      "Ok, so I went to the file on the desktop where I was doing all the bayescan bayeScEnv bayesenv2 etc formating and i got the genepop file out of there, named it LFMM_test to mess with it. \n",
      "the thing with a genepop file is that its coded like this: \n",
      "\n",
      "PAMUR10_0001,\t0202\t0303\t0102\t0404\t0202\t0404\t0202\n",
      "\n",
      "and yeah, a 0000 is a -9, that is easy to figure out, but what do I do with the 0202? if there are 3 options, a 0 1 or 2, what does that mean? \n",
      "shoud 0 be the homozygotes and 1 be the heterozygotes first allele \n",
      "\n",
      "\n",
      "ok this is in the LFMM manual, just further down so I hadnt seen it: \n",
      "The  LFMM  command-line  engine  allows  data  in  lfmm  format.   You  can  convert  from  ped,  eigenstratgeno,\n",
      "ancestrymap to lfmm format using perl scripts.  The format is (n is the number of individuals, L the number of loci):\n",
      "\n",
      "So I have to use PGDspider to convert the genepop file that i have into either the .ped or .ancestrymap (this doesnt seem like on that pgdspider can do) or the .eigenstratgeno format (which i think that pgdspider can do but im not positive) \n",
      "\n",
      "\n",
      "using PGDspider to convert the genepop file LFMM_test.txt into a .ped file format. I made the SPID file answering the questions as best I could, I said yes to a .map file (LFMM_test_map) and told it snps for the genepop file and to convert the 0 into a -9 in the code, because it codes 0 as missing data. \n",
      "\n",
      "\n",
      "It didnt actually convert the 0 to -9, maybe it cant do a string of more than one character or maybe it didnt like the negative. \n",
      "\n",
      "But moving on, now I want to use the script that they provided to do the conversion between the ped and the LFMM file. \n",
      "\n",
      "i copied them into the UBUntu shared folder because the LFMM is all installed on the linux. \n",
      "\n",
      "This is what the manual has for the code to get the files to convert: \n",
      "\n",
      "perl ./scripts/ped2lfmm.pl data/LFMM_test_ped.ped LFMM_test.lfmm 16681 383\n",
      "\n",
      "the last two are the number of loci and the number of individuals. This didnt work though. So i changed it to the name of the directory that has the actual executable: \n",
      "\n",
      "perl ./bin/ped2lfmm.pl data/LFMM_test_ped.ped LFMM_test.lfmm 16681 383\n",
      "\n",
      "nope\n",
      "\n",
      "perl ./bin/ped2lfmm.exe ./data/LFMM_test_ped.ped LFMM_test.lfmm 16681 383\n",
      "\n",
      "nope\n",
      "\n",
      "perl ./bin/ped2lfmm ./data/LFMM_test_ped.ped LFMM_test.lfmm 16681 383\n",
      "\n",
      "that got a response, but it doenst make a lot of sense to me, maybe it altered the file and spits it back oout? \n",
      "\n",
      "Unrecognized character \\x7F; marked by <-- HERE after <-- HERE near column 1 at ./bin/ped2lfmm line 1.\n",
      "\n",
      "ignored that and copied a version into the file with the data, made that the directory and then : \n",
      "\n",
      "carolyn@ubuntu:~/Desktop/LFMM_CL_v1.4/data$ ./ped2lfmm LFMM_test_ped.ped LFMM_test.lfmm 16681 383\n",
      "ERROR: commmand line format incorrect.\n",
      "\n",
      "HELP: ./ped2lfmm input_file [output_file]\n",
      "\n",
      "nope\n",
      "\n",
      "carolyn@ubuntu:~/Desktop/LFMM_CL_v1.4/data$ ./ped2lfmm LFMM_test_ped.ped LFMM_test.lfmm\n",
      "\n",
      "Summary of the options:\n",
      "\n",
      "        -input file      LFMM_test_ped.ped\n",
      "        -output file     LFMM_test.lfmm\n",
      "\t\t\n",
      "Error: unable to read file LFMM_test_ped.ped. It seems that line 1 contains 13982 columns instead of 16681 (number of columns of line 1).\n",
      "\n",
      "so i opened that file and copied the first line into a new txt file and did a find replace of the spaces with end of line and there are 33368 lines. there is the name of the individual and the pop and there are like 4 blank 0s at the beginning that have some sort of info but then i think that the rest are the genepop file broken up into halfs for each of the loci, because 16681*2 is 33362, but then the error message says that there are 13982 columns in the input file, so that doesnt really fit. \n",
      "\n",
      "I wonder if there is some limit to the amount of data that it can handle? \n",
      "\n",
      "but i also didnt specify how many loci were in the file, it came up with 16681 all on its own. SO maybe its some other kind of warning. \n",
      "\n",
      "this is what the example file for the .ped looks like: \n",
      "1 \tSAMPLE0 0 0 2 2 1 2 3 3 1 1 2 1\n",
      "2 \tSAMPLE1 0 0 1 2 2 1 1 3 0 4 1 1\n",
      "3 \tSAMPLE2 0 0 2 1 2 2 3 3 1 4 1 2\n",
      "\n",
      "\n",
      "         $$ September 28 2015\n",
      "==================================================================\n",
      "\n",
      "Ok, back to figuring out how to get this LFMM file to be the right format.\n",
      "\n",
      "Part of the problem is that the beginning of the document that has the names of the samples should have tabs. So i have ot figure out how to modify that. I thihnk it would be cool to write a python script that does it because i just tried to do it all by hand and something messed up and i lost all the work, so i definitley will proably be repeating the process so should make it more efficient. And I need to practice writing code. \n",
      "\n",
      "OK, so using some code ryan helped me write to make the code to convert the file. I found an unaltered ped file in the desktop file, so Im using a copy of that so I dont have to redo the PGD spider portion. \n",
      "\n",
      "edit_PGDped_to_LFMMped.py LFMM_ped_pgd.ped LFMM_ped.txt\n",
      "\n",
      "OK, so I worked on it all day long and got some great progress in python, with the occasional help of Ryan. Then I went to him and asked him a basic question about why something wasnt working and he came and looked and was like no. dont do anything that youre doing it isnt the best way. So he installed pandas and told me its a way to work with a txt file in python like it was an excel file, column by column, all at once. he also did it in ipython. he went into the command line and typed ipython notebook and one poped up in the firefox window and was saved in the folder that i had as the working directory for that command line prompt. Then he made a dictionary to replace the pop_1 with the actual names, and the 01 02 problem was solved because the program automatically assumed that they were integers and dropped the 0 at the beginning, and he said that there is some way to get it to drop the columns that i dont want (the ones that have the extra 0) but he didnt know, said to google it. Then he exported it and it looks pretty good. Its a shame to not have the python code done though, because its how I do most of the work and it would be nice to finish it so that the product that i spent the day on doesnt feel like it was wasted. \n",
      "\n",
      "I also went and talked to Erika sutherland, and Mathis from the olden lab. Erika showed me what the basics were in GIS and how i would go about getting the numbers out, and introduced me to Mathis who is their GIS wiz, then I talked to Eica Escajeda who is TAing the GIS class and loves it. she told me to go to the grad student lab and to just use the version they have there and get the numbers out that I need. I think with what they showed me I should be able to get it done really easily. \n",
      "\n",
      "Basically, you use a map, a basic continents map or whatever, something that is already made in the program that you load the layers onto. they are premade layers that come in a format that you cant extract the data anyother way, they have to be opened by GIS. then from there you go to a thing called the catalog and you right click on a layer and here the layers would be the different variables, and you say get attributes table. That will be the numbers. The other way you can do it, which might be easier depending on how complete these data sets are is to click on a point on the map , so make a layer that has my populations and then get attributes for the place, and if all the layers are loaded in it will give me all the details that i need about that one place, so all the data together. \n",
      "\n",
      "OK!!! i got it to work: \n",
      "\n",
      "edit_PGDped_to_LFMMped.py LFMM_ped_pgd.ped LFMM_ped.txt\n",
      "\n",
      "\n",
      "###Python code to edit the PGD ped file to the LFMM ped file\n",
      "###Carolyn Tarpey and Ryan Waples | September 2015\n",
      "\n",
      "#workflow: get a genepop file and convert it to ped with pgd spider and use that as the input file here\n",
      "###takes two arguments: 1) ped input file from PGDspider, 2) output file name for LFMM ped file\n",
      "# ie: edit_PGDped_to_LFMMped.py LFMM_ped_pgd.ped LFMM_ped.txt\n",
      "\n",
      "## Here is an example of what the output format should be: \n",
      "#1 \tSAMPLE0 0 0 2 2 1 2 3 3 1 1 2 1\n",
      "#2 \tSAMPLE1 0 0 1 2 2 1 1 3 0 4 1 1\n",
      "#3 \tSAMPLE2 0 0 2 1 2 2 3 3 1 4 1 2\n",
      "\n",
      "#!/bin/bash\n",
      "import sys\n",
      "import re\n",
      "\n",
      "pat1 = r'pop_1 '\n",
      "pat2 = r'pop_2 '\n",
      "pat3 = r'pop_3 '\n",
      "pat4 = r'pop_4 '\n",
      "pat5 = r'pop_5 '\n",
      "pat6 = r'pop_6 '\n",
      "pat7 = r'pop_7 '\n",
      "pat8 = r'pop_8 '\n",
      "pat9 = r'pop_9 '\n",
      "pat10 = r'pop_10 '\n",
      "pat11 = r'pop_11 '\n",
      "pat12 = r'pop_12 '\n",
      "pat13 = r'pop_13 '\n",
      "pat14 = r'pop_14 '\n",
      "\n",
      "pat1a = r'AMUR10 \\t '\n",
      "pat2a = r'AMUR11 \\t '\n",
      "pat3a = r'HAYLY09 \\t '\n",
      "pat4a = r'HAYLY10 \\t '\n",
      "pat5a = r'KOPE91 \\t '\n",
      "pat6a = r'KOPE96 \\t '\n",
      "pat7a = r'KUSHI06 \\t '\n",
      "pat8a = r'KUSHI07 \\t '\n",
      "pat9a = r'NOME91 \\t '\n",
      "pat10a = r'NOME94 \\t '\n",
      "pat11a = r'SNOH03 \\t '\n",
      "pat12a = r'SNOH96 \\t '\n",
      "pat13a = r'TAUY09 \\t '\n",
      "pat14a = r'TAUY12 \\t '\n",
      "\n",
      "pat01 = r'01'\n",
      "pat02 = r'02'\n",
      "pat03 = r'03'\n",
      "pat04 = r'04'\n",
      "\n",
      "pat01a = r'1'\n",
      "pat02a = r'2'\n",
      "pat03a = r'3'\n",
      "pat04a = r'4'\n",
      "\n",
      "\n",
      "with open(sys.argv[1], 'r') as INFILE:\n",
      "\twith open(sys.argv[2], 'w') as OUTFILE:\n",
      "\t\tfor line in INFILE:\n",
      "\t\t\tsample = line.strip()\n",
      "\t\t\tif pat1 in line:\n",
      "\t\t\t\tsample = re.sub(pat1, pat1a, sample)\n",
      "\t\t\tif pat2 in line:\n",
      "\t\t\t\tsample = re.sub(pat2, pat2a, sample) \n",
      "\t\t\tif pat3 in line:\n",
      "\t\t\t\tsample = re.sub(pat3, pat3a, sample)\n",
      "\t\t\tif pat4 in line:\n",
      "\t\t\t\tsample = re.sub(pat4, pat4a, sample)\n",
      "\t\t\tif pat5 in line:\n",
      "\t\t\t\tsample = re.sub(pat5, pat5a, sample)\n",
      "\t\t\tif pat6 in line:\n",
      "\t\t\t\tsample = re.sub(pat6, pat6a, sample)\n",
      "\t\t\tif pat7 in line:\n",
      "\t\t\t\tsample = re.sub(pat7, pat7a, sample)\n",
      "\t\t\tif pat8 in line:\n",
      "\t\t\t\tsample = re.sub(pat8, pat8a, sample)\n",
      "\t\t\tif pat9 in line:\n",
      "\t\t\t\tsample = re.sub(pat9, pat9a, sample)\n",
      "\t\t\tif pat10 in line:\n",
      "\t\t\t\tsample = re.sub(pat10, pat10a, sample)\n",
      "\t\t\tif pat11 in line:\n",
      "\t\t\t\tsample = re.sub(pat11, pat11a, sample)\n",
      "\t\t\tif pat12 in line:\n",
      "\t\t\t\tsample = re.sub(pat12, pat12a, sample)\n",
      "\t\t\tif pat13 in line:\n",
      "\t\t\t\tsample = re.sub(pat13, pat13a, sample)\n",
      "\t\t\tif pat14 in line:\n",
      "\t\t\t\tsample = re.sub(pat14, pat14a, sample)\n",
      "\t\t\tsample = sample.split(\" \")\n",
      "\t\t\tfrontslice = sample[0:6]\n",
      "\t\t\tcutfrontslice = frontslice[0:4]\n",
      "\t\t\tbackslice = sample[6:]\n",
      "\t\t\tbackslicedit1 = re.sub(pat01, pat01a, \" \".join(backslice))\n",
      "\t\t\tbackslicedit2 = re.sub(pat02, pat02a, backslicedit1)\n",
      "\t\t\tbackslicedit3 = re.sub(pat03, pat03a, backslicedit2)\n",
      "\t\t\tbackslicedit4 = re.sub(pat04, pat04a, backslicedit3)\n",
      "\t\t\tbackslicedit4 = backslicedit4.split(\" \")\n",
      "\t\t\teditedline = cutfrontslice + backslicedit4\n",
      "\t\t\tOUTFILE.write(\" \".join(editedline))\n",
      "\t\t\tOUTFILE.write(\"\\n\")\n",
      "\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tomorrow Ill go and get the environmental variables out of ArcGIS \n",
      "Ill run LFMM\n",
      "and the other environmental BAYES programs that need the other variables. \n",
      "\n",
      "\n",
      "\n",
      "Tyler explained a little bit about the Latent Factor Mixed Model, he said that the latent factors are the hidden factors, or in this case the population structure. SO picking the k value is in effect identifying that population structure and that is the Latent Factor and there are several ways to get K and you should test several K. \n",
      "\n",
      "the environmental variables are the ones that are fixed in this model. Its similar to Bayenv, but Bayenv builds a covariate matrix (or something like that... ) \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "Im going to put that aside and look at LEA the R package that allows you to run LFMM. Ryan says it will also estimate your K for you.\n",
      "\n",
      "I have the LFMM file in the .ped format\n",
      "I have the \"new\" lat and long files that I made for BayeScEnv the other day (moved over to the LFMM file)\n",
      "\n",
      "I still need to edit it to be missing values as 9\n",
      "\n",
      "\n",
      "         $$ October 9  2015\n",
      "==================================================================\n",
      "\n",
      "I couldnt get the file to open, the ipython notebook was not opening in the notebook viewer, so i remembered that ryan had used the command line to open it. \n",
      "\n",
      "i opened a command line window in the folder and typed in iphython notebook and that opened a list of the files in the web browser window. Looking at it, im not sure that I used that file to actually make the conversions, I think i might have just finished writing my own .py script. \n",
      "\n",
      "now what i need to do is change the one pattern so that things that are coded as 0 are instead coded as 9. \n",
      "\n",
      "\n",
      "####### OK i got it to work and replace the 0 with a 9. \n",
      "\n",
      "\n",
      "changed the extention of the file to be lfmm so that the program would recognize it. \n",
      "\n",
      "\n",
      "From the manual: \n",
      "  Using the genotypic matrix, the first step is to evaluate population genetic structure with the program snmf. The snmf function provides outputs similar to those of the computer program STRUCTURE, but snmf is much faster than STRUCTURE. We start with converting the genotypic matrix from the \u201clfmm\u201d to the \u201cgeno\u201d format\n",
      "\n",
      "\n",
      "\t- number of detected individuals:\t383\n",
      "\t- number of detected loci:\t\t33366\n",
      "\t\n",
      "This isnt right. The correct number of individuals, but twice the number of loci. I think that I didnt convert the file right? I dont understand the genepop file? \n",
      "\n",
      "i asked ryan but he doesnt seem to get my question or i didnt frame it right. \n",
      "\n",
      "This is what the manual says:\n",
      "\n",
      "The lfmm format  for  the genotype  matrix consists  of  one  row  for  each  individual.   Each  row  contains the genotypic values for each locus (separated by spaces or tabulations).  These values represent the number of alleles for each SNP. The number of alleles can be the number of reference alleles or the number of derived alleles as long as a same choice is made for an entire column.  Missing genotypes are encoded with the value 9 (-9 is also accepted).  Here is an example of a data set in the lfmm format for 3 diploid individuals genotype at 4 SNPs\n",
      "\n",
      "1 0 0 1\n",
      "1 1 9 2\n",
      "2 0 1 1\n",
      "\n",
      "\n",
      "So the issue that Im having is how to get a ped file for my data from a genepop file that doesnt take a file that has 16,881 snps and code it as 33,666 snps. \n",
      "\n",
      "\n",
      "i talked to Ryan and Garrett and got it to work- if there is a ped file (has the two loci per snps broken up) it can be converted in the program. So I used the script i wrote to recode the pgd ped file so that 01 was 1 and put that into the LFMM program and let it do the conversion to its own format- that way it wouldnt treat the loci as snps. \n",
      "\n",
      "###Python code to edit the PGD ped file to the LFMM ped file\n",
      "###Carolyn Tarpey and Ryan Waples | September 2015\n",
      "\n",
      "#workflow: get a genepop file and convert it to ped with pgd spider and use that as the input file here\n",
      "###takes two arguments: 1) ped input file from PGDspider, 2) output file name for LFMM ped file\n",
      "# ie: edit_PGDped_to_LFMMped.py LFMM_ped_pgd.ped LFMM_ped.txt\n",
      "\n",
      "# ie: edit_PGDped_to_LFMMped.py LFMM_test_ped.ped LFMM_outtest_ped.txt\n",
      "\n",
      "## Here is an example of what the output format should be: \n",
      "#1 \tSAMPLE0 0 0 2 2 1 2 3 3 1 1 2 1\n",
      "#2 \tSAMPLE1 0 0 1 2 2 1 1 3 0 4 1 1\n",
      "#3 \tSAMPLE2 0 0 2 1 2 2 3 3 1 4 1 2\n",
      "\n",
      "#!/bin/bash\n",
      "import sys\n",
      "import re\n",
      "\n",
      "pat1 = r'pop_1 '\n",
      "pat2 = r'pop_2 '\n",
      "pat3 = r'pop_3 '\n",
      "pat4 = r'pop_4 '\n",
      "pat5 = r'pop_5 '\n",
      "pat6 = r'pop_6 '\n",
      "pat7 = r'pop_7 '\n",
      "pat8 = r'pop_8 '\n",
      "pat9 = r'pop_9 '\n",
      "pat10 = r'pop_10 '\n",
      "pat11 = r'pop_11 '\n",
      "pat12 = r'pop_12 '\n",
      "pat13 = r'pop_13 '\n",
      "pat14 = r'pop_14 '\n",
      "\n",
      "pat1a = r'AMUR10 \\t'\n",
      "pat2a = r'AMUR11 \\t'\n",
      "pat3a = r'HAYLY09 \\t'\n",
      "pat4a = r'HAYLY10 \\t'\n",
      "pat5a = r'KOPE91 \\t'\n",
      "pat6a = r'KOPE96 \\t'\n",
      "pat7a = r'KUSHI06 \\t'\n",
      "pat8a = r'KUSHI07 \\t'\n",
      "pat9a = r'NOME91 \\t'\n",
      "pat10a = r'NOME94 \\t'\n",
      "pat11a = r'SNOH03 \\t'\n",
      "pat12a = r'SNOH96 \\t'\n",
      "pat13a = r'TAUY09 \\t'\n",
      "pat14a = r'TAUY12 \\t'\n",
      "\n",
      "pat01 = r'01'\n",
      "pat02 = r'02'\n",
      "pat03 = r'03'\n",
      "pat04 = r'04'\n",
      "\n",
      "\n",
      "pat01a = r'1'\n",
      "pat02a = r'2'\n",
      "pat03a = r'3'\n",
      "pat04a = r'4'\n",
      "\n",
      "\n",
      "with open(sys.argv[1], 'r') as INFILE:\n",
      "\twith open(sys.argv[2], 'w') as OUTFILE:\n",
      "\t\tfor line in INFILE:\n",
      "\t\t\tsample = line.strip()\n",
      "\t\t\tif pat1 in line:\n",
      "\t\t\t\tsample = re.sub(pat1, pat1a, sample)\n",
      "\t\t\tif pat2 in line:\n",
      "\t\t\t\tsample = re.sub(pat2, pat2a, sample) \n",
      "\t\t\tif pat3 in line:\n",
      "\t\t\t\tsample = re.sub(pat3, pat3a, sample)\n",
      "\t\t\tif pat4 in line:\n",
      "\t\t\t\tsample = re.sub(pat4, pat4a, sample)\n",
      "\t\t\tif pat5 in line:\n",
      "\t\t\t\tsample = re.sub(pat5, pat5a, sample)\n",
      "\t\t\tif pat6 in line:\n",
      "\t\t\t\tsample = re.sub(pat6, pat6a, sample)\n",
      "\t\t\tif pat7 in line:\n",
      "\t\t\t\tsample = re.sub(pat7, pat7a, sample)\n",
      "\t\t\tif pat8 in line:\n",
      "\t\t\t\tsample = re.sub(pat8, pat8a, sample)\n",
      "\t\t\tif pat9 in line:\n",
      "\t\t\t\tsample = re.sub(pat9, pat9a, sample)\n",
      "\t\t\tif pat10 in line:\n",
      "\t\t\t\tsample = re.sub(pat10, pat10a, sample)\n",
      "\t\t\tif pat11 in line:\n",
      "\t\t\t\tsample = re.sub(pat11, pat11a, sample)\n",
      "\t\t\tif pat12 in line:\n",
      "\t\t\t\tsample = re.sub(pat12, pat12a, sample)\n",
      "\t\t\tif pat13 in line:\n",
      "\t\t\t\tsample = re.sub(pat13, pat13a, sample)\n",
      "\t\t\tif pat14 in line:\n",
      "\t\t\t\tsample = re.sub(pat14, pat14a, sample)\n",
      "\t\t\tsample = sample.split(\" \")\n",
      "\t\t\tfrontslice = sample[0:6]\n",
      "\t\t\t#cutfrontslice = frontslice[0:4]\n",
      "\t\t\tbackslice = sample[6:]\n",
      "\t\t\tbackslicedit1 = re.sub(pat01, pat01a, \" \".join(backslice))\n",
      "\t\t\tbackslicedit2 = re.sub(pat02, pat02a, backslicedit1)\n",
      "\t\t\tbackslicedit3 = re.sub(pat03, pat03a, backslicedit2)\n",
      "\t\t\tbackslicedit4 = re.sub(pat04, pat04a, backslicedit3)\n",
      "\t\t\tbackslicedit4 = backslicedit4.split(\" \")\n",
      "\t\t\teditedline = frontslice + backslicedit4\n",
      "\t\t\tOUTFILE.write(\" \".join(editedline))\n",
      "\t\t\tOUTFILE.write(\"\\n\")\n",
      "\t\t\t\n",
      "###########################\n",
      "\n",
      "> ped2lfmm(\"G:/Analysis/Pop_analysis/Populations_b3_may/LFMM/ConvertFiles/LFMM_out_ped.ped\",\"LFMM.lfmm\" )\n",
      "\n",
      "\t- number of detected individuals:\t383\n",
      "\t- number of detected loci:\t\t16681\n",
      "\n",
      "[1] \"LFMM.lfmm\"\n",
      "\n",
      "yay!\n",
      "\n",
      "OK, moved on to estimating K using the code in LFMM found on the website\n",
      "\n",
      "I estimated Ks from 1 through 14 and used a repetition of 10, which is what they used in the manual, and said that cross entropy was true, which im not sure what that means. \n",
      "\n",
      "The  manual says: \n",
      "The snmf function also estimates an entropy criterion that evaluates the quality of fit of the statistical model to the data using a cross-validation technique. The entropy criterion can help choosing the number of ancestral populations that best explains the genotypic data. \n",
      "\n",
      "#to get the cross-entropy of each run for K = 4\n",
      "ce_4 <- cross.entropy(project, K= 4)\n",
      "\n",
      "#select the run with the lowest cross-entropy \n",
      "best <- which.min(ce_4)\n",
      "\n",
      "The number of ancestral population is closely linked to the number of principal components that explain variation in the genomic data. Both numbers can help determining the number of latent factors when correcting for confounding effects due to population structure in ecological association tests. \n",
      "\n",
      "\n",
      "#plot cross-entropy criterion of all runs of the project\n",
      "plot(project, lwd= 5, col = \"red\", pch=1)\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "         $$ October 9  2015\n",
      "==================================================================\n",
      "\n",
      "LFMM finished running the cross entropy or whatever and it looks like 4, 5 6 are the best bets for the K value, though trying 4-8 wouldnt be bad. \n",
      "\n",
      "I want to make the environmental files to get LFMM running over the weeked with stand_lat and stand_long\n",
      "\n",
      "The env format for the environmental variable matrix consists of one row for each individual.  Each row contains one value for each environmental variable, and the values are separated by spaces or tabulations.  Here is an example of an environmental variable file for n = 3 individuals and two environmental variables.  Caution: For more than one variable, the program can be launched for each variable sequentially (Default option) or with all variables simultaneously (see command-line options)\n",
      "\n",
      "\n",
      "Took the input file and opened it in excel keeping only the names of the individuals and the pops and then did a vlookup with the popInfo sheet that has the standardized lats and longs for each of the pops so that the end result is a row for each individual (383) and a column for each variable, there are only 2, long and then lat. \n",
      "\n",
      "\n",
      "\n",
      "ANYWAY, the LFMM isnt running, so thats a bummer. It says that theres a trio problem or something \n",
      "\n",
      "Error: internal error in trio library\n",
      "\n",
      "I modified the file to see if that would help, deleted the row at the end, but then it gave me an even scarier warning. \n",
      "\n",
      "Error in projectLfmmLoad(input.file, environment.file, project) : \n",
      "  The input file has been modified since the creation of the project.\n",
      "If the input file is different, the results concatenating all runs can be false.\n",
      "To remove the current project and start a new one, add the option 'project = new'.\n",
      "To continue with the same project, add the option 'project = force'.\n",
      "\n",
      "So its like how can it claim to be able to run it earlier but now there are problems with it? Frustrating.\n",
      "\n",
      "\n",
      "\n",
      "        $$ October 13  2015\n",
      "==================================================================\n",
      "\n",
      "Talked to Lisa about the results of the PCAs and she didnt really know what to do about it. She recommended that I talk to Julian Olden about it, or go back to Daniel to see what he thinks.\n",
      "\n",
      "Made an excel file that has the summary results of the PCA to show Julian if he can meet to talk about the PCAS. \n",
      "\n",
      "I went back to LFMM to see what is going on with the files, but it was pretty easy to figure out what was keeping it from working right, the file format for the ped file that it converts has to actually be .ped not .txt \n",
      "\n",
      "I still cant figure out how to get the barplot that looks like the structure plots to actually plot, it is giving me a black chunk. Im directly copying the code from the website, and the previous steps worked just fine. \n",
      "\n",
      "OK, So I started it again, I think it might just have some wierd glitch? Maybe theres a path that I dont understand. \n",
      "\n",
      "hahah omg its because the plot was too small. But interestingly, every time that I ran the cross-entropy analysis it gave me a slightly different answer\n",
      "\n",
      "So I have the barplots now, but I cant seem to get it to run the analysis, its giving me this weird error that is even stranger considering I just restarted everything, so the project should have the same input file,\n",
      "\n",
      "Error in projectLfmmLoad(input.file, environment.file, project) : \n",
      "  The input file has been modified since the creation of the project.\n",
      "If the input file is different, the results concatenating all runs can be false.\n",
      "To remove the current project and start a new one, add the option 'project = new'.\n",
      "To continue with the same project, add the option 'project = force'.\n",
      "\n",
      " ill try with some different code in another manual. \n",
      "This is from the manual, it shows why they picked only one value for K: \n",
      "\n",
      "The snmf results suggested that we could use around K=6 factors in lfmm to describe population structure. Note that lfmm does not require an accurate estimate of K (its goal is to end with well-calibrated p-values, not to estimate genetic ancestry). So, our next step is run lfmm with 6 latent factors. The typical call is as follows.\n",
      "\n",
      "Their environmental file only contains one environmental variable too, though I am pretty sure that there is a way to call it so that it runs each one independently, one after the other. \n",
      "\n",
      "To load the project, use:\n",
      " project = load.snmfProject(\"LFMM/LFMM.snmfProject\")\n",
      "\n",
      "To remove the project, use:\n",
      " remove.snmfProject(\"LFMM/LFMM.snmfProject\")\n",
      " \n",
      " ok, so R crashed but the above command did not allow me to just restart where I had left off in the project, so I restarted, from the reconverting the files step. .\n",
      " \n",
      " I started the code again. I dont understand the structure of the LFMM projects so im not sure why this isnt easier. \n",
      " \n",
      " Do I have like 15 projects languishing behind the scenes half finished? \n",
      " \n",
      " they must be overwriting eachother because it gave me this same set of instructions after the cross-entropy section finished: \n",
      " \n",
      " To load the project, use:\n",
      " project = load.snmfProject(\"pulations_b3_may/LFMM/LFMM.snmfProject\")\n",
      "\n",
      "To remove the project, use:\n",
      " remove.snmfProject(\"pulations_b3_may/LFMM/LFMM.snmfProject\")\n",
      " \n",
      "but the plot for that looked the most different so far, so i added the rep = 10 to try to get it to repeat the process 10 times and get something that is more in keeping with what I had seen before. \n",
      "\n",
      "Its going to take a while, but Ill be glad that there was some more riggorous testing of the K values. \n",
      "\n",
      "OK, the plots look pretty good, and i did the barplots and saved them. I was thinking trying to remember the order that the populations were in when they first went into R. the ped file has the names of the populations and it is the same as this: \n",
      "\n",
      "AMUR10\n",
      "AMUR11\n",
      "HAYLY09\n",
      "HAYLY10\n",
      "KOPE91\n",
      "KOPE96\n",
      "KUSHI06\n",
      "KUSHI07\n",
      "NOME91\n",
      "NOME94\n",
      "SNOH03\n",
      "SNOH96\n",
      "TAUY09\n",
      "TAUY12\n",
      "\n",
      "\n",
      "So I am going to import that into R and use it as the names for the x axis. Nope, cant figure out how to And somehow i managed to get R to freeze and crash adn have to restart. None of the actual objects saved, so I dont know how to go about it without just re-doing them. That really really sucks. \n",
      "\n",
      "So its going again, re-writing everything. At least at this point I know that the code is definitely reproduceable. \n",
      "\n",
      "Though the manual definitely says that once you run something it shoudl stay run because the results are saved to a txt file that can be opened again and worked from there so that you dont have to start again each time. Im not sure how that works, but I don thave any indcaton that it ould not work. \n",
      "\n",
      "> summary(obj.snmf)\n",
      "$repetitions\n",
      "                      K = 1 K = 2 K = 3 K = 4 K = 5 K = 6 K = 7 K = 8 K = 9 K = 10 K = 11 K = 12 K = 13 K = 14\n",
      "with cross-entropy       10    10    10    10    10    10    10    10    10     10     10     10     10     10\n",
      "without cross-entropy     0     0     0     0     0     0     0     0     0      0      0      0      0      0\n",
      "total                    10    10    10    10    10    10    10    10    10     10     10     10     10     10\n",
      "\n",
      "$crossEntropy\n",
      "         K = 1     K = 2     K = 3     K = 4     K = 5     K = 6     K = 7     K = 8     K = 9    K = 10    K = 11   K = 12    K = 13    K = 14\n",
      "min  0.4624069 0.4410228 0.4361531 0.4337424 0.4334968 0.4338626 0.4341755 0.4347467 0.4361734 0.4376739 0.4396331 0.4418765 0.4434396 0.4447607\n",
      "mean 0.4646096 0.4430417 0.4384701 0.4360118 0.4361846 0.4362917 0.4367039 0.4375235 0.4389642 0.4404085 0.4423001 0.4440547 0.4455539 0.4475796\n",
      "max  0.4667275 0.4449942 0.4407450 0.4383116 0.4390526 0.4386862 0.4397827 0.4399081 0.4415410 0.4438212 0.4457868 0.4463047 0.4485282 0.4499863\n",
      "     \n",
      "\n",
      "I got the same error as before which sucks because I dont understand how if I have been making this damn project from scratch every time. \n",
      "\n",
      "\n",
      "Error in projectLfmmLoad(input.file, environment.file, project) : \n",
      "  The input file has been modified since the creation of the project.\n",
      "If the input file is different, the results concatenating all runs can be false.\n",
      "To remove the current project and start a new one, add the option 'project = new'.\n",
      "To continue with the same project, add the option 'project = force'.\n",
      "\n",
      "\n",
      "OK so I figured it out, I made the working directory the LFMM file where the .lfmm and .env files are located\n",
      "\n",
      "and I opened the env file and replaced the tab that was separating the columns with a space. So the format changed, it looks like this  now: \n",
      "\n",
      "obj.lfmm_4_d1 <- lfmm(\"LFMM2.lfmm\",\"Long_Lat.env\", project = \"new\", \n",
      "     K = 4,  all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "     iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\t \n",
      "Started them running! \n",
      "\n",
      "I think its going to take a long time to finish. If a couple of them finish over night I might move it over to the student lab. \n",
      "\n",
      "It might finish all of them over night, i started the first one at 4:20 and its 4:45 and the little bars that tell how far along it is are about half way, so it might take one run about an hour and then there are 10 runs, so in 10 hours there might be some resolution! \n",
      "\n",
      "        \n",
      "        \n",
      "         $$ October 14  2015\n",
      "==================================================================\n",
      "The LFMM finished runing over night, this is what the output looks like in R: \n",
      "\n",
      "\n",
      "[1] \"********************************\"\n",
      "[1] \"* K = 8  repetition 1  d = 2   *\"\n",
      "[1] \"********************************\"\n",
      "Summary of the options:\n",
      "\n",
      "        -n (number of individuals)      383\n",
      "        -L (number of loci)             16681\n",
      "        -K (number of latent factors)   8\n",
      "        -o (output file)                LFMM2_Long_Lat.lfmm/K8/run1/LFMM2_r1\n",
      "        -i (number of iterations)       10000\n",
      "        -b (burnin)                     5000\n",
      "        -s (seed random init)           1231957180\n",
      "        -p (number of processes (CPU))  1\n",
      "        -x (genotype file)              LFMM2.lfmm\n",
      "        -v (variable file)              Long_Lat.env\n",
      "        -D (number of covariables)      2\n",
      "        -d (the dth covariable)         2\n",
      "        -m (missing data)                 \n",
      "\n",
      "Read variable file:\n",
      " \tLong_Lat.env\t\tOK.\n",
      "\n",
      "Read genotype file:\n",
      " \tLFMM2.lfmm\t\tOK.\n",
      "\n",
      "<<<<\n",
      "\t Analyse for variable 2\n",
      "\n",
      "\t\tStart of the Gibbs Sampler algorithm.\n",
      "\n",
      "\t[                                                                           ]\n",
      "\t[===========================================================================]\n",
      "\n",
      "\t\tEnd of the Gibbs Sampler algorithm.\n",
      "\n",
      "\tED:6388833.433\t DIC: 6388815.156 \n",
      "\n",
      "\tThe statistics for the run are registered in:\n",
      " \t\tLFMM2_Long_Lat.lfmm/K8/run1/LFMM2_r1_s2.8.dic.\n",
      "\n",
      "\tThe zscores for variable 2 are registered in:\n",
      " \t\tLFMM2_Long_Lat.lfmm/K8/run1/LFMM2_r1_s2.8.zscore.\n",
      "\tThe columns are: zscores, -log10(p-values), p-values.\n",
      "\n",
      "\t-------------------------\n",
      "\tThe execution for variable 2 worked without error.\n",
      "\n",
      "    \n",
      "    \n",
      "HEres a tutorial link to LEA\n",
      "\n",
      "http://membres-timc.imag.fr/Olivier.Francois/LEA/files/SlidesTutorial.pdf\n",
      "\n",
      "    \n",
      "    \n",
      "         $$ October 16  2015\n",
      "==================================================================\n",
      "\n",
      "the runs that were all the environmental variables didnt work because the D variable didnt work. \n",
      "\n",
      "I'm going to take that out and try again. \n",
      "\n",
      "But im confused about the difference between the d the all and the D. what is needed when? \n",
      "\n",
      "\n",
      "\n",
      "This is some of the code that was not working in R: \n",
      "\n",
      "\n",
      "> obj.lfmm_5_PT_all <-lfmm(\"LFMM_in.lfmm\",\"precip_temp_2.env\", project = \"continue\", K = 5, \n",
      "+                         all = TRUE, D = 2, missing.data = TRUE, CPU = 1, d = NULL,\n",
      "+                         iterations = 10000, burnin = 5000, repetitions = 1 )\n",
      "Error in lfmm(\"LFMM_in.lfmm\", \"precip_temp_2.env\", project = \"continue\",  : unused argument (D = 2)\n",
      "\n",
      "\n",
      "\n",
      "> ## pc axis one alone d= 1\n",
      "> \n",
      "> obj.lfmm_4_PT_d1 <-lfmm(\"LFMM_in.lfmm\",\"precip_temp_2.env\", project = \"continue\",  K = 4, \n",
      "+                         all = FALSE, missing.data = TRUE, CPU = 1, d = 1,\n",
      "+                         iterations = 10000, burnin = 5000, repetitions = 1 )\n",
      "The project is saved into :\n",
      " LFMM_in_precip_temp_2.lfmmProject \n",
      "\n",
      "To load the project, use:\n",
      " project = load.lfmmProject(\"LFMM_in_precip_temp_2.lfmmProject\")\n",
      "\n",
      "To remove the project, use:\n",
      " remove.lfmmProject(\"LFMM_in_precip_temp_2.lfmmProject\")\n",
      "\n",
      "[1] \"********************************\"\n",
      "[1] \"* K = 4  repetition 1  d = 1   *\"\n",
      "[1] \"********************************\"\n",
      "The number of individuals of LFMM_in.lfmm (383) is different from the number of individuals of precip_temp_2.env (384)\n",
      "Error: internal error in trio library\n",
      "> \n",
      "\n",
      "\n",
      "\n",
      "> obj.lfmm_4_PT_all <- lfmm(\"LFMM_in.lfmm\",\"precip_temp_2.env\", project = \"continue\", K = 4,  \n",
      "+                          all = TRUE, missing.data = TRUE, CPU = 1, d = NULL,\n",
      "+                          iterations = 10000, burnin = 5000, repetitions = 1)\n",
      "Error in test_integer(\"nd\", d[ndd], 1) : \n",
      "  'nd' argument has to be of type integer.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "> obj.lfmm_4_PT_all <- lfmm(\"LFMM_in.lfmm\",\"precip_temp_2.env\", project = \"continue\", K = 4,  \n",
      "+                          all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "+                          iterations = 10000, burnin = 5000, repetitions = 1)\n",
      "Error in projectLfmmLoad(input.file, environment.file, project) : \n",
      "  The variable file has been modified since the creation of the project.\n",
      "If the variable file is different, the results concatenating all runs can be false.\n",
      "To remove the current project and start a new one, add the option 'project = new'.\n",
      "To continue with the same project, add the option 'project = force'. To create a new project and keep the previous one, change the name of the variable file.\n",
      "\n",
      "> obj.lfmm_4_PT_all <- lfmm(\"LFMM_in.lfmm\",\"precip_temp_2.env\", project = \"force\", K = 4,  \n",
      "+                          all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "+                          iterations = 10000, burnin = 5000, repetitions = 1)\n",
      "Error in projectLfmmLoad(input.file, environment.file, project) : \n",
      "  The variable file has been modified since the creation of the project.\n",
      "If the variable file is different, the results concatenating all runs can be false.\n",
      "To remove the current project and start a new one, add the option 'project = new'.\n",
      "To continue with the same project, add the option 'project = force'. To create a new project and keep the previous one, change the name of the variable file.\n",
      "\n",
      "\n",
      "\n",
      "> obj.lfmm_4_PT_all <- lfmm(\"LFMM_in.lfmm\",\"precip_temp_2.env\", project = force, K = 4,  \n",
      "+                          all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "+                          iterations = 10000, burnin = 5000, repetitions = 1)\n",
      "Error in match(x, table, nomatch = 0L) : \n",
      "  'match' requires vector arguments\n",
      "  \n",
      "  \n",
      "> obj.lfmm_4_PT_all <- lfmm(\"LFMM_in.lfmm\",\"precip_temp.env\", project = \"continue\", K = 4,  \n",
      "+                          all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "+                          iterations = 10000, burnin = 5000, repetitions = 1)\n",
      "\n",
      "^^^^^ this one finally seems to work, I changed the environmental file so that it doesnt have a header, and so it has 383 lines, and changed the name of it so that it is a new project. \n",
      "\n",
      "this is the good news: \n",
      "\n",
      "WARNING: You launched LFMM command line with several variables with '-a' option. The model will be\n",
      "\tlaunched with all variables at the same time.\n",
      "\t\n",
      "But it ends up working so thats fantastic! \n",
      "\n",
      "Ok so I learned something about the U drive, apparently when i am using it on a computer over at SAFS I cant also use it over here, It seems it kicked me off over there and the files couldnt be found etc etc. Very sad. \n",
      "\n",
      "But i put the files out of the udrive and onto a folde on the desktop to save that probelem from happening again, and I restarted the runs for this weekend. I did the LL for 5 repetitions and the temp and precip for 5 repetitions, both the 1 and 2 variables independetly and the all together one. \n",
      "\n",
      "\n",
      "October 18\n",
      "\n",
      "I made the files to run LFMM like with only the individual lineage and continent, so there are 4 new input ped files, and the are:\n",
      "\n",
      "ASO_ped.ped \n",
      "ASE_ped.ped\n",
      "NAO_ped.ped\n",
      "NAE_ped.ped\n",
      "\n",
      "\n",
      "\n",
      "         $$ October 19  2015\n",
      "==================================================================\n",
      "\n",
      "Friday I ran the LFMM on all the samples with the environmental gradients (pca axis one and two of the temp and precip plot) and the Asian groupings. The files werent built so I had to do them by hand over there, but I really wanted them started. \n",
      "\n",
      "I did not do the north american ones, but I will get those files built today and then go over and see what is done on the other ones and have these running. \n",
      "\n",
      "Oct 22\n",
      "\n",
      "The LFMM runs did finish and it seems like there were no errors. i copied all the files back to the thumb drive and to the Udrive to make sure that I have everything. I also checked on the BayeSCenv run on the other computer but it is only about a quarter through the run. Which is lame because it started on Monday so its going to take about a month to finish. \n",
      "\n",
      "\n",
      "Recomputing the covariance each time, we should also be recomputing or restandardizing the environmental variables for each of the sets of populations that Im running. \n",
      "\n",
      "i asked Ryan about LFMM, and he said that he didnt think that I had to worry about that program because it doenst ask for the standardized numbers and so when he ran it he didnt standardize them. \n",
      "\n",
      "\n",
      "\n",
      "Doing the post-analysis phase of the LFMM complete, so its all the populations and the lat and long, and the precip and temp. each of those runs was done seperately. (and also together?)\n",
      "\n",
      "\n",
      "oh my god. so moving them all around was a bad idea because apparently the files are hard coded into the class. \n",
      "\n",
      "i tried to do this, the very most basic thing, loading the project in, and got the error that essentially the class files were missing. \n",
      "\n",
      "> project_LL <- load.snmfProject(\"LFMM_in_Long_Lat_5_new.lfmmProject\")\n",
      "Error in load.snmfProject(\"LFMM_in_Long_Lat_5_new.lfmmProject\") :   no slot of name \"snmfClass.files\" for this object of class \"lfmmProject\"\n",
      "\n",
      "\n",
      "\n",
      "\t\t\n",
      "new(\"lfmmProject\"\n",
      "    , lfmmProject.file = \"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmmProject\"\n",
      "    , directory = \"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/\"\n",
      "    , input.file = \"C:\\\\Users\\\\ctarpey\\\\Desktop\\\\copy_of_Udrive\\\\LFMM_complete\\\\LFMM_in.lfmm\"\n",
      "    , environment.file = \"C:\\\\Users\\\\ctarpey\\\\Desktop\\\\copy_of_Udrive\\\\LFMM_complete\\\\Long_Lat_5_new.env\"\n",
      "    , runs = list()\n",
      "    , K = c(4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, \n",
      "4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L)\n",
      "    , d = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, \n",
      "2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L)\n",
      "    , all = c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n",
      "FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n",
      "FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n",
      "FALSE, FALSE, FALSE)\n",
      "    , lfmmClass.files = c(\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K4/run1/LFMM_in_r1_s1.4.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K4/run2/LFMM_in_r2_s1.4.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K4/run3/LFMM_in_r3_s1.4.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K4/run4/LFMM_in_r4_s1.4.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K4/run5/LFMM_in_r5_s1.4.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K5/run1/LFMM_in_r1_s1.5.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K5/run2/LFMM_in_r2_s1.5.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K5/run3/LFMM_in_r3_s1.5.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K5/run4/LFMM_in_r4_s1.5.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K5/run5/LFMM_in_r5_s1.5.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K6/run1/LFMM_in_r1_s1.6.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K6/run2/LFMM_in_r2_s1.6.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K6/run3/LFMM_in_r3_s1.6.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K6/run4/LFMM_in_r4_s1.6.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K6/run5/LFMM_in_r5_s1.6.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K4/run1/LFMM_in_r1_s2.4.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K4/run2/LFMM_in_r2_s2.4.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K4/run3/LFMM_in_r3_s2.4.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K4/run4/LFMM_in_r4_s2.4.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K4/run5/LFMM_in_r5_s2.4.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K5/run1/LFMM_in_r1_s2.5.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K5/run2/LFMM_in_r2_s2.5.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K5/run3/LFMM_in_r3_s2.5.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K5/run4/LFMM_in_r4_s2.5.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K5/run5/LFMM_in_r5_s2.5.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K6/run1/LFMM_in_r1_s2.6.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K6/run2/LFMM_in_r2_s2.6.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K6/run3/LFMM_in_r3_s2.6.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K6/run4/LFMM_in_r4_s2.6.lfmmClass\", \n",
      "\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm/K6/run5/LFMM_in_r5_s2.6.lfmmClass\"\n",
      ")\n",
      "    , n = 383L\n",
      "    , L = 16681L\n",
      "    , D = 2L\n",
      "    , creationTime = structure(1445289735.93101, class = c(\"POSIXct\", \"POSIXt\"))\n",
      ")\n",
      "\n",
      "\n",
      "OK, so i have all the locations, I just have to do a find replace on the paths. \n",
      "\n",
      "everything is here: G:\\Analysis\\Pop_analysis\\Populations_b3_may\\LFMM\\LFMM_complete\\LFMM_in_Long_Lat_5_new.lfmm\n",
      "\n",
      "so Ill open the file and find this: \n",
      "C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm\n",
      "\n",
      "and replace it with this: \n",
      "G:/Analysis/Pop_analysis/Populations_b3_may/LFMM/LFMM_complete/LFMM_in_Long_Lat_5_new.lfmm\n",
      "\n",
      "I saved the file as _edit at the end. in case I fucked it up. DAMN. theyre all different. so like if you go into the project file, they are all incorretly hard coding the wrong file path. I wonder what I can do? I could write a python script to open all the files and find replace the wrong part of the path with the correct one? FUCK. that seems risky, but it will be so so much work to go through and fix all these by hand. I guess the other option is to run the post-analysis on the computer that they were originally run on. That makes sense. \n",
      "\n",
      "SO\n",
      "\n",
      "i copied the file from Seagate back to the udrive, and ill go put it back on that computer. OR>>> I guess I could just recreate that file on this computer? Ill try that really quick. \n",
      "\n",
      "Nope, that doesnt work because im called Carolyn here and its only when i sign into those other computers that my user name is ctarpey. So that wont work. \n",
      "\n",
      "\n",
      "\n",
      "         $$ October 29 2015\n",
      "==================================================================\n",
      "\n",
      "Im in the graduate computer lab because the file paths for the LFMM results are all for the computers in here. \n",
      "\n",
      "I figured out that the issue with the error i was getting about the class not existing was because i was using the wrong command. I was using the load.snmfProject command instead of the load.lfmmProject command, because what i am loading is hte lfmm project instead of the snmf. \n",
      "\n",
      "so im glad that got straightend up. I still think that the command woulndt have worked on my own computer because of the hardcoded path names, so im glad that i came over here to figure it out. \n",
      "\n",
      "The other thing that i had to change is to add the value of d when I get down to the z.scores section. I have to double that part to account for it. \n",
      "\n",
      "\n",
      "\n",
      "ok i got it to work, it gives me no more errors. i did the lat long and the pt for the all lfmm output, so thats cool. \n",
      "\n",
      "Next im going to do individual ones that are just copies of this code for each of the groupings. NAE NAO ASE ASO and capture the console output too. \n",
      "\n",
      "\n",
      "So ive done the NAE ASE ASO and im about to do the NAO and Im wondering if it really ran the way that I thought it was going to where it takes both the variables and runs them togheter at the same time. I think it didnt do that? SO far all the results are looking like this: \n",
      "\n",
      "lfmmProject file:                      C:/Users/ctarpey/Desktop/LFMM_sm_runs/NAO/NAO_lfmm_NAO_long_lat_PT.lfmmProject \n",
      "directory:                             C:/Users/ctarpey/Desktop/LFMM_sm_runs/NAO/NAO_lfmm_NAO_long_lat_PT.lfmm/ \n",
      "date of creation:                      1445288963 \n",
      "input file:                            C:\\Users\\ctarpey\\Desktop\\LFMM_sm_runs\\NAO\\NAO_lfmm.lfmm \n",
      "variable file:                         C:\\Users\\ctarpey\\Desktop\\LFMM_sm_runs\\NAO\\NAO_long_lat_PT.env \n",
      "number of individuals:                 73 \n",
      "number of loci:                        16681 \n",
      "number of environmental variables:     4 \n",
      "run for the latent factors:            2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 \n",
      "run for the environmental variables:   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 \n",
      "variables separately or together:      FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE \n",
      "\n",
      "\n",
      "\n",
      "All those falses down at the bottom are concerning. SOme of those are supposed to be TRUE> because the command had TRUE In it. Im not really sure what to do about that. \n",
      "\n",
      "I found a problem with the code, after I had set them all up, but it was pretty simple to fix. i went back and reran them all, and remade the console notes for all the groups. "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}