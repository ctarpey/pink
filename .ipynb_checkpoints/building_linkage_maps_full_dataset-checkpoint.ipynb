{
 "metadata": {
  "name": "",
  "signature": "sha256:084dd2de9378519b3bab9e0b3b4f54707bc89353f38cc21030fc65b8a8b9bbbc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Building pink salmon linkage maps\n",
      "\n",
      "I used the ipython notebook building_linkage_maps-original to build linkage maps the Haploid families, after all the resequencing. \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Step 1. Filter the haplotypes and flag duplicates using Ryan's pipeline\n",
      "\n",
      "- Prepare the haplotype file from Stacks \n",
      "- Edit the pipeline; hardcode our file paths and family names\n",
      "\n",
      "Because I did not export the haplotype file in the .sql format, I made formatting changes to the haplotype file to make it ready for the pipeline. \n",
      "\n",
      "The first change to the file is to cut out all the consensus genotypes, they are not useful in the map and take up space. Garrett wrote this script in perl that takes the haplotype file and outputs a version witout the consensus:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#removeConsensus.pl\n",
      "#March 30 2015\n",
      "\n",
      "#!/usr/bin/perl -w\n",
      "use strict;\n",
      "\n",
      "my$header=<>;\n",
      "chomp $header;\n",
      "my@headers=split \"\\t\", $header;\n",
      "print \"$header\\n\";\n",
      "\n",
      "while(my$line=<>){\n",
      "\tmy$consensus=0;\n",
      "\tmy$other=0;\n",
      "    chomp $line;\n",
      "    my@genos=split \"\\t\", $line;\n",
      "    foreach my$i (2..$#genos){\n",
      "        if ($genos[$i] =~ /consensus/){\n",
      "\t\t\t$consensus=1;\n",
      "        }\n",
      "    }\n",
      "\tunless($consensus==1){\n",
      "\t\tprint \"$line\\n\";\n",
      "\t}\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After removing the consensus genotypes, I opened up the haplotype file in Excel to add some columns that the sql file has but the haplotype file is missing.\n",
      "\n",
      "The file needs 5 empty columns after the catalog id column. It also needs 4 empty columns after the count column and one column with the header 'deleveraging' after these newly added 4 empty columns. The deleveraging column should be autofilled with zeros. These are the headers: # Catalog ID, Annotation, Chr, BP, Consensus, Num Parents, Num Progeny, Num SNPs, SNPs, Num Alleles, Alleles, Deleveraging. \n",
      "\n",
      "After the deleveraging column should be columns for the female parents of the families represented. They do not have to have the actual genotypes, Ryan's pipeline only requires their names, but I added the genotypes. Because my parents had been genotyped in Stacks seperate from the haploid individuals because of their ploidy, I used a vlookup in excel to populate their genopytes. The pipeline takes the offspring genotypes and rebuilds the parent genotypes, so I wanted to be able to compare those genotypes to those from Stacks for the parents. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With the haplotype file saved as a text file and ready to be used on the pipeline, the next step is to edit the code for the pipeline. I used the same code as before, so the family names were already changed, but I still had to double check the sample numbers and the file paths. \n",
      "\n",
      "- PBIRD13X_108H 81\n",
      "- PBIRD13x_110H 82\n",
      "- PHOOD11x_110H 93\n",
      "- PHOOD11x_05H 92\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Run the pipeline\n",
      "Here is the actual pipeline code, the supporting programs and files can all be found on the network drives. I copied the whole file locally and I ran the pipeline in Canopy, one chunk at a time to make sure that there were no issues. The pipeline that Ryan wrote is much longer than I have printed in this notebook, but we only used the portion here that ends with writing the loci in the Mst format. In the original script this is about line 244. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#psv_allhaps.py\n",
      "#july 8 2015\n",
      "\n",
      "import os\n",
      "os.chdir(\"G:/Analysis/Mapping/Stacks_mapping/Python\")\n",
      "\n",
      "import cPickle as pickle\n",
      "import numpy\n",
      "\n",
      "import Stacks_SQL_class\n",
      "from models_to_test import models_to_test\n",
      "\n",
      "#Added to attempt phase switching\n",
      "import switch_allele_functions as switchAlleles\n",
      "\n",
      "# Load data created with export_sql.pl \n",
      "chin_fams = Stacks_SQL_class.Stacks_SQL(path = \"G:/Analysis/Mapping/AllHaps/HapHaplotypes.txt\", \n",
      "    name = 'pink',\n",
      "    num_parents = 4, \n",
      "    num_offspring = 348, \n",
      "    parent_offspring = (81, 82, 93, 92)\n",
      "    )\n",
      "    \n",
      "# Kick out Loci (within families) with too many missing genotypes\n",
      "too_many_missing_01 = chin_fams.remove_missing_within_cross(max_miss = .25, parent = 'PBIRD13X108H')\n",
      "too_many_missing_02 = chin_fams.remove_missing_within_cross(max_miss = .25, parent = 'PBIRD13X110H')\n",
      "too_many_missing_03 = chin_fams.remove_missing_within_cross(max_miss = .25, parent = 'PHOOD11X01H')\n",
      "too_many_missing_04 = chin_fams.remove_missing_within_cross(max_miss = .25, parent = 'PHOOD11X05H')\n",
      "\n",
      "\n",
      "# Kick out loci (within families) with too many alleles\n",
      "#too_many_alleles_01 = chum_fams.remove_max_alleles_within_cross(max_alleles = 4, parent = 'CMUW10X_0001')\n",
      "too_many_alleles_01 = chin_fams.remove_max_alleles_within_cross(max_alleles = 4, parent = 'PBIRD13X108H')\n",
      "too_many_alleles_02 = chin_fams.remove_max_alleles_within_cross(max_alleles = 4, parent = 'PBIRD13X110H')\n",
      "too_many_alleles_03 = chin_fams.remove_max_alleles_within_cross(max_alleles = 4, parent = 'PHOOD11X01H')\n",
      "too_many_alleles_04 = chin_fams.remove_max_alleles_within_cross(max_alleles = 4, parent = 'PHOOD11X05H')\n",
      "\n",
      "# Purge CatIDs that failed previous tests in all families\n",
      "purged = chin_fams.purge_absent_catIDs()\n",
      "\n",
      "# Calculate model results using models found in in \"models_to_test.py\"\n",
      "print(\"Calculating PSV Model Likelihoods\")\n",
      "chin_fams.set_model_results(to_test = models_to_test, epsilon_bound_high = 0.1, epsilon_bound_low = 0.01)\n",
      "\n",
      "#mappable_01, stats_01 = chum_fams.find_mappable_markers(parent = 'CMUW10X_0001', models_to_test = models_to_test)\n",
      "mappable_01, stats_01 = chin_fams.find_mappable_markers(parent = 'PBIRD13X108H', models_to_test = models_to_test)\n",
      "mappable_02, stats_02 = chin_fams.find_mappable_markers(parent = 'PBIRD13X110H', models_to_test = models_to_test)\n",
      "mappable_03, stats_03 = chin_fams.find_mappable_markers(parent = 'PHOOD11X01H', models_to_test = models_to_test)\n",
      "mappable_04, stats_04 = chin_fams.find_mappable_markers(parent = 'PHOOD11X05H', models_to_test = models_to_test)\n",
      "\n",
      "\n",
      "def write_stats(filename, stats):\n",
      "    with open(filename, 'w') as OUTFILE:\n",
      "        for catID, values in stats.items():\n",
      "            OUTFILE.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
      "                catID, \n",
      "                values.epsilon,\n",
      "                values.best_model,\n",
      "                values.best_likelihood,\n",
      "                values.second_best_model,\n",
      "                values.second_best_likelihood,\n",
      "                values.x1_seg_pval,\n",
      "                values.x2_seg_pval\n",
      "                )\n",
      "            )\n",
      "            \n",
      "#from psv_working import stats_08\n",
      "#write_stats('/olympus/WORK/WAPLES/Stacks_mapping/Chum_data/psv/chum_01.stats', stats_01)\n",
      "write_stats(\"G:/Analysis/Mapping/AllHaps/PBIRD13X108H_stats_unfiltered.txt\", stats_01)\n",
      "write_stats(\"G:/Analysis/Mapping/AllHaps/PBIRD13X110H_stats_unfiltered.txt\", stats_02)\n",
      "write_stats(\"G:/Analysis/Mapping/AllHaps/PHOOD11X01H_stats_unfiltered.txt\", stats_03)\n",
      "write_stats(\"G:/Analysis/Mapping/AllHaps/PHOOD11X05H_stats_unfiltered.txt\", stats_04)\n",
      "\n",
      "#########################################################################################################################\n",
      "##############################Write Mst Map File for Unfiltered Data#####################################################\n",
      "# Write loci to MSTmap format\n",
      "chin_fams.write_mstmap('PBIRD13X108H', 'G:/Analysis/Mapping/AllHaps/PBIRD13X_108H_mstmap_unfiltered.txt', mappable_01)\n",
      "chin_fams.write_mstmap('PBIRD13X110H', 'G:/Analysis/Mapping/AllHaps/PBIRD13X_110H_mstmap_unfiltered.txt', mappable_02)\n",
      "chin_fams.write_mstmap('PHOOD11X01H', 'G:/Analysis/Mapping/AllHaps/PHOOD11X_01H_mstmap_unfiltered.txt', mappable_03)\n",
      "chin_fams.write_mstmap('PHOOD11X05H', 'G:/Analysis/Mapping/AllHaps/PHOOD11X_05H_mstmap_unfiltered.txt', mappable_04)\n",
      "#########################################################################################################################\n",
      "\n",
      "\n",
      "# Conduct filtering on loci and catIDs\n",
      "# Kick out failed loci\n",
      "# segregation testing\n",
      "import mne\n",
      "import collections\n",
      "def filter_mappable_segregation(stats, alpha = .05):\n",
      "    stats_of_locus = dict()\n",
      "    loci = list()\n",
      "    raw_p_vals = list()\n",
      "    for catID in stats:\n",
      "        if stats[catID].x1_seg_pval == \"NA\":\n",
      "            pass\n",
      "        else:\n",
      "            raw_p_vals.append(stats[catID].x1_seg_pval)\n",
      "            loci.append(catID + \"_x1\")\n",
      "        if stats[catID].x2_seg_pval == \"NA\":\n",
      "            pass\n",
      "        else:\n",
      "            raw_p_vals.append(stats[catID].x2_seg_pval)\n",
      "            loci.append(catID + \"_x2\")\n",
      "    reject, pval_corrected = mne.stats.fdr_correction(pvals = raw_p_vals, alpha = alpha, method = 'indep')\n",
      "    seg_test_fdr = collections.namedtuple('seg_test_fdr', ['reject', 'pval_corrected', 'pval_raw'])\n",
      "    for locus, rej, pvc, pvr in zip(loci, reject, pval_corrected, raw_p_vals):\n",
      "        stats_of_locus[locus] = seg_test_fdr(rej, pvc, pvr)\n",
      "    return(stats_of_locus)\n",
      "# do segregation testing with FDR    \n",
      "\n",
      "seg_test_01 = filter_mappable_segregation(stats_01, alpha = 0.05)\n",
      "seg_test_02 = filter_mappable_segregation(stats_02, alpha = 0.05)\n",
      "seg_test_03 = filter_mappable_segregation(stats_03, alpha = 0.05)\n",
      "seg_test_04 = filter_mappable_segregation(stats_04, alpha = 0.05)\n",
      "\n",
      "# Print how many *would be* excluded\n",
      "print(\"Reject {} out of {} loci in fam_01\".format(sum([x.reject for x in seg_test_01.values()]), len([x.reject for x in seg_test_01.values()])))\n",
      "print(\"Reject {} out of {} loci in fam_02\".format(sum([x.reject for x in seg_test_02.values()]), len([x.reject for x in seg_test_02.values()])))\n",
      "print(\"Reject {} out of {} loci in fam_03\".format(sum([x.reject for x in seg_test_03.values()]), len([x.reject for x in seg_test_03.values()])))\n",
      "print(\"Reject {} out of {} loci in fam_04\".format(sum([x.reject for x in seg_test_04.values()]), len([x.reject for x in seg_test_04.values()])))\n",
      "\n",
      "failed_seg_test_01 = [k for k,v in seg_test_01.items() if v.reject]\n",
      "failed_seg_test_02 = [k for k,v in seg_test_02.items() if v.reject]\n",
      "failed_seg_test_03 = [k for k,v in seg_test_03.items() if v.reject]\n",
      "failed_seg_test_04 = [k for k,v in seg_test_04.items() if v.reject]\n",
      "\n",
      "failed_epsilon_test_01 = [k for k,v in stats_01.items() if v.epsilon > .2]\n",
      "failed_epsilon_test_02 = [k for k,v in stats_02.items() if v.epsilon > .2]\n",
      "failed_epsilon_test_03 = [k for k,v in stats_03.items() if v.epsilon > .2]\n",
      "failed_epsilon_test_04 = [k for k,v in stats_04.items() if v.epsilon > .2]\n",
      "\n",
      "failed_missing_test_01 = [k for k,v in mappable_01.items() if v.count('-')/float(len(v)) > .25]\n",
      "failed_missing_test_02 = [k for k,v in mappable_02.items() if v.count('-')/float(len(v)) > .25]\n",
      "failed_missing_test_03 = [k for k,v in mappable_03.items() if v.count('-')/float(len(v)) > .25]\n",
      "failed_missing_test_04 = [k for k,v in mappable_04.items() if v.count('-')/float(len(v)) > .25]\n",
      "\n",
      "def remove_locus(mappable, locus):\n",
      "    if locus in mappable:\n",
      "        del mappable[locus]\n",
      "        return(1)\n",
      "    else:\n",
      "        return(0)\n",
      "    \n",
      "def remove_catID(mappable, catID):\n",
      "    removed_count = 0\n",
      "    if catID+\"_x1\" in mappable:\n",
      "        del mappable[ catID+\"_x1\"]\n",
      "        removed_count +=1\n",
      "    if catID+\"_x2\" in mappable:\n",
      "        del mappable[ catID+\"_x2\"]\n",
      "        removed_count +=1\n",
      "    return(removed_count)\n",
      "\n",
      "def remove_catIDs(mappable, catIDs):\n",
      "    num_removed = 0\n",
      "    for catID in catIDs:\n",
      "        num_removed += remove_catID(mappable, catID)\n",
      "    print(\"Removed {} loci\".format(num_removed))\n",
      "    \n",
      "def remove_loci(mappable, loci):\n",
      "    num_removed = 0\n",
      "    for locus in loci:\n",
      "        num_removed += remove_locus(mappable, locus)\n",
      "    print(\"Removed {} loci\".format(num_removed))  \n",
      "     \n",
      "remove_catIDs(mappable_01, failed_epsilon_test_01)\n",
      "remove_catIDs(mappable_02, failed_epsilon_test_02)\n",
      "remove_catIDs(mappable_03, failed_epsilon_test_03)\n",
      "remove_catIDs(mappable_04, failed_epsilon_test_04)\n",
      "\n",
      "remove_loci(mappable_01, failed_missing_test_01)\n",
      "remove_loci(mappable_02, failed_missing_test_02)\n",
      "remove_loci(mappable_03, failed_missing_test_03)\n",
      "remove_loci(mappable_04, failed_missing_test_04)\n",
      "\n",
      "remove_loci(mappable_01, failed_seg_test_01)\n",
      "remove_loci(mappable_02, failed_seg_test_02)\n",
      "remove_loci(mappable_03, failed_seg_test_03)\n",
      "remove_loci(mappable_04, failed_seg_test_04)\n",
      "\n",
      "def write_mappable_stats(filename, stats, mappable):\n",
      "    with open(filename, 'w') as OUTFILE:\n",
      "        for catID, values in stats.items():\n",
      "            locally_mappable = sum((catID+\"_x1\" in mappable, catID+\"_x2\" in mappable))\n",
      "            OUTFILE.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
      "                catID,\n",
      "                locally_mappable, \n",
      "                values.epsilon,\n",
      "                values.best_model,\n",
      "                values.best_likelihood,\n",
      "                values.second_best_model,\n",
      "                values.second_best_likelihood,\n",
      "                values.x1_seg_pval,\n",
      "                values.x2_seg_pval\n",
      "                 \n",
      "                )\n",
      "            )\n",
      "\n",
      "write_mappable_stats(\"G:/Analysis/Mapping/AllHaps/PBIRD13X108H_filtered.stats\", stats_01, mappable_01)\n",
      "write_mappable_stats(\"G:/Analysis/Mapping/AllHaps/PBIRD13X_110H_filtered.stats\", stats_02, mappable_02)\n",
      "write_mappable_stats(\"G:/Analysis/Mapping/AllHaps/PHOOD11X_01H_filtered.stats\", stats_03, mappable_03)\n",
      "write_mappable_stats(\"G:/Analysis/Mapping/AllHaps/PHOOD11X_05H_filtered.stats\", stats_04, mappable_04)\n",
      "\n",
      "# Write loci to MSTmap format\n",
      "chin_fams.write_mstmap('PBIRD13X108H', 'G:/Analysis/Mapping/AllHaps/PBIRD13X108H_mstmap_filtered.txt', mappable_01)\n",
      "chin_fams.write_mstmap('PBIRD13X110H', 'G:/Analysis/Mapping/AllHaps//PBIRD13X110H_mstmap_filtered.txt', mappable_02)\n",
      "chin_fams.write_mstmap('PHOOD11X01H', 'G:/Analysis/Mapping/AllHaps/PHOOD11X01H_mstmap_filtered.txt', mappable_03)\n",
      "chin_fams.write_mstmap('PHOOD11X05H', 'G:/Analysis/Mapping/AllHaps/PHOOD11X05H_mstmap_filtered.txt', mappable_04)\n",
      "\n",
      "# Write loci to Rqtl format\n",
      "chin_fams.write_Rqtl('PBIRD13X108H', 'G:/Analysis/Mapping/AllHaps/PBIRD13X_108H_Rqtl_filtered.txt', mappable_01)\n",
      "chin_fams.write_Rqtl('PBIRD13X110H', 'G:/Analysis/Mapping/AllHaps/PBIRD13X_110H_Rqtl_filtered.txt', mappable_02)\n",
      "chin_fams.write_Rqtl('PHOOD11X01H', 'G:/Analysis/Mapping/AllHaps/PHOOD11X_01H_Rqtl_filtered.txt', mappable_03)\n",
      "chin_fams.write_Rqtl('PHOOD11X05H', 'G:/Analysis/Mapping/AllHaps/PHOOD11X_05H_Rqtl_filtered.txt', mappable_04)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There were some errors that had to be addressed as I went along, here is the condensed version as a series of tips: \n",
      "\n",
      "- The families should be in order\n",
      "- The header row of the haplotype file should start with a # \n",
      "- Make sure that the family names that you put in the code of the pipeline match the beginning of the parent names in the haplotype file and that they match the beginninig of the offspring names. That's how the pipeline identifies the parents and the offpsring.\n",
      "\n",
      "I ran the pipeline on Ryan's computer, and created a log file with the command <psv_allhaps_log.txt 2>&1\n",
      "\n",
      "Here is some of the output: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Removed 16776 catIDs from parent: PBIRD13X108H for missingness\n",
      "Removed 16780 catIDs from parent: PBIRD13X110H for missingness\n",
      "Removed 15278 catIDs from parent: PHOOD11X01H for missingness\n",
      "Removed 15392 catIDs from parent: PHOOD11X05H for missingness\n",
      "    \n",
      "Removed 171 catIDs from parent: PBIRD13X108H for too many alleles\n",
      "Removed 148 catIDs from parent: PBIRD13X110H for too many alleles\n",
      "Removed 310 catIDs from parent: PHOOD11X01H for too many alleles\n",
      "Removed 291 catIDs from parent: PHOOD11X05H for too many alleles\n",
      "    \n",
      "Purged 13720 CatIDs removed from all families\n",
      "\n",
      "Reject 212 out of 4647 loci in fam_01\n",
      "Reject 125 out of 5484 loci in fam_02\n",
      "Reject 334 out of 5178 loci in fam_03\n",
      "Reject 304 out of 5052 loci in fam_04\n",
      "\n",
      "Removed 156 loci\n",
      "Removed 116 loci\n",
      "Removed 83 loci\n",
      "Removed 92 loci\n",
      "Removed 52 loci\n",
      "Removed 38 loci\n",
      "Removed 22 loci\n",
      "Removed 16 loci\n",
      "Removed 171 loci\n",
      "Removed 103 loci\n",
      "Removed 301 loci\n",
      "Removed 286 loci\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Output \n",
      "\n",
      "The pipeline produces files for each of the families, a the top of each is a summary. Here are the four summaries for the families run through the pipeline. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "population_type DH\n",
      "population_name PHOOD11X05H\n",
      "distance_function kosambi\n",
      "cut_off_p_value 1e-07\n",
      "no_map_dist 15.0\n",
      "no_map_size 2\n",
      "missing_threshold 0.25\n",
      "estimation_before_clustering yes\n",
      "detect_bad_data yes\n",
      "objective_function COUNT\n",
      "number_of_loci 4658\n",
      "number_of_individual 92\n",
      "\n",
      "population_type DH\n",
      "population_name PHOOD11X01H\n",
      "distance_function kosambi\n",
      "cut_off_p_value 1e-07\n",
      "no_map_dist 15.0\n",
      "no_map_size 2\n",
      "missing_threshold 0.25\n",
      "estimation_before_clustering yes\n",
      "detect_bad_data yes\n",
      "objective_function COUNT\n",
      "number_of_loci 4772\n",
      "number_of_individual 93\n",
      "\n",
      "population_type DH\n",
      "population_name PBIRD13X110H\n",
      "distance_function kosambi\n",
      "cut_off_p_value 1e-07\n",
      "no_map_dist 15.0\n",
      "no_map_size 2\n",
      "missing_threshold 0.25\n",
      "estimation_before_clustering yes\n",
      "detect_bad_data yes\n",
      "objective_function COUNT\n",
      "number_of_loci 5227\n",
      "number_of_individual 82\n",
      "\n",
      "population_type DH\n",
      "population_name PBIRD13X108H\n",
      "distance_function kosambi\n",
      "cut_off_p_value 1e-07\n",
      "no_map_dist 15.0\n",
      "no_map_size 2\n",
      "missing_threshold 0.25\n",
      "estimation_before_clustering yes\n",
      "detect_bad_data yes\n",
      "objective_function COUNT\n",
      "number_of_loci 4268\n",
      "number_of_individual 81\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 2: MST Map \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will build the final maps with LEP-Map as it does a better job calculating the map distance, but for these tests we will build the linkage maps with MSTMap because it is so much faster. \n",
      "\n",
      "MSTMap requires the data be phased, which ours is not. To get past this we will phase it by duplicating it: bulk phase method. We will duplicate the data and swap phase by making a copy of the data that has the exact opposite genotypes for all the individuals and combining the two sets.\n",
      "\n",
      "The resulting maps will have twice the number of linkage groups that we expect, one version represents the opposite phase on the same linkage gropu. Pink salmon have between 52 and 54 chromosomes, so for these haploids we would expect about half of that, ~26 linkage groups. Using the bulk phasing method doubles that, so the likage maps should have around 52 linkage groups. \n",
      "\n",
      "MSTMap takes the Mst output from Ryans pipeline. The genotypes are coded as a and b, with - demarkating missing data. There are no heterozygotes, Ryan's pipeline has split those out. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Background on the parameters used\n",
      "\n",
      "These are located at the top of the MST file that was created in Ryan's pipeline, not all the information there is covered here, some is self explanatory. \n",
      "\n",
      "The cutoff p-value:  decreasing it (more stringent) makes a more fragmented map, but if this is too stringent, then it causes overmerging of the linkage groups. The p-value is typically settled on by trial and error, where you change it until you have the right number of linkage groups. For small families you expect to use a smaller pvalue. We will test pvalue cutoffs between 1e-7 to 1e-3, though we expect the final one to be somewhere between 1e-7 and 1e-5. \n",
      "\n",
      "No map distance: at what point are the markers at the end left off the linkage group, typically it is set at 10cM or 15cM\n",
      "\n",
      "No map size: works in tandem with the no map distance to make the call on whether to make a gap in the linkage group or kick out the makers. 2 here means that if there are only two loci and they are 15 cM away from other markers do not include them.\n",
      "\n",
      "Missingness threshold: this was set in Ryans's pipeline. Here we used  .25\n",
      "\n",
      "Detect bad data: the program trusts the phasing you give it as an imput and it will flag any phase change as an error and it will not include the marker for that individuals. \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Bulk phasing\n",
      "\n",
      "To bulk phase the data, Garrett wrote a perl script that takes the haplotypes for a family and converts all the a's to b's and vice versa. The translated file is then manually copied and pasted to the end of the original file, resulting in a file that is twice as long, with reversed genotypes comprising the addition. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#reveseMSTphase.pl\n",
      "\n",
      "#!/usr/bin/perl -w\n",
      "use strict;\n",
      "\n",
      "while(my$line=<>){\n",
      "\tchomp $line;\n",
      "\tif(($line=~\"x1\")||($line=~\"x2\")){\n",
      "\t\t$line=~tr/ab/ba/;\n",
      "\t}\n",
      "\tprint \"$line\\n\";\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perl reverseMSTphase.pl PHOOD11X05H_mstmap_filtered.txt >PHOOD11X05H_mstmap_filtered_reversed.txt\n",
      "perl reverseMSTphase.pl PHOOD11X01H_mstmap_filtered.txt >PHOOD11X01H_mstmap_filtered_reversed.txt\n",
      "perl reverseMSTphase.pl PBIRD13X108H_mstmap_filtered.txt >PBIRD13X108H_mstmap_filtered_reversed.txt\n",
      "perl reverseMSTphase.pl PBIRD13X110H_mstmap_filtered.txt >PBIRD13X110H_mstmap_filtered_reversed.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The output of this file needs some hands on editing. First, I did a find replace of the _x1 and _x2 to _x1R and _x2R. Then I copied the loci over to the end of the _filtered.txt file, and changed the number of loci in the parameters headers, doubling the number. I saved that file with _combined in the name. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From the tests done using MSTMap the first time, I know that I want to test a couple of differnt p-value cutoffs, between 1e-7 and 1e-3 "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Running MSTMap\n",
      "\n",
      "From a command line inside the directory of MSTMap (or from the directory with the files that has a copy of the program), the command should be:\n",
      "\n",
      "./MSTmap.exe infilename outputfilename\n",
      "\n",
      "There were end of line issues with some of the files in the first set of input files I used, so most of them failed. Here are the four that worked. There are three families represented. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#MSTMap_July.sh\n",
      "\n",
      "./MSTMap.exe PHOOD11X01H_mstmap_combined_5.txt PHOOD11X01H_combined_5_out.txt\n",
      "./MSTMap.exe PHOOD11X05H_mstmap_combined_5.txt PHOOD11X05H_combined_5_out.txt\n",
      "./MSTMap.exe PBIRD13X108H_mstmap_combined_5.txt PBIRD13X108H_combined_5_out.txt\n",
      "./MSTMap.exe PBIRD13X108H_mstmap_combined_4.txt PBIRD13X108H_combined_4_out.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Summarizing MSTMap output"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To more easily identify the results of the MSTMap program, Garrett wrote a perl script that summarizes the output by reporting on the length, the number of markers, and the number of bins per linkage group"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#MST_summary.pl\n",
      "\n",
      "#!/usr/bin/perl -w\n",
      "use strict;\n",
      "\n",
      "my%loci;\n",
      "my%LGlociNum;\n",
      "my%LGlength;\n",
      "my%LGbins;\n",
      "my$lociNum=0;\n",
      "my%binNum;\n",
      "my$currentLG;\n",
      "my$currentPosition;\n",
      "my$store_loci=0;\n",
      "while(my$line=<>){\n",
      "\tchomp $line;\n",
      "\tif($line=~/^group/){\n",
      "\t\tmy($discard, $LG)=split \" \", $line, 2;\n",
      "\t\t$currentLG=$LG;\n",
      "\t}\n",
      "\tif($line=~/\\;BEGINOFGROUP/){\n",
      "\t\t$store_loci=1;\n",
      "\t\tnext;\n",
      "\t}\n",
      "\tif($line=~/\\;ENDOFGROUP/){\n",
      "\t\t$LGlociNum{$currentLG}=$lociNum;\n",
      "\t\t$LGlength{$currentLG}=$currentPosition;\n",
      "\t\tmy$binNum=0;\n",
      "\t\tforeach my$key (keys %binNum){\n",
      "\t\t\t$binNum++;\n",
      "\t\t}\n",
      "\t\t$LGbins{$currentLG}=$binNum;\n",
      "\t\t%binNum=();\n",
      "\t\t$store_loci=0;\n",
      "\t\t$lociNum=0;\n",
      "\t\t$currentLG=\"\";\n",
      "\t\t$currentPosition=\"\";\n",
      "\t}\n",
      "\tif($store_loci==1){\n",
      "\t\tmy($locus, $position)=split \"\\t\", $line, 2;\n",
      "\t\t$loci{$locus}=$currentLG;\n",
      "\t\t$currentPosition=$position;\n",
      "\t\t$binNum{$position}++;\n",
      "\t\t$lociNum++;\n",
      "\t}\n",
      "}\n",
      "\n",
      "print \"LinkageGroup\\tLength(cM)\\t#Markers\\t#Bins\\n\";\n",
      "foreach my$key (sort keys %LGlength){\n",
      "\tprint \"$key\\t$LGlength{$key}\\t$LGlociNum{$key}\\t$LGbins{$key}\\n\";\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perl MST_summary.pl PBIRD13X108H_combined_5_out.txt >PBIRD13X108H_5_out_summary.txt 2>&1\n",
      "perl MST_summary.pl PBIRD13X108H_combined_4_out.txt >PBIRD13X108H_4_out_summary.txt 2>&1\n",
      "perl MST_summary.pl PHOOD11X01H_combined_5_out.txt >PHOOD11X01H_5_out_summary.txt 2>&1\n",
      "perl MST_summary.pl PHOOD11X05H_combined_5_out.txt >PHOOD11X05H_5_out_summary.txt 2>&1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Here's an exaple of what the summary looks like, the majority of the linkage groups at this stage are just a lenght of zero with one maker. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LGroup\tLength(cM)\t#Markers\t#Bins\n",
      "lg253\t0.000\t\t1\t\t1\n",
      "lg254\t0.000\t\t1\t\t1\n",
      "lg255\t0.000\t\t1\t\t1\n",
      "lg256\t225.578\t\t197\t\t174\n",
      "lg257\t195.961\t\t159\t\t137\n",
      "lg258\t861.969\t\t568\t\t469\n",
      "lg259\t230.971\t\t177\t\t169\n",
      "lg26\t0.000\t\t1\t\t1\n",
      "lg260\t158.835\t\t89\t\t72\n",
      "lg261\t235.370\t\t171\t\t156\n",
      "lg262\t170.295\t\t151\t\t126\n",
      "lg263\t227.866\t\t199\t\t175\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Identifying and removing duplicated linkage groups"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are several scripts that Garrett wrote in perl that, when used together, take the output of MSTMap and identify which linkage groups are duplicates of each other, identify which markers belong to a single set of the linkage groups (phase) and finally, split out the the linkage groups into a single set, removing the duplicated linkage groups and markers. \n",
      "\n",
      "The first of these programs is idMSTdupLGs.pl, it identifies the linkage groups that are duplicates of eachother. We expect to have duplicate linkage groups because of the bulk phasing method that we used. This perl sript takes the raw MSTMap output as the first argument, and using > you name the output. The output of the program is a tab seperated list of the paired chromosomes. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#idMSTdupLGs.pl\n",
      "\n",
      "#!/usr/bin/perl -w\n",
      "use strict;\n",
      "\n",
      "my%loci;\n",
      "my$store_loci=0;\n",
      "my$currentLG;\n",
      "while(my$line=<>){\n",
      "\tchomp $line;\n",
      "\tchomp $line;\n",
      "\tif($line=~/^group/){\n",
      "\t\tmy($discard, $LG)=split \" \", $line, 2;\n",
      "\t\t$currentLG=$LG;\n",
      "\t}\n",
      "\tif($line=~/\\;BEGINOFGROUP/){\n",
      "\t\t$store_loci=1;\n",
      "\t\tnext;\n",
      "\t}\n",
      "\tif($line=~/\\;ENDOFGROUP/){\n",
      "\t\t$store_loci=0;\n",
      "\t\t$currentLG=\"\";\n",
      "\t}\n",
      "\tif($store_loci==1){\n",
      "\t\tmy($locus, $position)=split \"\\t\", $line, 2;\n",
      "\t\t$locus=~s/R//;\n",
      "\t\tif(exists $loci{$locus}){\n",
      "\t\t\t$loci{$locus}.=\"\\t\".$currentLG;\n",
      "\t\t}else{\n",
      "\t\t\t$loci{$locus}=$currentLG;\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "\n",
      "my%groupings;\n",
      "foreach my$key (keys %loci){\n",
      "\t$groupings{$loci{$key}}++;\n",
      "}\n",
      "\n",
      "foreach my$key (keys %groupings){\n",
      "\tprint \"$key\\n\";\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perl idMSTdupLGs.pl PBIRD13X108H_combined_4_out.txt >PBIRD13X108H_4_idDUPlgs.txt\n",
      "perl idMSTdupLGs.pl PBIRD13X108H_combined_5_out.txt >PBIRD13X108H_5_idDUPlgs.txt\n",
      "perl idMSTdupLGs.pl PHOOD11X01H_combined_5_out.txt >PHOOD11X01H_5_idDUPlgs.txt\n",
      "perl idMSTdupLGs.pl PHOOD11X05H_combined_5_out.txt >PHOOD11X05H_5_idDUPlgs.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The beginning of the output file from this program is shown below. The next step to 'unphase' the markers, getLGmarkersBatchPhase.pl, requires a single set of the chromosomes, or one column of this list. I open it in excel and delete one column, saving it with another name. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lg139\tlg449\n",
      "lg47\tlg357\n",
      "lg159\tlg469\n",
      "lg69\tlg379\n",
      "lg14\tlg324\n",
      "lg87\tlg397\n",
      "lg25\tlg335\n",
      "lg221\tlg531\n",
      "lg119\tlg429\n",
      "lg305\tlg615\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "getLGmarkersBatchPhase.pl is a perl script that takes the original MSTMap output file as its first argument and the single list of linkage groups made by editing the output of the idMSTdupLGs.pl program as its second. It returns a single set of markers for that list of linkage groups, basically reducing the makers down to a single phase. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#getLGmarkersBatchPhase.pl\n",
      "\n",
      "#!/usr/bin/perl -w\n",
      "use strict;\n",
      "\n",
      "my$MSTfile=$ARGV[0];\n",
      "my$LGfile=$ARGV[1];\n",
      "\n",
      "my%LGs;\n",
      "open(LGFILE, \"<$LGfile\")||die \"cannot open $LGfile:$!\";\n",
      "while(my$line=<LGFILE>){\n",
      "\tchomp $line;\n",
      "\t$LGs{$line}++;\n",
      "}\n",
      "close LGFILE;\n",
      "\n",
      "open(MSTFILE, \"$MSTfile\")||die \"cannot open $MSTfile:$!\";\n",
      "my%loci;\n",
      "my$store_loci=0;\n",
      "my$currentLG;\n",
      "while(my$line=<MSTFILE>){\n",
      "\tchomp $line;\n",
      "\tchomp $line;\n",
      "\tif($line=~/^group/){\n",
      "\t\tmy($discard, $LG)=split \" \", $line, 2;\n",
      "\t\t$currentLG=$LG;\n",
      "\t}\n",
      "\tif($line=~/\\;BEGINOFGROUP/){\n",
      "\t\t$store_loci=1;\n",
      "\t\tnext;\n",
      "\t}\n",
      "\tif($line=~/\\;ENDOFGROUP/){\n",
      "\t\t$store_loci=0;\n",
      "\t\t$currentLG=\"\";\n",
      "\t}\n",
      "\tif($store_loci==1){\n",
      "\t\tmy($locus, $position)=split \"\\t\", $line, 2;\n",
      "\t\t#$locus=~s/R//;\n",
      "\t\tif(exists $LGs{$currentLG}){\n",
      "\t\t\tprint \"$locus\\n\";\n",
      "\t\t}\n",
      "\t}\n",
      "}\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perl getLGmarkersBatchPhase.pl PHOOD11X01H_combined_5_out.txt PHOOD11X01H_5_idDUPlgs_half.txt >PHOOD11X01H_5_getLGs.txt\n",
      "perl getLGmarkersBatchPhase.pl PBIRD13X108H_combined_5_out.txt PBIRD13X108H_5_idDUPlgs_half.txt >PBIRD13X108H_5_getLGs.txt\n",
      "perl getLGmarkersBatchPhase.pl PHOOD11X05H_combined_5_out.txt PHOOD11X05H_5_idDUPlgs_half.txt >PHOOD11X05H_5_getLGs.txt\n",
      "perl getLGmarkersBatchPhase.pl PBIRD13X108H_combined_4_out.txt PBIRD13X108H_4_idDUPlgs_half.txt >PBIRD13X108H_4_getLGs.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The final perl script in this series is called splitMSTbulkPhase.pl. It takes the output from MSTMap as the first argument and for the second argument, the output of the above program, the list of markers at one set of chromosomes. It returns an output similar to the MSTMap original output, but for one set of linkage groups, one phase of the markers. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#splitMSTbulkPhase.pl\n",
      "\n",
      "#!/usr/bin/perl -w\n",
      "use strict;\n",
      "\n",
      "my$MSTfile=$ARGV[0];\n",
      "my$markerList=$ARGV[1];\n",
      "\n",
      "my%printMarkers;\n",
      "open(MARKERLIST, \"<$markerList\")||die \"cannot open $markerList:$!\";\n",
      "while(my$line=<MARKERLIST>){\n",
      "\tchomp $line;\n",
      "\t$printMarkers{$line}++;\n",
      "}\n",
      "close MARKERLIST;\n",
      "\n",
      "open(MSTFILE, \"<$MSTfile\")||die \"cannot open $MSTfile:$!\";\n",
      "my$lineCount=0;\n",
      "while(my$line=<MSTFILE>){\n",
      "\tchomp $line;\n",
      "\t$lineCount++;\n",
      "\tmy($locus,$rest)=split \"\\t\", $line, 2;\n",
      "\tif($lineCount<=14){\n",
      "\t\tprint \"$line\\n\";\n",
      "\t}elsif(exists $printMarkers{$locus}){\n",
      "\t\tprint \"$line\\n\";\n",
      "\t}\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perl splitMSTbulkPhase.pl PHOOD11X01H_combined_5_out.txt PHOOD11X01H_5_getLGs.txt >PHOOD11X01H_5_split.txt\n",
      "perl splitMSTbulkPhase.pl PBIRD13X108H_combined_5_out.txt PBIRD13X108H_5_getLGs.txt >PBIRD13X108H_5_split.txt\n",
      "perl splitMSTbulkPhase.pl PHOOD11X05H_combined_5_out.txt PHOOD11X05H_5_getLGs.txt >PHOOD11X05H_5_split.txt\n",
      "perl splitMSTbulkPhase.pl PBIRD13X108H_combined_4_out.txt PBIRD13X108H_4_getLGs.txt >PBIRD13X108H_4_split.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#####Formatting the output to match the MSTMap output format\n",
      "\n",
      "The output for this program, for the most part, looks like the output from MSTMap, except for some formatting differences. The original output has the linkage groups split up with a header and footer and some blank space between the groups, like this: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "13948_x1\t105.722\n",
      "63466_x1\t105.722\n",
      "6722_x1\t105.722\n",
      "27026_x1\t105.722\n",
      ";ENDOFGROUP\n",
      "\n",
      ";lowerbound:110.422 upperbound: 124.525 cost after initialization:125.046\n",
      "group odd_lg621\n",
      ";BEGINOFGROUP\n",
      "23634_x1\t0.000\n",
      "23634_x2\t13.779\n",
      "29512_x1\t24.140\n",
      "60673_x1\t26.292\n",
      "30026_x2\t27.368"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The output from the splitMSTbulkPhase.pl script doesnt retain those headers. They are not necessary, but for the perl script MST_summary.pl to work, those headers need to be in place. In the output that I wanted to look into more in depth, I went by hand, comparing the original output from MSTMap to the output here, and added the headers from the original MSTMap output in manually."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I ran the summary script again to get a condensed and updated look at the output of the unphased linkage groups. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perl MST_summary.pl PBIRD13X108H_4_split_L.txt >PBIRD13X108H_4_split_summary.txt\n",
      "perl MST_summary.pl PBIRD13X108H_5_split_L.txt >PBIRD13X108H_5_split_summary.txt\n",
      "perl MST_summary.pl PHOOD11X01H_5_split_L.txt >PHOOD11X01H_5_split_summary.txt\n",
      "perl MST_summary.pl PHOOD11X05H_5_split_L.txt >PHOOD11X05H_5_split_summary.txt\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The results: \n",
      "\n",
      "the PBIRD 13x family got the number of linkage groups that we would expect, the _5 had 27 LG and the _4 had 23 LG\n",
      "\n",
      "But for the Hood samples there is something wrong with the linkage groups in this run. There are more than we expected, and I think it has something to do with the phaseing or some step along there. \n",
      "\n",
      "the 01H family has 46 Lg\n",
      "the 05H family has 43 Lg\n",
      "\n",
      "I think its the phase because there are some linkage groups that have the same locus, but different phases. For instance, in the 05H_5 family, the linkage group # 486 and 484 have markers 45043_x1 and 45043_x1R when they should have already have been identified as being the same linkage group and one should have been discarded. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I need to run more versions of MSTMap to get all the families through the program and also to identify a p-value that results in the expected number of linkage groups, anywhere around 26. \n",
      "\n",
      "Im going to split the difference with 108H: try 5 e -5, which is between 1 e-4 and 1 e-5. \n",
      "\n",
      "I ran as many of the steps in the same shell script as possible to speed it up, but after the idMSTdupLGs it requires some hands on attention, so thats where this shell script stops. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#MSTMap_3_delux.sh\n",
      "\n",
      "./MSTMap.exe PHOOD11X05H_mstmap_combined_4.txt PHOOD11X05H_combined_4_out.txt\n",
      "./MSTMap.exe PHOOD11X05H_mstmap_combined_5.txt PHOOD11X05H_combined_5_out.txt\n",
      "./MSTMap.exe PHOOD11X01H_mstmap_combined_4.txt PHOOD11X01H_combined_4_out.txt\n",
      "./MSTMap.exe PHOOD11X01H_mstmap_combined_5.txt PHOOD11X01H_combined_5_out.txt\n",
      "./MSTMap.exe PBIRD13X110H_mstmap_combined_3.txt PBIRD13X110H_combined_3_out.txt\n",
      "./MSTMap.exe PBIRD13X110H_mstmap_combined_4.txt PBIRD13X110H_combined_4_out.txt\n",
      "./MSTMap.exe PBIRD13X108H_mstmap_combined_55.txt PBIRD13X108H_combined_55_out.txt\n",
      "\n",
      "perl MST_summary.pl PHOOD11X05H_combined_4_out.txt >PHOOD11X05H_4_out_summary.txt\n",
      "perl MST_summary.pl PHOOD11X05H_combined_5_out.txt >PHOOD11X05H_5_out_summary.txt\n",
      "perl MST_summary.pl PHOOD11X01H_combined_4_out.txt >PHOOD11X01H_4_out_summary.txt\n",
      "perl MST_summary.pl PHOOD11X01H_combined_5_out.txt >PHOOD11X01H_5_out_summary.txt\n",
      "perl MST_summary.pl PBIRD13X110H_combined_3_out.txt >PBIRD13X110H_3_out_summary.txt\n",
      "perl MST_summary.pl PBIRD13X110H_combined_4_out.txt >PBIRD13X110H_4_out_summary.txt\n",
      "perl MST_summary.pl PBIRD13X108H_combined_55_out.txt >PBIRD13X108H_55_out_summary.txt\n",
      "\n",
      "perl idMSTdupLGs.pl PHOOD11X05H_combined_4_out.txt >PHOOD11X05H_4_idMSTdups.txt\n",
      "perl idMSTdupLGs.pl PHOOD11X05H_combined_5_out.txt >PHOOD11X05H_5_idMSTdups.txt\n",
      "perl idMSTdupLGs.pl PHOOD11X01H_combined_4_out.txt >PHOOD11X01H_4_idMSTdups.txt\n",
      "perl idMSTdupLGs.pl PHOOD11X01H_combined_5_out.txt >PHOOD11X01H_5_idMSTdups.txt\n",
      "perl idMSTdupLGs.pl PBIRD13X110H_combined_3_out.txt >PBIRD13X110H_3_idMSTdups.txt\n",
      "perl idMSTdupLGs.pl PBIRD13X110H_combined_4_out.txt >PBIRD13X110H_4_idMSTdups.txt\n",
      "perl idMSTdupLGs.pl PBIRD13X108H_combined_55_out.txt >PBIRD13X108H_55_idMSTdups.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "the log files for these runs show that there are a large number of what the program calls suspicious data, or individual genotypes at a locus that are not in the phase that the program expects. They seem to be indicative of double crossover recombination events. Mst marks them and treats them as missing data. I was worried that there were a lot of them, but there are only about 14,596 (still seems like a lot) out of 691,416 total genotypes (81 individuals at 8,000+ loci in this case) which is only 2% which isnt that many, in my opinion. \n",
      "\n",
      "I opened the _idMSTdups files in excel and delete one column, then saved it with the same name and a _half at the end. \n",
      "\n",
      "The last time i did this i had some files that had uneven number of linkage groups, but this time both columns had the same number of linkage groups which is a much better sign, and started to run them through the perl program getLGmarkersBatchPhase.pl "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perl getLGmarkersBatchPhase.pl PHOOD11X05H_combined_4_out.txt PHOOD11X05H_4_idMSTdups_half.txt >PHOOD11X05H_4_getLGs.txt \n",
      "perl getLGmarkersBatchPhase.pl PHOOD11X05H_combined_5_out.txt PHOOD11X05H_5_idMSTdups_half.txt >PHOOD11X05H_5_getLGs.txt\n",
      "perl getLGmarkersBatchPhase.pl PHOOD11X01H_combined_4_out.txt PHOOD11X01H_4_idMSTdups_half.txt >PHOOD11X01H_4_getLGs.txt\n",
      "perl getLGmarkersBatchPhase.pl PHOOD11X01H_combined_5_out.txt PHOOD11X01H_5_idMSTdups_half.txt >PHOOD11X01H_5_getLGs.txt\n",
      "perl getLGmarkersBatchPhase.pl PBIRD13X110H_combined_3_out.txt PBIRD13X110H_3_idMSTdups_half.txt >PBIRD13X110H_3_getLGs.txt\n",
      "perl getLGmarkersBatchPhase.pl PBIRD13X110H_combined_4_out.txt PBIRD13X110H_4_idMSTdups_half.txt >PBIRD13X110H_4_getLGs.txt\n",
      "perl getLGmarkersBatchPhase.pl PBIRD13X108H_combined_55_out.txt PBIRD13X108H_55_idMSTdups_half.txt >PBIRD13X108H_55_getLGs.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Split out the Linkage groups, keeping only one phased version\n",
      "\n",
      "perl splitMSTbulkPhase.pl PHOOD11X05H_combined_4_out.txt PHOOD11X05H_4_getLGs.txt >PHOOD11X05H_4_split.txt \n",
      "perl splitMSTbulkPhase.pl PHOOD11X05H_combined_5_out.txt PHOOD11X05H_5_getLGs.txt >PHOOD11X05H_5_split.txt\n",
      "perl splitMSTbulkPhase.pl PHOOD11X01H_combined_4_out.txt PHOOD11X01H_4_getLGs.txt >PHOOD11X01H_4_split.txt\n",
      "perl splitMSTbulkPhase.pl PHOOD11X01H_combined_5_out.txt PHOOD11X01H_5_getLGs.txt >PHOOD11X01H_5_split.txt\n",
      "perl splitMSTbulkPhase.pl PBIRD13X110H_combined_3_out.txt PBIRD13X110H_3_getLGs.txt >PBIRD13X110H_3_split.txt\n",
      "perl splitMSTbulkPhase.pl PBIRD13X110H_combined_4_out.txt PBIRD13X110H_4_getLGs.txt >PBIRD13X110H_4_split.txt\n",
      "perl splitMSTbulkPhase.pl PBIRD13X108H_combined_55_out.txt PBIRD13X108H_55_getLGs.txt >PBIRD13X108H_55_split.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I went through and looked at the linkage groups, 0.00 for the size as the beginning of one linkage group and i would do a search in the MSTmap output file and see if that was the beginning of a LG and then copy over the header for the linkage group. I have all the linkage groups headered and ready to look at with the summary script again. \n",
      "I named the files that had the linkage group headers with an _L at the end of the file name to distinguish them. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perl MST_summary.pl PHOOD11X05H_4_split_L.txt >PHOOD11X05H_4_split_summary.txt \n",
      "perl MST_summary.pl PHOOD11X05H_5_split_L2.txt >PHOOD11X05H_5_split_summary2.txt\n",
      "perl MST_summary.pl PHOOD11X01H_4_split_L.txt >PHOOD11X01H_4_split_summary.txt\n",
      "perl MST_summary.pl PHOOD11X01H_5_split_L.txt >PHOOD11X01H_5_split_summary.txt\n",
      "perl MST_summary.pl PBIRD13X110H_3_split_L.txt >PBIRD13X110H_3_split_summary.txt\n",
      "perl MST_summary.pl PBIRD13X110H_4_split_L.txt >PBIRD13X110H_4_split_summary.txt\n",
      "perl MST_summary.pl PBIRD13X108H_55_split_L.txt >PBIRD13X108H_55_split_summary.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\t\t\t#gps Length(cM)\t#Markers\t#Bins\t\n",
      "PHOOD11X05H_4\t25\t109\t\t176\t\t38\taverage\n",
      "\t\t\t\t\t2729\t4402\t958\ttotal\n",
      "PHOOD11X05H_5\t26\t103\t\t169\t\t37\t\n",
      "\t\t\t\t\t2669\t4402\t964\t\n",
      "PHOOD11X01H_4\t26\t100\t\t170\t\t39\t\n",
      "\t\t\t\t\t2607\t4430\t1001\t\n",
      "PHOOD11X01H_5\t28\t93\t\t161\t\t36\t\n",
      "\t\t\t\t\t2617\t4514\t1012\t\n",
      "\t\t\t\t\n",
      "PBIRD13X110H_3\t11\t1866\t530\t\t530\t\n",
      "\t\t\t\t\t22391\t6361\t6361\t\n",
      "PBIRD13X110H_4\t24\t694\t\t207\t\t207\t\n",
      "\t\t\t\t\t16649\t4978\t4978\t\n",
      "\t\t\t\t\n",
      "PBIRD13X108H_4\t23\t231\t\t173\t\t150\n",
      "\t\t\t\t\t5323\t3976\t3453\t\n",
      "PBIRD13X108H_55 25\t207\t\t159\t\t139\t [this is 5 e-5]\n",
      "\t\t\t\t\t5175\t3976\t3463\t\n",
      "PBIRD13X108H_5\t27\t191\t\t147\t\t128\n",
      "\t\t\t\t\t5167\t3976\t3449"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "PBird 13x 110 crosses are strange. They have the same number of markers as bins. The size of the linkage groups is enormous too.\n",
      "\n",
      "I looked output of Ryans pipeline for the amount of missing data per individual for the four families and the Hood have no individuals that are missing more than 20% of their genotypes. \n",
      "\n",
      "But the PBIRD families do have some individuals missing data. I remade the MSTMap input files for the PBird families, two for each. For the 110 family, one file has only individuals that were genotyped at an 80% rate or higher (69 inds), and one that has individuals that were genotyped at a 65% rate or higher (75) and the same thing with the 108 family (78 indvs with .65 or higher) and (74 indvs with .80 or higher). All have a p-value cutoff of 1 e-5 and there was no change in the number of loci. I used the programs listed above to reverse the loci and then combined the files. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perl reverseMSTphase.pl PBIRD13X108H_mstmap_filtered_80GR.txt >PBIRD13X108H_reversed_80GR.txt\n",
      "perl reverseMSTphase.pl PBIRD13X108H_mstmap_filtered_65GR.txt >PBIRD13X108H_reversed_65GR.txt\n",
      "perl reverseMSTphase.pl PBIRD13X110H_mstmap_filtered_80GR.txt >PBIRD13X110H_reversed_80GR.txt\n",
      "perl reverseMSTphase.pl PBIRD13X110H_mstmap_filtered_65GR.txt >PBIRD13X110H_reversed_65GR.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#MSTMap_4_delux.sh\n",
      "\n",
      "./MSTMap.exe PBIRD13X108H_mstmap_filtered_80GR_combined.txt PBIRD13X108H_80GR_combined_out.txt\n",
      "./MSTMap.exe PBIRD13X108H_mstmap_filtered_65GR_combined.txt PBIRD13X108H_65GR_combined_out.txt\n",
      "\n",
      "#MSTMap_5_delux.sh\n",
      "\n",
      "./MSTMap.exe PBIRD13X110H_mstmap_filtered_80GR_combined.txt PBIRD13X110H_80GR_combined_out.txt\n",
      "./MSTMap.exe PBIRD13X110H_mstmap_filtered_65GR_combined.txt PBIRD13X110H_65GR_combined_out.txt\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perl MST_summary.pl PBIRD13X108H_80GR_combined_out.txt >PBIRD13X108H_80GR_out_summary.txt\n",
      "perl MST_summary.pl PBIRD13X108H_65GR_combined_out.txt >PBIRD13X108H_65GR_out_summary.txt\n",
      "perl MST_summary.pl PBIRD13X110H_80GR_combined_out.txt >PBIRD13X110H_80GR_out_summary.txt\n",
      "perl MST_summary.pl PBIRD13X110H_65GR_combined_out.txt >PBIRD13X110H_65GR_out_summary.txt\n",
      "\n",
      "perl idMSTdupLGs.pl PBIRD13X108H_80GR_combined_out.txt >PBIRD13X108H_80GR_idMSTdups.txt\n",
      "perl idMSTdupLGs.pl PBIRD13X108H_65GR_combined_out.txt >PBIRD13X108H_65GR_idMSTdups.txt\n",
      "perl idMSTdupLGs.pl PBIRD13X110H_80GR_combined_out.txt >PBIRD13X110H_80GR_idMSTdups.txt\n",
      "perl idMSTdupLGs.pl PBIRD13X110H_65GR_combined_out.txt >PBIRD13X110H_65GR_idMSTdups.txt\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I hand edited the idMSTdups. output down to one column of linkage groups and saved it as _half.txt"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perl getLGmarkersBatchPhase.pl PBIRD13X108H_80GR_combined_out.txt PBIRD13X108H_80GR_idMSTdups_half.txt >PBIRD13X108H_80GR_getLGs.txt\n",
      "perl getLGmarkersBatchPhase.pl PBIRD13X108H_65GR_combined_out.txt PBIRD13X108H_65GR_idMSTdups_half.txt >PBIRD13X108H_65GR_getLGs.txt\n",
      "perl getLGmarkersBatchPhase.pl PBIRD13X110H_80GR_combined_out.txt PBIRD13X110H_80GR_idMSTdups_half.txt >PBIRD13X110H_80GR_getLGs.txt\n",
      "perl getLGmarkersBatchPhase.pl PBIRD13X110H_65GR_combined_out.txt PBIRD13X110H_65GR_idMSTdups_half.txt >PBIRD13X110H_65GR_getLGs.txt\n",
      "\n",
      "perl splitMSTbulkPhase.pl PBIRD13X108H_80GR_combined_out.txt PBIRD13X108H_80GR_getLGs.txt >PBIRD13X108H_80GR_split.txt\n",
      "perl splitMSTbulkPhase.pl PBIRD13X108H_65GR_combined_out.txt PBIRD13X108H_65GR_getLGs.txt >PBIRD13X108H_65GR_split.txt\n",
      "perl splitMSTbulkPhase.pl PBIRD13X110H_80GR_combined_out.txt PBIRD13X110H_80GR_getLGs.txt >PBIRD13X110H_80GR_split.txt\n",
      "perl splitMSTbulkPhase.pl PBIRD13X110H_65GR_combined_out.txt PBIRD13X110H_65GR_getLGs.txt >PBIRD13X110H_65GR_split.txt\n",
      "\n",
      "perl MST_summary.pl PBIRD13X108H_80GR_split_L.txt >PBIRD13X108H_80GR_split_summary.txt\n",
      "perl MST_summary.pl PBIRD13X108H_65GR_split_L.txt >PBIRD13X108H_65GR_split_summary.txt\n",
      "perl MST_summary.pl PBIRD13X110H_80GR_split_L.txt >PBIRD13X110H_80GR_split_summary.txt\n",
      "perl MST_summary.pl PBIRD13X110H_65GR_split_L.txt >PBIRD13X110H_65GR_split_summary.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PBIRD13X108H_80GR_SPLIT_L (26)\n",
      "Group  Length(cM)\t#Markers #Bins\n",
      "lg252\t\t186.122\t\t197\t\t150\n",
      "lg253\t\t167.096\t\t159\t\t100\n",
      "lg255\t\t193.801\t\t285\t\t222\n",
      "lg256\t\t133.341\t\t89\t\t64\n",
      "lg257\t\t183.158\t\t171\t\t120\n",
      "lg258\t\t143.879\t\t151\t\t97\n",
      "lg259\t\t193.757\t\t199\t\t140\n",
      "lg261\t\t233.652\t\t182\t\t123\n",
      "lg262\t\t203.847\t\t189\t\t116\n",
      "lg263\t\t228.321\t\t194\t\t152\n",
      "lg264\t\t182.431\t\t209\t\t154\n",
      "lg267\t\t156.406\t\t164\t\t110\n",
      "lg269\t\t215.570\t\t199\t\t155\n",
      "lg270\t\t171.471\t\t196\t\t126\n",
      "lg271\t\t174.270\t\t159\t\t121\n",
      "lg272\t\t166.462\t\t117\t\t94\n",
      "lg273\t\t106.404\t\t95\t\t75\n",
      "lg277\t\t174.471\t\t154\t\t121\n",
      "lg280\t\t18.469\t\t27\t\t25\n",
      "lg282\t\t68.136\t\t93\t\t67\n",
      "lg284\t\t172.423\t\t131\t\t87\n",
      "lg288\t\t192.666\t\t183\t\t122\n",
      "lg290\t\t169.384\t\t121\t\t101\n",
      "lg291\t\t218.425\t\t163\t\t117\n",
      "lg292\t\t144.450\t\t152\t\t112\n",
      "\n",
      "PBIRD13X108H_65GR_SPLIT_L (25)\n",
      "Group  Length(cM)\t#Markers #Bins\n",
      "lg254\t\t167.151\t\t197\t\t118\n",
      "lg255\t\t153.274\t\t159\t\t86\n",
      "lg256\t\t83.942\t\t103\t\t52\n",
      "lg257\t\t159.323\t\t177\t\t92\n",
      "lg258\t\t115.559\t\t89\t\t51\n",
      "lg259\t\t156.273\t\t171\t\t98\n",
      "lg260\t\t132.836\t\t151\t\t82\n",
      "lg261\t\t172.710\t\t198\t\t114\n",
      "lg263\t\t190.883\t\t182\t\t89\n",
      "lg264\t\t188.919\t\t190\t\t100\n",
      "lg265\t\t191.182\t\t194\t\t120\n",
      "lg266\t\t40.228\t\t57\t\t33\n",
      "lg268\t\t138.949\t\t152\t\t89\n",
      "lg269\t\t129.225\t\t164\t\t85\n",
      "lg271\t\t169.195\t\t199\t\t98\n",
      "lg272\t\t140.906\t\t196\t\t84\n",
      "lg273\t\t140.110\t\t159\t\t97\n",
      "lg274\t\t157.174\t\t117\t\t80\n",
      "lg275\t\t104.187\t\t95\t\t74\n",
      "lg279\t\t154.777\t\t155\t\t92\n",
      "lg282\t\t54.569\t\t120\t\t73\n",
      "lg286\t\t148.788\t\t131\t\t86\n",
      "lg290\t\t143.044\t\t183\t\t79\n",
      "lg292\t\t157.200\t\t121\t\t90\n",
      "lg293\t\t177.780\t\t163\t\t90\n",
      "lg294\t\t127.122\t\t152\t\t83\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Besides some smaller differences, it looks like the major difference between the two runs is that LGroup 280 and 282 are combined in _65_ run to be one LGroup: 282. There are also more bins per linkage group in the output of the  _80_ run. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Filtering the MSTmap ouput\n",
      "Garrett wrote a perl script that takes the split output that has had the headers put back into the linkage groups and formats it to make the output easier to work with in excel and R. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#MST_format.pl\n",
      "\n",
      "#!/usr/bin/perl -w\n",
      "use strict;\n",
      "\n",
      "my$MSTfile=$ARGV[0];\n",
      "#my$CRIfile=$ARGV[1];\n",
      "\n",
      "my%loci;\n",
      "my$currentLG;\n",
      "my$store_loci=0;\n",
      "open(MST, \"<$MSTfile\")||die \"cannot open $MSTfile:$!\";\n",
      "while(my $line=<MST>){\n",
      "\tchomp $line;\n",
      "\tif($line=~/^group/){\n",
      "\t\tmy($discard, $LG)=split \" \", $line, 2;\n",
      "\t\t$currentLG=$LG;\n",
      "\t}\n",
      "\tif($line=~/\\;BEGINOFGROUP/){\n",
      "\t\t$store_loci=1;\n",
      "\t\tnext;\n",
      "\t}\n",
      "\tif($line=~/\\;ENDOFGROUP/){\n",
      "\t\t$store_loci=0;\n",
      "\t\t$currentLG=\"\";\n",
      "\t}\n",
      "\tif($store_loci==1){\n",
      "\t\tmy($locus, $position)=split \"\\t\", $line, 2;\n",
      "\t\t$loci{$locus}=$currentLG;\n",
      "\t\tprint \"$locus\\t$position\\t$currentLG\\n\";\n",
      "\t}\n",
      "}\n",
      "close MST;\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I tried it on the 108_65 and 108_80 runs:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perl MST_format.pl PBIRD13X108H_80GR_split_L.txt >PBIRD13X108H_80GR_split_format.txt\n",
      "perl MST_format.pl PBIRD13X108H_65GR_split_L.txt >PBIRD13X108H_65GR_split_format.txt\n",
      "perl MST_format.pl PBIRD13X110H_80GR_split_L.txt >PBIRD13X110H_80GR_split_format.txt\n",
      "perl MST_format.pl PBIRD13X110H_65GR_split_L.txt >PBIRD13X110H_65GR_split_format.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "here is an example of what that format output looks like: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "73440_x1R\t0.000\tlg252\n",
      "10634_x1\t1.029\tlg252\n",
      "17752_x1\t1.681\tlg252\n",
      "51622_x1\t2.086\tlg252\n",
      "11317_x1R\t2.265\tlg252\n",
      "77806_x1\t2.541\tlg252\n",
      "1537_x1\t   2.877\tlg252\n",
      "17706_x1\t3.097\tlg252\n",
      "38056_x1R\t3.097\tlg252\n",
      "21781_x1\t3.808\tlg252\n",
      "36721_x1\t4.651\tlg252\n",
      "48626_x1\t5.605\tlg252\n",
      "64889_x1R\t6.799\tlg252\n",
      "81668_x1R\t7.822\tlg252\n",
      "38934_x1R\t9.309\tlg252\n",
      "65309_x1R\t9.417\tlg252\n",
      "12435_x1\t9.417\tlg252"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "While I was building some files for LepMap, errors in some of the scripts led me to talking to Garrett about how I had run MSTMap, and he told me that I had run one of the programs with the wrong input. The step where we split out the phased data, usin ghte splitMSTbulkPhase.pl program requires the input to MSTMap, not the output from the run. What it does is parse the input file so that it only contains a single phase of data. Then you are supposed to RERUN MSTMap with the new input file and get the right phase and set of linkage groups. From there you can continue with the summary and formatting in excel. By using the output of MSTMap and adding the headers to the linkage groups myself, I was not really doing anything wrong, but I was cutting off linkage group 0 (never more than a singleton in my families) and by sheer lazyness of not wanting to copy paste the header a couple hundered times, I was also filtering out the singleton groups. \n",
      "\n",
      "For all the preliminary runs, this worked fine. I was only interested in the \"real\" linkage groups, or anyway, those that had at least ten markers. But for comparing loci and linkage groups across families and for idenfying duplicated linkage groups I had to re-do this step. \n",
      "\n",
      "I only used the parameters for the four families that I want to use as I move forward through LepMap,and I only need to start at the splitMSTbulkPhase.pl step, all the previous steps are correctly done. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#MSTMap_7_delux.sh\n",
      "\n",
      "./MSTMap.exe PHOOD11X01H_4_splitNEW.txt PHOOD11X01H_4_splitNEW_out.txt\n",
      "./MSTMap.exe PHOOD11X05H_5_splitNEW.txt PHOOD11X05H_5_splitNEW_out.txt\n",
      "./MSTMap.exe PBIRD13X108H_80GR_splitNEW.txt PBIRD13X108H_80GR_splitNEW_out.txt\n",
      "./MSTMap.exe PBIRD13X110H_65GR_splitNEW.txt PBIRD13X110H_65GR_splitNEW_out.txt\n",
      "\n",
      "perl MST_summary.pl PHOOD11X01H_4_splitNEW_out.txt >PHOOD11X01H_4_splitNEW_out_summary.txt\n",
      "perl MST_summary.pl PHOOD11X05H_5_splitNEW_out.txt >PHOOD11X05H_5_splitNEW_out_summary.txt\n",
      "perl MST_summary.pl PBIRD13X108H_80GR_splitNEW_out.txt >PBIRD13X108H_80GR_splitNEW_out_summary.txt\n",
      "perl MST_summary.pl PBIRD13X110H_65GR_splitNEW_out.txt >PBIRD13X110H_65GR_splitNEW_out_summary.txt\n",
      "\n",
      "perl MST_format.pl PHOOD11X01H_4_splitNEW_out.txt >PHOOD11X01H_4_splitNEW_out_format.txt\n",
      "perl MST_format.pl PHOOD11X05H_5_splitNEW_out.txt >PHOOD11X05H_5_splitNEW_out_format.txt\n",
      "perl MST_format.pl PBIRD13X108H_80GR_splitNEW_out.txt >PBIRD13X108H_80GR_splitNEW_out_format.txt\n",
      "perl MST_format.pl PBIRD13X110H_65GR_splitNEW_out.txt >PBIRD13X110H_65GR_splitNEW_out_format.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A note on plotting the maps: \n",
      "    Garrett uses the lattice package in R \n",
      "\n",
      "A note for naming consistency: \n",
      "    The linkage groups will be named arbitrarily each time they are run, and they will be different between families and projects. For this reason, re-name your linkage groups to the chromosome names as soon as possible. \n",
      "\n",
      "A note for using Lep-Map: \n",
      "    Lep-Map changes your loci names. To get over this, copy the names to excel and do conversions. Each family will have a differnt set of loci after being run in Lep-map so keep each conversion key with the family for which it was used, to prevent confusion. "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}