{
 "metadata": {
  "name": "",
  "signature": "sha256:0c5c2812b0d71f8c997f63f744bc2517d9574695b6702d201419bec80a3c1fa1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Outlier Tests with the program LFMM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Background\n",
      "\n",
      "There are several ways to run the program LFMM. I'm using the R package LEA:  http://www.bioconductor.org/packages/release/bioc/html/LEA.html\n",
      "\n",
      "LFMM stands for Latent Factor Mixed Model. The latent factors are the hidden factors, or in this case the population structure. The environmental variables are the fixed variables in this model. Its similar to Bayenv, but Bayenv builds a covariate matrix.\n",
      "\n",
      "##Input files:\n",
      "This is from the manual. Input files are composed of two files:  a genotype file and a variable file.  \n",
      "\n",
      "The genotype file is a SNP matrix with one line per individual, and one column for each locus. Each element can be 0, 1 or 2, missing data is coded with -9.  Each element of the matrix is separated by a single space.  There should be a single space after\n",
      "the last value of each line.  This is an example of a genotype file for n = 3 individuals and L = 5 loci.\n",
      " \n",
      "1 0 0 0 1\n",
      "1 1 -9 2 0\n",
      "0 0 2 1 0\n",
      "\n",
      "The environmental variable file is a vector composed of n lines and D columns.  Each line is the values of the D variables for\n",
      "the corresponding individual.  Below, an example of variable file for n = 3 individuals and D = 1 covariable.\n",
      "\n",
      "Warning:   If  you  set  several  covariables,  the  program  will  be  launched  for  each  covariable  sequentially  and\n",
      "independently.\n",
      "\n",
      "0.252477\n",
      "0.216618\n",
      "-0.47509\n",
      "\n",
      "##Converting the genotype file \n",
      "\n",
      "PGDspider does not convert into Lfmm format. LFMM can convert a .ped into the LFMM format, which PGDspider can do. In PGDSpider I made the SPID file with a yes to a .map file (LFMM_test_map) and told it SNPs for the genepop file and to convert the 0 into a -9 in the code. But it didnt actually convert the 0 to -9. When I use the file in the LFMM program, it missreads the number of SNPs. How do I get a ped file from a genepop file that doesnt take 16,881 snps and code them as 33,666 snps?\n",
      "\n",
      "Apparently, the program can take a ped file (has the two loci per SNPs broken up) and convert it to the right format. So I wrote a script that recodes the PGDSpider ped file so that 01 is 1, etc. and put that file into the LFMM program and let it do the conversion to its own format- that way it wouldnt treat the loci as snps.\n",
      "\n",
      "This is the order of the populations: \n",
      "\n",
      "- AMUR10\n",
      "- AMUR11\n",
      "- HAYLY09\n",
      "- HAYLY10\n",
      "- KOPE91\n",
      "- KOPE96\n",
      "- KUSHI06\n",
      "- KUSHI07\n",
      "- NOME91\n",
      "- NOME94\n",
      "- SNOH03\n",
      "- SNOH96\n",
      "- TAUY09\n",
      "- TAUY12\n",
      "\n",
      "edit_PGDped_to_LFMMped.py LFMM_ped_pgd.ped LFMM_ped.txt"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###Python code to edit the PGD ped file to the LFMM ped file\n",
      "###Carolyn Tarpey and Ryan Waples | September 2015\n",
      "\n",
      "#workflow: get a genepop file and convert it to ped with pgd spider and use that as the input file here\n",
      "###takes two arguments: 1) ped input file from PGDspider, 2) output file name for LFMM ped file\n",
      "# ie: edit_PGDped_to_LFMMped.py LFMM_ped_pgd.ped LFMM_ped.txt\n",
      "\n",
      "# ie: edit_PGDped_to_LFMMped.py LFMM_test_ped.ped LFMM_outtest_ped.txt\n",
      "\n",
      "## Here is an example of what the output format should be: \n",
      "#1 \tSAMPLE0 0 0 2 2 1 2 3 3 1 1 2 1\n",
      "#2 \tSAMPLE1 0 0 1 2 2 1 1 3 0 4 1 1\n",
      "#3 \tSAMPLE2 0 0 2 1 2 2 3 3 1 4 1 2\n",
      "\n",
      "#!/bin/bash\n",
      "import sys\n",
      "import re\n",
      "\n",
      "pat1 = r'pop_1 '\n",
      "pat2 = r'pop_2 '\n",
      "pat3 = r'pop_3 '\n",
      "pat4 = r'pop_4 '\n",
      "pat5 = r'pop_5 '\n",
      "pat6 = r'pop_6 '\n",
      "pat7 = r'pop_7 '\n",
      "pat8 = r'pop_8 '\n",
      "pat9 = r'pop_9 '\n",
      "pat10 = r'pop_10 '\n",
      "pat11 = r'pop_11 '\n",
      "pat12 = r'pop_12 '\n",
      "pat13 = r'pop_13 '\n",
      "pat14 = r'pop_14 '\n",
      "\n",
      "pat1a = r'AMUR10 \\t'\n",
      "pat2a = r'AMUR11 \\t'\n",
      "pat3a = r'HAYLY09 \\t'\n",
      "pat4a = r'HAYLY10 \\t'\n",
      "pat5a = r'KOPE91 \\t'\n",
      "pat6a = r'KOPE96 \\t'\n",
      "pat7a = r'KUSHI06 \\t'\n",
      "pat8a = r'KUSHI07 \\t'\n",
      "pat9a = r'NOME91 \\t'\n",
      "pat10a = r'NOME94 \\t'\n",
      "pat11a = r'SNOH03 \\t'\n",
      "pat12a = r'SNOH96 \\t'\n",
      "pat13a = r'TAUY09 \\t'\n",
      "pat14a = r'TAUY12 \\t'\n",
      "\n",
      "pat01 = r'01'\n",
      "pat02 = r'02'\n",
      "pat03 = r'03'\n",
      "pat04 = r'04'\n",
      "\n",
      "\n",
      "pat01a = r'1'\n",
      "pat02a = r'2'\n",
      "pat03a = r'3'\n",
      "pat04a = r'4'\n",
      "\n",
      "\n",
      "with open(sys.argv[1], 'r') as INFILE:\n",
      "\twith open(sys.argv[2], 'w') as OUTFILE:\n",
      "\t\tfor line in INFILE:\n",
      "\t\t\tsample = line.strip()\n",
      "\t\t\tif pat1 in line:\n",
      "\t\t\t\tsample = re.sub(pat1, pat1a, sample)\n",
      "\t\t\tif pat2 in line:\n",
      "\t\t\t\tsample = re.sub(pat2, pat2a, sample) \n",
      "\t\t\tif pat3 in line:\n",
      "\t\t\t\tsample = re.sub(pat3, pat3a, sample)\n",
      "\t\t\tif pat4 in line:\n",
      "\t\t\t\tsample = re.sub(pat4, pat4a, sample)\n",
      "\t\t\tif pat5 in line:\n",
      "\t\t\t\tsample = re.sub(pat5, pat5a, sample)\n",
      "\t\t\tif pat6 in line:\n",
      "\t\t\t\tsample = re.sub(pat6, pat6a, sample)\n",
      "\t\t\tif pat7 in line:\n",
      "\t\t\t\tsample = re.sub(pat7, pat7a, sample)\n",
      "\t\t\tif pat8 in line:\n",
      "\t\t\t\tsample = re.sub(pat8, pat8a, sample)\n",
      "\t\t\tif pat9 in line:\n",
      "\t\t\t\tsample = re.sub(pat9, pat9a, sample)\n",
      "\t\t\tif pat10 in line:\n",
      "\t\t\t\tsample = re.sub(pat10, pat10a, sample)\n",
      "\t\t\tif pat11 in line:\n",
      "\t\t\t\tsample = re.sub(pat11, pat11a, sample)\n",
      "\t\t\tif pat12 in line:\n",
      "\t\t\t\tsample = re.sub(pat12, pat12a, sample)\n",
      "\t\t\tif pat13 in line:\n",
      "\t\t\t\tsample = re.sub(pat13, pat13a, sample)\n",
      "\t\t\tif pat14 in line:\n",
      "\t\t\t\tsample = re.sub(pat14, pat14a, sample)\n",
      "\t\t\tsample = sample.split(\" \")\n",
      "\t\t\tfrontslice = sample[0:6]\n",
      "\t\t\t#cutfrontslice = frontslice[0:4]\n",
      "\t\t\tbackslice = sample[6:]\n",
      "\t\t\tbackslicedit1 = re.sub(pat01, pat01a, \" \".join(backslice))\n",
      "\t\t\tbackslicedit2 = re.sub(pat02, pat02a, backslicedit1)\n",
      "\t\t\tbackslicedit3 = re.sub(pat03, pat03a, backslicedit2)\n",
      "\t\t\tbackslicedit4 = re.sub(pat04, pat04a, backslicedit3)\n",
      "\t\t\tbackslicedit4 = backslicedit4.split(\" \")\n",
      "\t\t\teditedline = frontslice + backslicedit4\n",
      "\t\t\tOUTFILE.write(\" \".join(editedline))\n",
      "\t\t\tOUTFILE.write(\"\\n\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then take this file and use the command in LFMM ped2lfmm to convert it to the lfmm format, making sure the program counts the correct number of individuals and loci."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "> ped2lfmm(\"G:/Analysis/Pop_analysis/Populations_b3_may/LFMM/ConvertFiles/LFMM_out_ped.ped\",\"LFMM.lfmm\" )\n",
      "\n",
      "\t- number of detected individuals:\t383\n",
      "\t- number of detected loci:\t\t16681\n",
      "\n",
      "[1] \"LFMM.lfmm\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Estimating population structure, K, with LEA\n",
      "\n",
      "The K value, or the latent factor, represents the population structure.  There are several ways to get K and you should test several K. From the manual: The number of latent factors is the number of principal components that should be required for the neutral structure of the data. Several values should be tested.  A too small value of K will do the model too liberal.  A too large value of K will do the model too conservative.  In our paper, we used the number of significative principal components in the Tracy-Widom test of SmartPCA (http://helix.nih.gov/Applications/eigensoft.html).  This heuristic is a bit too conservative.  We also used the Bayesian clustering programs STRUCTURE (http://pritch.bsd.uchicago.edu/software/structure21.html) to find K the number of components which could better describe our simulated data.  We advise you to be really careful in the choice of K and to test several values of K\n",
      "\n",
      "Can I run STRUCTURE analyses from the R command line using LEA?\n",
      "    Answer: Yes. The \"snmf\" function is very similar to STRUCTURE but hundred times faster. The choice of the number of clusters is based on a cross-validation criterion, which may be more reliable than methods used for STRUCTURE. \n",
      "\n",
      "###LFMM estimates K for you.\n",
      "\n",
      "Using the code found on the website and the R packagae LEA, I estimated values of K from 1 through 14 (the number of total populations). I used a repetition of 10 (used in the manual) and emplyed the cross entropy option.\n",
      "\n",
      "The  manual says: \n",
      "The snmf function also estimates an entropy criterion that evaluates the quality of fit of the statistical model to the data using a cross-validation technique. The entropy criterion can help choosing the number of ancestral populations that best explains the genotypic data. The number of ancestral population is closely linked to the number of principal components that explain variation in the genomic data. Both numbers can help determining the number of latent factors when correcting for confounding effects due to population structure in ecological association tests. The snmf results suggested that we (the authors of the manual) could use around K = 6 factors in lfmm to describe population structure. Note that lfmm does not require an accurate estimate of K (its goal is to end with well-calibrated p-values, not to estimate genetic ancestry). So, our next step is run lfmm with 6 latent factors. \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Performing LFMM analyis on population data\n",
      "###    using the package LEA from http://www.bioconductor.org/packages/release/bioc/html/LEA.html\n",
      "### Carolyn Tarpey | September 2015 \n",
      "### ---------------------------------------\n",
      "\n",
      "#set the working directory \n",
      "#setwd(\"C:/Users/Carolyn/Documents/GitHub/pink/LFMM\")\n",
      "\n",
      "setwd(\"G:/Analysis/Pop_analysis/Populations_b3_may/LFMM\")\n",
      "\n",
      "#install.packages(\"biocLite\", source = \"https://bioconductor.org/biocLite.R\")\n",
      "#biocLite(\"LEA\")\n",
      "\n",
      "library(LEA)\n",
      "\n",
      "#to load project, use:\n",
      "project <- load.snmfProject(\"G:/Analysis/Pop_analysis/Populations_b3_may/LFMM/LFMM.snmfProject\")\n",
      "\n",
      "#names of the populations in order\n",
      "names <- read.table(\"G:/Analysis/Pop_analysis/Populations_b3_may/LFMM/POPnames.txt\", row.names = 1 )\n",
      "\n",
      "#convert the edited ped file into the LFMM format\n",
      "ped2lfmm(\"G:/Analysis/Pop_analysis/Populations_b3_may/LFMM/ConvertFiles/LFMM_out_ped.ped\",\n",
      "         \"G:/Analysis/Pop_analysis/Populations_b3_may/LFMM/LFMM2.lfmm\" )\n",
      "\n",
      "#convert the lfmm format into the genotype format\n",
      "genotype <- lfmm2geno(\"G:/Analysis/Pop_analysis/Populations_b3_may/LFMM/LFMM2.lfmm\", \n",
      "                      \"G:/Analysis/Pop_analysis/Populations_b3_may/LFMM/LFMM.geno\")\n",
      "\n",
      "#figuring out K, the number of ancestral populations\n",
      "obj.snmf = snmf(genotype, K = 1:14, entropy = TRUE, ploidy = 2, rep = 10, project = \"new\")\n",
      "\n",
      "#show and summarize the results \n",
      "show(obj.snmf)\n",
      "summary(obj.snmf)\n",
      "\n",
      "#Plotting the values of the cross-entropy criterion for each K; the value for which the function plateaus or increases is our estimate of K\n",
      "plot(obj.snmf)\n",
      "\n",
      "#plot cross-entropy criterion of all runs of the project\n",
      "plot(obj.snmf, lwd= 5, col = \"red\", pch=1)\n",
      "\n",
      "#to get the cross-entropy of each run for K = 4:8\n",
      "ce_4 <- cross.entropy(obj.snmf, K= 4)\n",
      "ce_5 <- cross.entropy(obj.snmf, K= 5)\n",
      "ce_6 <- cross.entropy(obj.snmf, K= 6)\n",
      "ce_7 <- cross.entropy(obj.snmf, K= 7)\n",
      "ce_8 <- cross.entropy(obj.snmf, K= 8)\n",
      "\n",
      "#select the run with the lowest cross-entropy \n",
      "best_4 <- which.min(ce_4)\n",
      "best_5 <- which.min(ce_5)\n",
      "best_6 <- which.min(ce_6)\n",
      "best_7 <- which.min(ce_7)\n",
      "best_8 <- which.min(ce_8)\n",
      "\n",
      "#visualize a bar plot of ancestry coefficients \n",
      "windows(height=7, width=7)\n",
      "\n",
      "barplot(t(Q(obj.snmf, K = 4, run = best_4)), col = 1:4)\n",
      "barplot(t(Q(obj.snmf, K = 5, run = best_5)), col = 1:5)\n",
      "barplot(t(Q(obj.snmf, K = 6, run = best_6)), col = 1:6)\n",
      "barplot(t(Q(obj.snmf, K = 7, run = best_7)), col = 1:7)\n",
      "barplot(t(Q(obj.snmf, K = 8, run = best_8)), col = 1:8)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "LFMM finished running, and it looks like 4, 5 6 are the best K values, though I will try 4-8 to be safe."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Environmental variable files\n",
      "\n",
      "The environmental file format consists of one row for each individual, and each column is an environmental variable.  Caution: For more than one variable, the program can be launched for each variable sequentially (Default option) or with all variables simultaneously (see command-line options). \n",
      "\n",
      "I built the environmental file in excel, opening the genotype file and keeping the individual names and populations and using  vlookup with a spreadsheet that has all the environmental variables for each population.\n",
      "\n",
      "Recomputing the covariance each time, we should also be recomputing or restandardizing the environmental variables for each of the sets of populations that Im running. i asked Ryan about LFMM, and he said that he didnt think that I had to worry about that program because it doenst ask for the standardized numbers and so when he ran it he didnt standardize them. \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Running the genome scan with the environmental variables\n",
      "There was a lot of testing of the code to see what would run. This ended up working, and I built the following R code around the command.  I changed the environmental file so that it doesn't have a header, that way it has 383 lines. I also changed the name of the file so that it would be a new project, the program names the project based on the environmental variable file. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "> obj.lfmm_4_PT_all <- lfmm(\"LFMM_in.lfmm\",\"precip_temp.env\", project = \"continue\", K = 4,  \n",
      "+                          all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "+                          iterations = 10000, burnin = 5000, repetitions = 1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "The first set of runs that I tried are the Lat and Long (LL) for 5 repetitions and the Temp and Precip (P, T) for 5 repetitions. In each case, I tried to run it with each of the variables independently d=1, d=2 and then both the variables together. When they are run together, they are paired LL and PT. I have seen two different warnings about running the variables at the same time, one thing in the manual says this: \n",
      "\n",
      "Caution: For more than one variable, the program can be launched for each variable sequentially (Default option) or with all variables simultaneously (see command-line options).  \n",
      "\n",
      "and another this:\n",
      "\n",
      "Warning:   If  you  set  several  covariables,  the  program  will  be  launched  for  each  covariable  sequentially  and\n",
      "independently.\n",
      "\n",
      "I won't know if it works until I try. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Performing LFMM analyis on population data\n",
      "###    using the package LEA from http://www.bioconductor.org/packages/release/bioc/html/LEA.html\n",
      "### Carolyn Tarpey | September 2015 \n",
      "### ---------------------------------------\n",
      "\n",
      "#set the working directory \n",
      "setwd(\"U:/LFMM\")\n",
      "setwd(\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete\")\n",
      "\n",
      "source(\"http://bioconductor.org/biocLite.R\")\n",
      "biocLite()\n",
      "biocLite(\"LEA\")\n",
      "library(LEA)\n",
      "\n",
      "#to load project, use:\n",
      "#project <- load.snmfProject(\"G:/Analysis/Pop_analysis/Populations_b3_may/LFMM/LFMM.snmfProject\")\n",
      "\n",
      "#names of the populations in order\n",
      "names <- read.table(\"POPnames.txt\", row.names = 1 )\n",
      "\n",
      "#convert the edited ped file into the LFMM format\n",
      "ped2lfmm(\"LFMM_out_ped.ped\", \"LFMM_in.lfmm\" )\n",
      "\n",
      "#convert the lfmm format into the genotype format\n",
      "genotype <- lfmm2geno(\"LFMM_in.lfmm\", \"LFMM_in.geno\")\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "\n",
      "#genome scan for selection using env variables\n",
      "#running it with the standard longitude as the first variable and the stand lat as the second \n",
      "\n",
      "#project <- \"SecondTest\"\n",
      "\n",
      "obj.lfmm_4_LL_d1 <- lfmm(\"LFMM_in.lfmm\",\"Long_Lat_new.env\", project = \"continue\", K = 4,  \n",
      "      all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "     iterations = 10000, burnin = 5000, repetitions = 1)\n",
      "\n",
      "obj.lfmm_5_LL_d1 <-lfmm(\"LFMM_in.lfmm\",\"Long_Lat_new.env\", project = \"continue\", K = 5, \n",
      "     all = FALSE, missing.data = TRUE, CPU = 1, d = 1,\n",
      "     iterations = 10000, burnin = 5000, repetitions = 1 )\n",
      "\n",
      "obj.lfmm_6_LL_d1 <-lfmm(\"LFMM_in.lfmm\",\"Long_Lat_new.env\", project = \"continue\",  K = 6, \n",
      "      all = FALSE, missing.data = TRUE, CPU = 1, d = 1,\n",
      "     iterations = 10000, burnin = 5000, repetitions = 1 )\n",
      "\n",
      "obj.lfmm_4_LL_d2 <- lfmm(\"LFMM_in.lfmm\",\"Long_Lat_new.env\", project = \"continue\",  K = 4, \n",
      "    all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "    iterations = 10000, burnin = 5000, repetitions = 1)\n",
      "\n",
      "obj.lfmm_5_LL_d2 <-lfmm(\"LFMM_in.lfmm\",\"Long_Lat_new.env\", project = \"continue\",  K = 5, \n",
      "      all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "     iterations = 10000, burnin = 5000, repetitions = 1)\n",
      "\n",
      "obj.lfmm_6_LL_d2 <-lfmm(\"LFMM_in.lfmm\",\"Long_Lat_new.env\", project = \"continue\",  K = 6, \n",
      "      all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "     iterations = 10000, burnin = 5000, repetitions = 1 )\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "#genome scan for selection using env variables\n",
      "#running it with the temperature and precipitation variables\n",
      "########Repetition of 1\n",
      "#all pc axis together- one and two. \n",
      "\n",
      "obj.lfmm_4_PT_all <- lfmm(\"LFMM_in.lfmm\",\"precip_temp.env\", project = \"continue\", K = 4,  \n",
      "                         all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "                         iterations = 10000, burnin = 5000, repetitions = 1)\n",
      "\n",
      "obj.lfmm_5_PT_all <-lfmm(\"LFMM_in.lfmm\",\"precip_temp.env\", project = \"continue\", K = 5, \n",
      "                        all = TRUE, missing.data = TRUE, CPU = 1,\n",
      "                        iterations = 10000, burnin = 5000, repetitions = 1 )\n",
      "\n",
      "obj.lfmm_6_PT_all <-lfmm(\"LFMM_in.lfmm\",\"precip_temp.env\", project = \"continue\",  K = 6, \n",
      "                        all = TRUE, missing.data = TRUE, CPU = 1,\n",
      "                        iterations = 10000, burnin = 5000, repetitions = 1 )\n",
      "\n",
      "## pc axis one alone d= 1\n",
      "\n",
      "obj.lfmm_4_PT_d1 <-lfmm(\"LFMM_in.lfmm\",\"precip_temp.env\", project = \"continue\",  K = 4, \n",
      "                        all = FALSE, missing.data = TRUE, CPU = 1, d = 1,\n",
      "                        iterations = 10000, burnin = 5000, repetitions = 1 )\n",
      "\n",
      "obj.lfmm_5_PT_d1 <-lfmm(\"LFMM_in.lfmm\",\"precip_temp.env\", project = \"continue\", K = 5, \n",
      "                        all = FALSE, missing.data = TRUE, CPU = 1, d = 1,\n",
      "                        iterations = 10000, burnin = 5000, repetitions = 1 )\n",
      "\n",
      "obj.lfmm_6_PT_d1 <- lfmm(\"LFMM_in.lfmm\",\"precip_temp.env\", project = \"continue\",  K = 6, \n",
      "                         all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                         iterations = 10000, burnin = 5000, repetitions = 1)\n",
      "\n",
      "## pc axis two alone d = 2\n",
      "\n",
      "obj.lfmm_4_PT_d2 <-lfmm(\"LFMM_in.lfmm\",\"precip_temp.env\", project = \"continue\",  K = 4, \n",
      "                        all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                        iterations = 10000, burnin = 5000, repetitions = 1 )\n",
      "\n",
      "obj.lfmm_5_PT_d2 <-lfmm(\"LFMM_in.lfmm\",\"precip_temp.env\", project = \"continue\",  K = 5, \n",
      "                        all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                        iterations = 10000, burnin = 5000, repetitions = 1 )\n",
      "\n",
      "obj.lfmm_6_PT_d2 <-lfmm(\"LFMM_in.lfmm\",\"precip_temp.env\", project = \"continue\",  K = 6, \n",
      "                        all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                        iterations = 10000, burnin = 5000, repetitions = 1 )\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "  #genome scan for selection using env variables\n",
      "#running it with the standard longitude as the first variable and the stand lat as the second \n",
      "#repetition of 5\n",
      "\n",
      "obj.lfmm_4_LL_d1_5 <- lfmm(\"LFMM_in.lfmm\",\"Long_Lat_5_new.env\", project = \"continue\", K = 4,  \n",
      "                         all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                         iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "obj.lfmm_5_LL_d1_5 <-lfmm(\"LFMM_in.lfmm\",\"Long_Lat_5_new.env\", project = \"continue\", K = 5, \n",
      "                        all = FALSE, missing.data = TRUE, CPU = 1, d = 1,\n",
      "                        iterations = 10000, burnin = 5000, repetitions = 5 )\n",
      "\n",
      "obj.lfmm_6_LL_d1_5 <-lfmm(\"LFMM_in.lfmm\",\"Long_Lat_5_new.env\", project = \"continue\",  K = 6, \n",
      "                        all = FALSE, missing.data = TRUE, CPU = 1, d = 1,\n",
      "                        iterations = 10000, burnin = 5000, repetitions = 5 )\n",
      "\n",
      "obj.lfmm_4_LL_d2_5 <- lfmm(\"LFMM_in.lfmm\",\"Long_Lat_5_new.env\", project = \"continue\",  K = 4, \n",
      "                         all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                         iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "obj.lfmm_5_LL_d2_5 <-lfmm(\"LFMM_in.lfmm\",\"Long_Lat_5_new.env\", project = \"continue\",  K = 5, \n",
      "                        all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                        iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "obj.lfmm_6_LL_d2_5 <-lfmm(\"LFMM_in.lfmm\",\"Long_Lat_5_new.env\", project = \"continue\",  K = 6, \n",
      "                        all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                        iterations = 10000, burnin = 5000, repetitions = 5 )  \n",
      "\n",
      "########Repetition of 5\n",
      "#all pc axis together- one and two. \n",
      "\n",
      "obj.lfmm_4_PT_all_5 <- lfmm(\"LFMM_in.lfmm\",\"precip_temp_all.env\", project = \"continue\", K = 4,  \n",
      "                          all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "                          iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "obj.lfmm_5_PT_all_5 <-lfmm(\"LFMM_in.lfmm\",\"precip_temp_all.env\", project = \"continue\", K = 5, \n",
      "                         all = TRUE, missing.data = TRUE, CPU = 1,\n",
      "                         iterations = 10000, burnin = 5000, repetitions = 5 )\n",
      "\n",
      "obj.lfmm_6_PT_all_5 <-lfmm(\"LFMM_in.lfmm\",\"precip_temp_all.env\", project = \"continue\",  K = 6, \n",
      "                         all = TRUE, missing.data = TRUE, CPU = 1,\n",
      "                         iterations = 10000, burnin = 5000, repetitions = 5 )\n",
      "\n",
      "## pc axis one alone d= 1\n",
      "\n",
      "obj.lfmm_4_PT_d1_5 <-lfmm(\"LFMM_in.lfmm\",\"precip_temp_all.env\", project = \"continue\",  K = 4, \n",
      "                        all = FALSE, missing.data = TRUE, CPU = 1, d = 1,\n",
      "                        iterations = 10000, burnin = 5000, repetitions = 5 )\n",
      "\n",
      "obj.lfmm_5_PT_d1_5 <-lfmm(\"LFMM_in.lfmm\",\"precip_temp_all.env\", project = \"continue\", K = 5, \n",
      "                        all = FALSE, missing.data = TRUE, CPU = 1, d = 1,\n",
      "                        iterations = 10000, burnin = 5000, repetitions = 5 )\n",
      "\n",
      "obj.lfmm_6_PT_d1_5 <- lfmm(\"LFMM_in.lfmm\",\"precip_temp_all.env\", project = \"continue\",  K = 6, \n",
      "                         all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                         iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "## pc axis two alone d = 2\n",
      "\n",
      "obj.lfmm_4_PT_d2_5 <-lfmm(\"LFMM_in.lfmm\",\"precip_temp_all.env\", project = \"continue\",  K = 4, \n",
      "                        all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                        iterations = 10000, burnin = 5000, repetitions = 5 )\n",
      "\n",
      "obj.lfmm_5_PT_d2_5 <-lfmm(\"LFMM_in.lfmm\",\"precip_temp_all.env\", project = \"continue\",  K = 5, \n",
      "                        all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                        iterations = 10000, burnin = 5000, repetitions = 5 )\n",
      "\n",
      "obj.lfmm_6_PT_d2_5 <-lfmm(\"LFMM_in.lfmm\",\"precip_temp_all.env\", project = \"continue\",  K = 6, \n",
      "                        all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                        iterations = 10000, burnin = 5000, repetitions = 5 )\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "    #from here use the Post_process_LFMM.r code to process the output of these runs. \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###I got this warning, so I am optimistic that the variables can be run at the same time: \n",
      "\n",
      "WARNING: You launched LFMM command line with several variables with '-a' option. The model will be\n",
      "\tlaunched with all variables at the same time.\n",
      "\t"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "The LFMM finished runing over night, this is what the output looks like in R: \n",
      "\n",
      "\n",
      "[1] \"********************************\"\n",
      "[1] \"* K = 8  repetition 1  d = 2   *\"\n",
      "[1] \"********************************\"\n",
      "Summary of the options:\n",
      "\n",
      "        -n (number of individuals)      383\n",
      "        -L (number of loci)             16681\n",
      "        -K (number of latent factors)   8\n",
      "        -o (output file)                LFMM2_Long_Lat.lfmm/K8/run1/LFMM2_r1\n",
      "        -i (number of iterations)       10000\n",
      "        -b (burnin)                     5000\n",
      "        -s (seed random init)           1231957180\n",
      "        -p (number of processes (CPU))  1\n",
      "        -x (genotype file)              LFMM2.lfmm\n",
      "        -v (variable file)              Long_Lat.env\n",
      "        -D (number of covariables)      2\n",
      "        -d (the dth covariable)         2\n",
      "        -m (missing data)                 \n",
      "\n",
      "Read variable file:\n",
      " \tLong_Lat.env\t\tOK.\n",
      "\n",
      "Read genotype file:\n",
      " \tLFMM2.lfmm\t\tOK.\n",
      "\n",
      "<<<<\n",
      "\t Analyse for variable 2\n",
      "\n",
      "\t\tStart of the Gibbs Sampler algorithm.\n",
      "\n",
      "\t[                                                                           ]\n",
      "\t[===========================================================================]\n",
      "\n",
      "\t\tEnd of the Gibbs Sampler algorithm.\n",
      "\n",
      "\tED:6388833.433\t DIC: 6388815.156 \n",
      "\n",
      "\tThe statistics for the run are registered in:\n",
      " \t\tLFMM2_Long_Lat.lfmm/K8/run1/LFMM2_r1_s2.8.dic.\n",
      "\n",
      "\tThe zscores for variable 2 are registered in:\n",
      " \t\tLFMM2_Long_Lat.lfmm/K8/run1/LFMM2_r1_s2.8.zscore.\n",
      "\tThe columns are: zscores, -log10(p-values), p-values.\n",
      "\n",
      "\t-------------------------\n",
      "\tThe execution for variable 2 worked without error.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Running LFMM on the Lineages\n",
      "Using the same method as above, I made 4 new input ped files to run LFMM on the individual lineages. I started with the genepop file, and deleted the populations that I was not interested in. \n",
      "\n",
      "- ASO_ped.ped \n",
      "- ASE_ped.ped\n",
      "- NAO_ped.ped\n",
      "- NAE_ped.ped\n",
      "\n",
      "The Environmental files were made the same way as above, and the R code was modeled on what was used on all the populations. Below are the 4 runs, one set of R commands for each of the lineages. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Performing LFMM analyis on population data\n",
      "###    using the package LEA from http://www.bioconductor.org/packages/release/bioc/html/LEA.html\n",
      "### Carolyn Tarpey | October 2015 \n",
      "### ---------------------------------------\n",
      "\n",
      "#set the working directory \n",
      "setwd(\"C:/Users/ctarpey/Desktop/LFMM_sm_runs/ASE\")\n",
      "\n",
      "library(LEA)\n",
      "\n",
      "#names of the populations in order\n",
      "names <- read.table(\"POPnames.txt\", row.names = 1 )\n",
      "\n",
      "#convert the edited ped file into the LFMM format\n",
      "ped2lfmm(\"ASE_ped.ped\",\"ASE_lfmm.lfmm\" )\n",
      "\n",
      "#convert the lfmm format into the genotype format\n",
      "ASEgenotype <- lfmm2geno(\"ASE_lfmm.lfmm\", \"ASE_geno.geno\")\n",
      "\n",
      "#figuring out K, the number of ancestral populations\n",
      "ASE.snmf = snmf(ASEgenotype, K = 1:4, entropy = TRUE, ploidy = 2, rep = 10, project = \"new\")\n",
      "\n",
      "#$$$$$$$$$$$$$$$$$\n",
      " \n",
      "#show and summarize the results \n",
      "show(ASE.snmf)\n",
      "summary(ASE.snmf)\n",
      "\n",
      "#Plotting the values of the cross-entropy criterion for each K; the value for which the function plateaus or increases is our estimate of K\n",
      "plot(ASE.snmf)\n",
      "\n",
      "#plot cross-entropy criterion of all runs of the project\n",
      "plot(ASE.snmf, lwd= 5, col = \"red\", pch=1)\n",
      "\n",
      "#to get the cross-entropy of each run for K = 4:8\n",
      "ce_1 <- cross.entropy(ASE.snmf, K= 1)\n",
      "ce_2 <- cross.entropy(ASE.snmf, K= 2)\n",
      "ce_3 <- cross.entropy(ASE.snmf, K= 3)\n",
      "ce_4 <- cross.entropy(ASE.snmf, K= 4)\n",
      "\n",
      "\n",
      "#select the run with the lowest cross-entropy \n",
      "best_1 <- which.min(ce_1)\n",
      "best_2 <- which.min(ce_2)\n",
      "best_3 <- which.min(ce_3)\n",
      "best_4 <- which.min(ce_4)\n",
      "\n",
      "\n",
      "#visualize a bar plot of ancestry coefficients \n",
      "windows(height=7, width=7)\n",
      "\n",
      "barplot(t(Q(ASE.snmf, K = 1, run = best_1)), col = 1)\n",
      "barplot(t(Q(ASE.snmf, K = 2, run = best_2)), col = 1:2)\n",
      "barplot(t(Q(ASE.snmf, K = 3, run = best_3)), col = 1:3)\n",
      "barplot(t(Q(ASE.snmf, K = 4, run = best_4)), col = 1:4)\n",
      "\n",
      "#genome scan for selection using env variables\n",
      "#running it with the standard longitude as the first variable and the stand lat as the second \n",
      "\n",
      "\n",
      "ASE.lfmm_LL_k1_d1_r5 <- lfmm(\"ASE_lfmm.lfmm\",\"ASE_lat_long.env\", project = \"continue\", \n",
      "                      K = 1,  all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                      iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "ASE.lfmm_LL_k2_d1_r5 <- lfmm(\"ASE_lfmm.lfmm\",\"ASE_lat_long.env\", project = \"continue\", \n",
      "                             K = 2,  all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "ASE.lfmm_LL_k1_d2_r5 <- lfmm(\"ASE_lfmm.lfmm\",\"ASE_lat_long.env\", project = \"continue\", \n",
      "                             K = 1,  all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "ASE.lfmm_LL_k2_d2_r5 <- lfmm(\"ASE_lfmm.lfmm\",\"ASE_lat_long.env\", project = \"continue\", \n",
      "                             K = 2,  all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "#genome scan for selection using env variables\n",
      "#running it with the temperature and precipitation variables\n",
      "########Repetition of 1\n",
      " \n",
      "#all pc axis together- one and two. \n",
      "  \n",
      "ASE.lfmm_PT_k1_all_r5 <- lfmm(\"ASE_lfmm.lfmm\",\"ASE_PT.env\", project = \"continue\", K = 1,  \n",
      "                            all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "                            iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "ASE.lfmm_PT_k2_all_r5 <- lfmm(\"ASE_lfmm.lfmm\",\"ASE_PT.env\", project = \"continue\", K = 2,  \n",
      "                              all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "                              iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "## pc axis one alone d= 1\n",
      "ASE.lfmm_PT_k1_d1_r5 <- lfmm(\"ASE_lfmm.lfmm\",\"ASE_PT.env\", project = \"continue\", K = 1,  \n",
      "                              all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                              iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "ASE.lfmm_PT_k2_d1_r5 <- lfmm(\"ASE_lfmm.lfmm\",\"ASE_PT.env\", project = \"continue\", K = 2,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "## pc axis two alone d = 2\n",
      "\n",
      "ASE.lfmm_PT_k1_d2_r5 <- lfmm(\"ASE_lfmm.lfmm\",\"ASE_PT.env\", project = \"continue\", K = 1,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "ASE.lfmm_PT_k2_d2_r5 <- lfmm(\"ASE_lfmm.lfmm\",\"ASE_PT.env\", project = \"continue\", K = 2,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "    #from here use the Post_process_LFMM.r code to process the output of these runs. \n",
      "  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Performing LFMM analyis on population data\n",
      "###    using the package LEA from http://www.bioconductor.org/packages/release/bioc/html/LEA.html\n",
      "### Carolyn Tarpey | October 2015 \n",
      "### ---------------------------------------\n",
      "\n",
      "#set the working directory \n",
      "setwd(\"C:/Users/ctarpey/Desktop/LFMM_sm_runs/ASO\")\n",
      "\n",
      "library(LEA)\n",
      "\n",
      "#names of the populations in order\n",
      "names <- read.table(\"POPnames.txt\", row.names = 1 )\n",
      "\n",
      "#convert the edited ped file into the LFMM format\n",
      "ped2lfmm(\"ASO_ped.ped\",\"ASO_lfmm.lfmm\" )\n",
      "\n",
      "#convert the lfmm format into the genotype format\n",
      "ASOgenotype <- lfmm2geno(\"ASO_lfmm.lfmm\", \"ASO_geno.geno\")\n",
      "\n",
      "#figuring out K, the number of ancestral populations\n",
      "ASO.snmf = snmf(ASOgenotype, K = 1:4, entropy = TRUE, ploidy = 2, rep = 10, project = \"new\")\n",
      "\n",
      "#$$$$$$$$$$$$$$$$$\n",
      "\n",
      "#show and summarize the results \n",
      "show(ASO.snmf)\n",
      "summary(ASO.snmf)\n",
      "\n",
      "#Plotting the values of the cross-entropy criterion for each K; the value for which the function plateaus or increases is our estimate of K\n",
      "plot(ASO.snmf)\n",
      "\n",
      "#plot cross-entropy criterion of all runs of the project\n",
      "plot(ASO.snmf, lwd= 5, col = \"red\", pch=1)\n",
      "\n",
      "#to get the cross-entropy of each run for K = 4:8\n",
      "ce_1 <- cross.entropy(ASO.snmf, K= 1)\n",
      "ce_2 <- cross.entropy(ASO.snmf, K= 2)\n",
      "ce_3 <- cross.entropy(ASO.snmf, K= 3)\n",
      "ce_4 <- cross.entropy(ASO.snmf, K= 4)\n",
      "\n",
      "#select the run with the lowest cross-entropy \n",
      "best_1 <- which.min(ce_1)\n",
      "best_2 <- which.min(ce_2)\n",
      "best_3 <- which.min(ce_3)\n",
      "best_4 <- which.min(ce_4)\n",
      "\n",
      "#visualize a bar plot of ancestry coefficients \n",
      "windows(height=7, width=7)\n",
      "\n",
      "barplot(t(Q(ASO.snmf, K = 1, run = best_1)), col = 1)\n",
      "barplot(t(Q(ASO.snmf, K = 2, run = best_2)), col = 1:2)\n",
      "barplot(t(Q(ASO.snmf, K = 3, run = best_3)), col = 1:3)\n",
      "barplot(t(Q(ASO.snmf, K = 4, run = best_4)), col = 1:4)\n",
      "\n",
      "#genome scan for selection using env variables\n",
      "#running it with the standard longitude as the first variable and the stand lat as the second \n",
      "\n",
      "\n",
      "ASO.lfmm_LL_k1_d1_r5 <- lfmm(\"ASO_lfmm.lfmm\",\"ASO_lat_long.env\", project = \"continue\", \n",
      "                             K = 1,  all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "ASO.lfmm_LL_k2_d1_r5 <- lfmm(\"ASO_lfmm.lfmm\",\"ASO_lat_long.env\", project = \"continue\", \n",
      "                             K = 2,  all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "ASO.lfmm_LL_k1_d2_r5 <- lfmm(\"ASO_lfmm.lfmm\",\"ASO_lat_long.env\", project = \"continue\", \n",
      "                             K = 1,  all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "ASO.lfmm_LL_k2_d2_r5 <- lfmm(\"ASO_lfmm.lfmm\",\"ASO_lat_long.env\", project = \"continue\", \n",
      "                             K = 2,  all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "#genome scan for selection using env variables\n",
      "#running it with the temperature and precipitation variables\n",
      "########Repetition of 1\n",
      "#all pc axis together- one and two. \n",
      "\n",
      "ASO.lfmm_PT_k1_all_r5 <- lfmm(\"ASO_lfmm.lfmm\",\"ASO_PT.env\", project = \"continue\", K = 1,  \n",
      "                              all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "                              iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "ASO.lfmm_PT_k2_all_r5 <- lfmm(\"ASO_lfmm.lfmm\",\"ASO_PT.env\", project = \"continue\", K = 2,  \n",
      "                              all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "                              iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "## pc axis one alone d= 1\n",
      "ASO.lfmm_PT_k1_d1_r5 <- lfmm(\"ASO_lfmm.lfmm\",\"ASO_PT.env\", project = \"continue\", K = 1,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "ASO.lfmm_PT_k2_d1_r5 <- lfmm(\"ASO_lfmm.lfmm\",\"ASO_PT.env\", project = \"continue\", K = 2,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "## pc axis two alone d = 2\n",
      "\n",
      "ASO.lfmm_PT_k1_d2_r5 <- lfmm(\"ASO_lfmm.lfmm\",\"ASO_PT.env\", project = \"continue\", K = 1,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "ASO.lfmm_PT_k2_d2_r5 <- lfmm(\"ASO_lfmm.lfmm\",\"ASO_PT.env\", project = \"continue\", K = 2,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      " #from here use the Post_process_LFMM.r code to process the output of these runs. "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Performing LFMM analyis on population data\n",
      "###    using the package LEA from http://www.bioconductor.org/packages/release/bioc/html/LEA.html\n",
      "### Carolyn Tarpey | October 2015 \n",
      "### ---------------------------------------\n",
      "\n",
      "#set the working directory \n",
      "setwd(\"C:/Users/ctarpey/Desktop/LFMM_sm_runs/NAE\")\n",
      "\n",
      "library(LEA)\n",
      "\n",
      "#names of the populations in order\n",
      "names <- read.table(\"POPnames.txt\", row.names = 1 )\n",
      "\n",
      "#convert the edited ped file into the LFMM format\n",
      "ped2lfmm(\"NAE_ped.ped\",\"NAE_lfmm.lfmm\" )\n",
      "\n",
      "#convert the lfmm format into the genotype format\n",
      "NAEgenotype <- lfmm2geno(\"NAE_lfmm.lfmm\", \"NAE_geno.geno\")\n",
      "\n",
      "#figuring out K, the number of ancestral populations\n",
      "NAE.snmf = snmf(NAEgenotype, K = 1:4, entropy = TRUE, ploidy = 2, rep = 10, project = \"new\")\n",
      "\n",
      "#$$$$$$$$$$$$$$$$$\n",
      "\n",
      "#show and summarize the results \n",
      "show(NAE.snmf)\n",
      "summary(NAE.snmf)\n",
      "\n",
      "#Plotting the values of the cross-entropy criterion for each K; the value for which the function plateaus or increases is our estimate of K\n",
      "plot(NAE.snmf)\n",
      "\n",
      "#plot cross-entropy criterion of all runs of the project\n",
      "plot(NAE.snmf, lwd= 5, col = \"red\", pch=1)\n",
      "\n",
      "#to get the cross-entropy of each run for K = 4:8\n",
      "ce_1 <- cross.entropy(NAE.snmf, K= 1)\n",
      "ce_2 <- cross.entropy(NAE.snmf, K= 2)\n",
      "ce_3 <- cross.entropy(NAE.snmf, K= 3)\n",
      "ce_4 <- cross.entropy(NAE.snmf, K= 4)\n",
      "\n",
      "#select the run with the lowest cross-entropy \n",
      "best_1 <- which.min(ce_1)\n",
      "best_2 <- which.min(ce_2)\n",
      "best_3 <- which.min(ce_3)\n",
      "best_4 <- which.min(ce_4)\n",
      "\n",
      "#visualize a bar plot of ancestry coefficients \n",
      "windows(height=7, width=7)\n",
      "\n",
      "barplot(t(Q(NAE.snmf, K = 1, run = best_1)), col = 1)\n",
      "barplot(t(Q(NAE.snmf, K = 2, run = best_2)), col = 1:2)\n",
      "barplot(t(Q(NAE.snmf, K = 3, run = best_3)), col = 1:3)\n",
      "barplot(t(Q(NAE.snmf, K = 4, run = best_4)), col = 1:4)\n",
      "\n",
      "#genome scan for selection using env variables\n",
      "#running it with the standard longitude as the first variable and the stand lat as the second \n",
      "\n",
      "NAE.lfmm_LL_k1_d1_r5 <- lfmm(\"NAE_lfmm.lfmm\",\"NAE_long_lat_PT_2.env\", project = \"continue\", \n",
      "                             K = 1,  all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "NAE.lfmm_LL_k2_d1_r5 <- lfmm(\"NAE_lfmm.lfmm\",\"NAE_long_lat_PT_2.env\", project = \"continue\", \n",
      "                             K = 2,  all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "NAE.lfmm_LL_k1_d2_r5 <- lfmm(\"NAE_lfmm.lfmm\",\"NAE_long_lat_PT_2.env\", project = \"continue\", \n",
      "                             K = 1,  all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "NAE.lfmm_LL_k2_d2_r5 <- lfmm(\"NAE_lfmm.lfmm\",\"NAE_long_lat_PT_2.env\", project = \"continue\", \n",
      "                             K = 2,  all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "#genome scan for selection using env variables\n",
      "#running it with the temperature and precipitation variables\n",
      "########Repetition of 1\n",
      "#all pc axis together- one and two. \n",
      "\n",
      "NAE.lfmm_PT_k1_all_r5 <- lfmm(\"NAE_lfmm.lfmm\",\"NAE_PT_2.env\", project = \"continue\", K = 1,  \n",
      "                              all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "                              iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "NAE.lfmm_PT_k2_all_r5 <- lfmm(\"NAE_lfmm.lfmm\",\"NAE_PT_2.env\", project = \"continue\", K = 2,  \n",
      "                              all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "                              iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "## pc axis one alone d= 1\n",
      "NAE.lfmm_PT_k1_d1_r5 <- lfmm(\"NAE_lfmm.lfmm\",\"NAE_PT_2.env\", project = \"continue\", K = 1,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "ASE.lfmm_PT_k2_d1_r5 <- lfmm(\"NAE_lfmm.lfmm\",\"NAE_PT_2.env\", project = \"continue\", K = 2,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "## pc axis two alone d = 2\n",
      "\n",
      "NAE.lfmm_PT_k1_d2_r5 <- lfmm(\"NAE_lfmm.lfmm\",\"NAE_PT_2.env\", project = \"continue\", K = 1,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "NAE.lfmm_PT_k2_d2_r5 <- lfmm(\"NAE_lfmm.lfmm\",\"NAE_PT_2.env\", project = \"continue\", K = 2,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ \n",
      "#from here use the Post_process_LFMM.r code to process the output of these runs.  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Performing LFMM analyis on population data\n",
      "###    using the package LEA from http://www.bioconductor.org/packages/release/bioc/html/LEA.html\n",
      "### Carolyn Tarpey | October 2015 \n",
      "### ---------------------------------------\n",
      "\n",
      "#set the working directory \n",
      "setwd(\"C:/Users/ctarpey/Desktop/LFMM_sm_runs/NAO\")\n",
      "\n",
      "library(LEA)\n",
      "\n",
      "#names of the populations in order\n",
      "names <- read.table(\"POPnames.txt\", row.names = 1 )\n",
      "\n",
      "\n",
      "#convert the edited ped file into the LFMM format\n",
      "ped2lfmm(\"NAO_ped.ped\",\"NAO_lfmm.lfmm\" )\n",
      "\n",
      "#convert the lfmm format into the genotype format\n",
      "NAOgenotype <- lfmm2geno(\"NAO_lfmm.lfmm\", \"NAO_geno.geno\")\n",
      "\n",
      "#figuring out K, the number of ancestral populations\n",
      "NAO.snmf = snmf(NAOgenotype, K = 1:4, entropy = TRUE, ploidy = 2, rep = 10, project = \"new\")\n",
      "\n",
      "#$$$$$$$$$$$$$$$$\n",
      "\n",
      "#show and summarize the results \n",
      "show(NAO.snmf)\n",
      "summary(NAO.snmf)\n",
      "\n",
      "#Plotting the values of the cross-entropy criterion for each K; the value for which the function plateaus or increases is our estimate of K\n",
      "plot(NAO.snmf)\n",
      "\n",
      "#plot cross-entropy criterion of all runs of the project\n",
      "plot(NAO.snmf, lwd= 5, col = \"red\", pch=1)\n",
      "\n",
      "#to get the cross-entropy of each run for K = 4:8\n",
      "ce_1 <- cross.entropy(NAO.snmf, K= 1)\n",
      "ce_2 <- cross.entropy(NAO.snmf, K= 2)\n",
      "ce_3 <- cross.entropy(NAO.snmf, K= 3)\n",
      "ce_4 <- cross.entropy(NAO.snmf, K= 4)\n",
      "\n",
      "#select the run with the lowest cross-entropy \n",
      "best_1 <- which.min(ce_1)\n",
      "best_2 <- which.min(ce_2)\n",
      "best_3 <- which.min(ce_3)\n",
      "best_4 <- which.min(ce_4)\n",
      "\n",
      "#visualize a bar plot of ancestry coefficients \n",
      "windows(height=7, width=7)\n",
      "\n",
      "barplot(t(Q(NAO.snmf, K = 1, run = best_1)), col = 1)\n",
      "barplot(t(Q(NAO.snmf, K = 2, run = best_2)), col = 1:2)\n",
      "barplot(t(Q(NAO.snmf, K = 3, run = best_3)), col = 1:3)\n",
      "barplot(t(Q(NAO.snmf, K = 4, run = best_4)), col = 1:4)\n",
      "\n",
      "#genome scan for selection using env variables\n",
      "#running it with the standard longitude as the first variable and the stand lat as the second \n",
      "\n",
      "\n",
      "NAO.lfmm_LL_k2_d1_r5 <- lfmm(\"NAO_lfmm.lfmm\",\"NAO_long_lat_PT.env\", project = \"continue\", \n",
      "                             K = 2,  all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "NAO.lfmm_LL_k3_d1_r5 <- lfmm(\"NAO_lfmm.lfmm\",\"NAO_long_lat_PT.env\", project = \"continue\", \n",
      "                             K = 3,  all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "NAO.lfmm_LL_k3_d2_r5 <- lfmm(\"NAO_lfmm.lfmm\",\"NAO_long_lat_PT.env\", project = \"continue\", \n",
      "                             K = 3,  all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "NAO.lfmm_LL_k2_d2_r5 <- lfmm(\"NAO_lfmm.lfmm\",\"NAO_long_lat_PT.env\", project = \"continue\", \n",
      "                             K = 2,  all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "#genome scan for selection using env variables\n",
      "#running it with the temperature and precipitation variables\n",
      "########Repetition of 1\n",
      "#all pc axis together- one and two. \n",
      "\n",
      "NAO.lfmm_PT_k3_all_r5 <- lfmm(\"NAO_lfmm.lfmm\",\"NAO_PT.env\", project = \"continue\", K = 3,  \n",
      "                              all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "                              iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "NAO.lfmm_PT_k2_all_r5 <- lfmm(\"NAO_lfmm.lfmm\",\"NAO_PT.env\", project = \"continue\", K = 2,  \n",
      "                              all = TRUE, missing.data = TRUE, CPU = 1, \n",
      "                              iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "## pc axis one alone d= 1\n",
      "NAO.lfmm_PT_k3_d1_r5 <- lfmm(\"NAO_lfmm.lfmm\",\"NAO_PT.env\", project = \"continue\", K = 3,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "NAO.lfmm_PT_k2_d1_r5 <- lfmm(\"NAO_lfmm.lfmm\",\"NAO_PT.env\", project = \"continue\", K = 2,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 1, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "## pc axis two alone d = 2\n",
      "\n",
      "NAO.lfmm_PT_k3_d2_r5 <- lfmm(\"NAO_lfmm.lfmm\",\"NAO_PT.env\", project = \"continue\", K = 3,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "NAO.lfmm_PT_k2_d2_r5 <- lfmm(\"NAO_lfmm.lfmm\",\"NAO_PT.env\", project = \"continue\", K = 2,  \n",
      "                             all = FALSE, missing.data = TRUE, CPU = 1, d = 2, \n",
      "                             iterations = 10000, burnin = 5000, repetitions = 5)\n",
      "\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "#from here use the Post_process_LFMM.r code to process the output of these runs. "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Post anlysis of the LFMM runs\n",
      "The explanation for the code for post analysis on the LEA website is that it combines the individual runs and makes a joint P-value. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I had some issues with the post analysis because I ran the LFMM on a separate computer, and the R code of the results has the file paths hard coded in. When I move the files, even if the hierarchy is maintianed, R cant find the necessary files. This is the error that I got: \n",
      "\n",
      "> project_LL <- load.snmfProject(\"LFMM_in_Long_Lat_5_new.lfmmProject\")\n",
      "Error in load.snmfProject(\"LFMM_in_Long_Lat_5_new.lfmmProject\") :   no slot of name \"snmfClass.files\" for this object of class \"lfmmProject\"\n",
      "\n",
      "I had to return to the file where they were run and recreate the original file structure. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Performing LFMM analyis on population data\n",
      "###    using the package LEA from http://www.bioconductor.org/packages/release/bioc/html/LEA.html\n",
      "### Carolyn Tarpey | October 2015 \n",
      "### ---------------------------------------\n",
      "source(\"https://bioconductor.org/biocLite.R\")\n",
      "biocLite()\n",
      "biocLite(\"LEA\")\n",
      "library(LEA)\n",
      "\n",
      "#The lfmm function returns a project object containing all lfmm runs. \n",
      "#When performing additional runs, the function enables the project to be included as a parameter \n",
      "#to add more runs. Performing several runs for various values of the number of latent factors (K) \n",
      "#is recommended. \n",
      "#these are the steps listed in the manual for post-processing the LFMM runs: \n",
      "#setwd(\"U:/LFMM\")\n",
      "#setwd(\"G:/Analysis/Pop_analysis/Populations_b3_may/LFMM/LFMM_complete\")\n",
      "setwd(\"C:/Users/ctarpey/Desktop/copy_of_Udrive/LFMM_complete\")\n",
      "\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ LATITUDE and LONGITUDE\n",
      "\n",
      "#to load project, use:\n",
      "project_LL <- load.lfmmProject(\"LFMM_in_Long_Lat_5_new.lfmmProject\")\n",
      "\n",
      "# show the project\n",
      "show(project_LL)\n",
      "\n",
      "# summary of the project\n",
      "summary(project_LL)\n",
      "\n",
      "# get the zscores of each run for K \n",
      "zs_4_LL = z.scores(project_LL, d = 1, K = 4)\n",
      "zs_5_LL = z.scores(project_LL, d = 1, K = 5)\n",
      "zs_6_LL = z.scores(project_LL, d = 1 ,K = 6)\n",
      "\n",
      "zs_4_LL_2 = z.scores(project_LL, d = 2, K = 4)\n",
      "zs_5_LL_2 = z.scores(project_LL, d = 2, K = 5)\n",
      "zs_6_LL_2 = z.scores(project_LL, d = 2 ,K = 6)\n",
      "\n",
      "# Combine the z-scores using the Stouffer method\n",
      "zs_4.stouffer_LL = apply(zs_4_LL, MARGIN = 1, median)\n",
      "zs_5.stouffer_LL = apply(zs_5_LL, MARGIN = 1, median)\n",
      "zs_6.stouffer_LL = apply(zs_6_LL, MARGIN = 1, median)\n",
      "\n",
      "zs_4.stouffer_LL_2 = apply(zs_4_LL, MARGIN = 1, median)\n",
      "zs_5.stouffer_LL_2 = apply(zs_5_LL, MARGIN = 1, median)\n",
      "zs_6.stouffer_LL_2 = apply(zs_6_LL, MARGIN = 1, median)\n",
      "\n",
      "# calculate the inflation factor\n",
      "lambda_4_LL = median(zs_4.stouffer_LL^2)/.456\n",
      "lambda_5_LL = median(zs_5.stouffer_LL^2)/.456\n",
      "lambda_6_LL = median(zs_6.stouffer_LL^2)/.456\n",
      "\n",
      "lambda_4_LL_2 = median(zs_4.stouffer_LL_2^2)/.456\n",
      "lambda_5_LL_2 = median(zs_5.stouffer_LL_2^2)/.456\n",
      "lambda_6_LL_2 = median(zs_6.stouffer_LL_2^2)/.456\n",
      "\n",
      "# calculate adjusted p-values\n",
      "cp_4.values_LL = pchisq(zs_4.stouffer_LL^2/lambda_4_LL, df = 1, lower = FALSE)\n",
      "cp_5.values_LL = pchisq(zs_5.stouffer_LL^2/lambda_5_LL, df = 1, lower = FALSE)\n",
      "cp_6.values_LL = pchisq(zs_6.stouffer_LL^2/lambda_6_LL, df = 1, lower = FALSE)\n",
      "\n",
      "cp_4.values_LL_2 = pchisq(zs_4.stouffer_LL_2^2/lambda_4_LL_2, df = 1, lower = FALSE)\n",
      "cp_5.values_LL_2 = pchisq(zs_5.stouffer_LL_2^2/lambda_5_LL_2, df = 1, lower = FALSE)\n",
      "cp_6.values_LL_2 = pchisq(zs_6.stouffer_LL_2^2/lambda_6_LL_2, df = 1, lower = FALSE)\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 4 expected FDR:\", alpha))\n",
      "  L = length(cp_4.values_LL)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_4.values_LL) < alpha * (1:L) / L)\n",
      "  candidates_LL = order(cp_4.values_LL)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates_LL <= 350))/length(candidates_LL)\n",
      "  estimated.TP_LL = length(which(candidates_LL > 350))/50\n",
      "  print(paste(\"k = 4 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 5 expected FDR:\", alpha))\n",
      "  L = length(cp_5.values_LL)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_5.values_LL) < alpha * (1:L) / L)\n",
      "  candidates_LL = order(cp_5.values_LL)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates_LL <= 350))/length(candidates_LL)\n",
      "  estimated.TP_LL = length(which(candidates_LL > 350))/50\n",
      "  print(paste(\"K = 5 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 6 expected FDR:\", alpha))\n",
      "  L = length(cp_6.values_LL)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_6.values_LL) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_6.values_LL)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP_LL = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 6 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 4 expected FDR:\", alpha))\n",
      "  L = length(cp_4.values_LL_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_4.values_LL_2) < alpha * (1:L) / L)\n",
      "  candidates_LL = order(cp_4.values_LL_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates_LL <= 350))/length(candidates_LL)\n",
      "  estimated.TP_LL = length(which(candidates_LL > 350))/50\n",
      "  print(paste(\"k = 4 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 5 expected FDR:\", alpha))\n",
      "  L = length(cp_5.values_LL_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_5.values_LL_2) < alpha * (1:L) / L)\n",
      "  candidates_LL = order(cp_5.values_LL_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates_LL <= 350))/length(candidates_LL)\n",
      "  estimated.TP_LL = length(which(candidates_LL > 350))/50\n",
      "  print(paste(\"K = 5 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 6 expected FDR:\", alpha))\n",
      "  L = length(cp_6.values_LL_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_6.values_LL_2) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_6.values_LL_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP_LL = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 6 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ PRECIPITATION and TEMPERATURE\n",
      "#to load project, use:\n",
      "project_PT <- load.lfmmProject(\"LFMM_in_precip_temp_all.lfmmProject\")\n",
      "\n",
      "# show the project\n",
      "show(project_PT)\n",
      "\n",
      "# summary of the project\n",
      "summary(project_PT)\n",
      "\n",
      "# get the zscores of each run for K \n",
      "zs_4_PT = z.scores(project_PT, d = 1, K = 4)\n",
      "zs_5_PT = z.scores(project_PT, d = 1, K = 5)\n",
      "zs_6_PT = z.scores(project_PT, d = 1 ,K = 6)\n",
      "\n",
      "zs_4_PT_2 = z.scores(project_PT, d = 2, K = 4)\n",
      "zs_5_PT_2 = z.scores(project_PT, d = 2, K = 5)\n",
      "zs_6_PT_2 = z.scores(project_PT, d = 2, K = 6)\n",
      "\n",
      "# Combine the z-scores using the Stouffer method\n",
      "zs_4.stouffer_PT = apply(zs_4_PT, MARGIN = 1, median)\n",
      "zs_5.stouffer_PT = apply(zs_5_PT, MARGIN = 1, median)\n",
      "zs_6.stouffer_PT = apply(zs_6_PT, MARGIN = 1, median)\n",
      "\n",
      "zs_4.stouffer_PT_2 = apply(zs_4_PT, MARGIN = 1, median)\n",
      "zs_5.stouffer_PT_2 = apply(zs_5_PT, MARGIN = 1, median)\n",
      "zs_6.stouffer_PT_2 = apply(zs_6_PT, MARGIN = 1, median)\n",
      "\n",
      "# calculate the inflation factor\n",
      "lambda_4_PT = median(zs_4.stouffer_PT^2)/.456\n",
      "lambda_5_PT = median(zs_5.stouffer_PT^2)/.456\n",
      "lambda_6_PT = median(zs_6.stouffer_PT^2)/.456\n",
      "\n",
      "lambda_4_PT_2 = median(zs_4.stouffer_PT_2^2)/.456\n",
      "lambda_5_PT_2 = median(zs_5.stouffer_PT_2^2)/.456\n",
      "lambda_6_PT_2 = median(zs_6.stouffer_PT_2^2)/.456\n",
      "\n",
      "# calculate adjusted p-values\n",
      "cp_4.values_PT = pchisq(zs_4.stouffer_PT^2/lambda_4_PT, df = 1, lower = FALSE)\n",
      "cp_5.values_PT = pchisq(zs_5.stouffer_PT^2/lambda_5_PT, df = 1, lower = FALSE)\n",
      "cp_6.values_PT = pchisq(zs_6.stouffer_PT^2/lambda_6_PT, df = 1, lower = FALSE)\n",
      "\n",
      "cp_4.values_PT_2 = pchisq(zs_4.stouffer_PT_2^2/lambda_4_PT_2, df = 1, lower = FALSE)\n",
      "cp_5.values_PT_2 = pchisq(zs_5.stouffer_PT_2^2/lambda_5_PT_2, df = 1, lower = FALSE)\n",
      "cp_6.values_PT_2 = pchisq(zs_6.stouffer_PT_2^2/lambda_6_PT_2, df = 1, lower = FALSE)\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 4 expected FDR:\", alpha))\n",
      "  L = length(cp_4.values_PT)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_4.values_PT) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_4.values_PT)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"k = 4 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 5 expected FDR:\", alpha))\n",
      "  L = length(cp_5.values_PT)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_5.values_PT) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_5.values_PT)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 5 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 6 expected FDR:\", alpha))\n",
      "  L = length(cp_6.values_PT)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_6.values_PT) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_6.values_PT)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 6 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 4 expected FDR:\", alpha))\n",
      "  L = length(cp_4.values_PT_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_4.values_PT_2) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_4.values_PT_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"k = 4 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 5 expected FDR:\", alpha))\n",
      "  L = length(cp_5.values_PT_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_5.values_PT_2) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_5.values_PT_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 5 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 6 expected FDR:\", alpha))\n",
      "  L = length(cp_6.values_PT_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_6.values_PT_2) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_6.values_PT_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 6 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Performing LFMM analyis on population data\n",
      "###    using the package LEA from http://www.bioconductor.org/packages/release/bioc/html/LEA.html\n",
      "### Carolyn Tarpey | October 2015 \n",
      "### ---------------------------------------\n",
      "library(LEA)\n",
      "#The lfmm function returns a project object containing all lfmm runs. \n",
      "#When performing additional runs, the function enables the project to be included as a parameter \n",
      "#to add more runs. Performing several runs for various values of the number of latent factors (K) \n",
      "#is recommended. \n",
      "#these are the steps listed in the manual for post-processing the LFMM runs: \n",
      "setwd(\"C:/Users/ctarpey/Desktop/LFMM_sm_runs/ASE\")\n",
      "\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ LATITUDE and LONGITUDE\n",
      "\n",
      "#to load project, use:\n",
      "project_LL <- load.lfmmProject(\"ASE_lfmm_ASE_lat_long.lfmmProject\")\n",
      "\n",
      "# show the project\n",
      "show(project_LL)\n",
      "\n",
      "# summary of the project\n",
      "summary(project_LL)\n",
      "\n",
      "# get the zscores of each run for K \n",
      "zs_1_LL = z.scores(project_LL, d = 1, K = 1)\n",
      "zs_2_LL = z.scores(project_LL, d = 1, K = 2)\n",
      "\n",
      "zs_1_LL_2 = z.scores(project_LL, d = 2, K = 1)\n",
      "zs_2_LL_2 = z.scores(project_LL, d = 2, K = 2)\n",
      "\n",
      "# Combine the z-scores using the Stouffer method\n",
      "zs_1.stouffer_LL = apply(zs_1_LL, MARGIN = 1, median)\n",
      "zs_2.stouffer_LL = apply(zs_2_LL, MARGIN = 1, median)\n",
      "\n",
      "zs_1.stouffer_LL_2 = apply(zs_1_LL, MARGIN = 1, median)\n",
      "zs_2.stouffer_LL_2 = apply(zs_2_LL, MARGIN = 1, median)\n",
      "\n",
      "# calculate the inflation factor\n",
      "lambda_1_LL = median(zs_1.stouffer_LL^2)/.456\n",
      "lambda_2_LL = median(zs_2.stouffer_LL^2)/.456\n",
      "\n",
      "lambda_1_LL_2 = median(zs_1.stouffer_LL_2^2)/.456\n",
      "lambda_2_LL_2 = median(zs_2.stouffer_LL_2^2)/.456\n",
      "\n",
      "# calculate adjusted p-values\n",
      "cp_1.values_LL = pchisq(zs_1.stouffer_LL^2/lambda_1_LL, df = 1, lower = FALSE)\n",
      "cp_2.values_LL = pchisq(zs_2.stouffer_LL^2/lambda_2_LL, df = 1, lower = FALSE)\n",
      "\n",
      "cp_1.values_LL_2 = pchisq(zs_1.stouffer_LL_2^2/lambda_1_LL_2, df = 1, lower = FALSE)\n",
      "cp_2.values_LL_2 = pchisq(zs_2.stouffer_LL_2^2/lambda_2_LL_2, df = 1, lower = FALSE)\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 1 expected FDR:\", alpha))\n",
      "  L = length(cp_1.values_LL)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_1.values_LL) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_1.values_LL)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 1 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_LL)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_LL) < alpha * (1:L) / L)\n",
      "  candidates_LL = order(cp_2.values_LL)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates_LL <= 350))/length(candidates_LL)\n",
      "  estimated.TP_LL = length(which(candidates_LL > 350))/50\n",
      "  print(paste(\"k = 2 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 1 expected FDR:\", alpha))\n",
      "  L = length(cp_1.values_LL_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_1.values_LL_2) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_1.values_LL_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 1 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_LL_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_LL_2) < alpha * (1:L) / L)\n",
      "  candidates_LL = order(cp_2.values_LL_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates_LL <= 350))/length(candidates_LL)\n",
      "  estimated.TP_LL = length(which(candidates_LL > 350))/50\n",
      "  print(paste(\"k = 2 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ PRECIPITATION and TEMPERATURE\n",
      "\n",
      "#to load project, use:\n",
      "project_PT <- load.lfmmProject(\"ASE_lfmm_ASE_PT.lfmmProject\")\n",
      "\n",
      "# show the project\n",
      "show(project_PT)\n",
      "\n",
      "# summary of the project\n",
      "summary(project_PT)\n",
      "\n",
      "# get the zscores of each run for K \n",
      "zs_1_PT = z.scores(project_PT, d = 1, K = 1)\n",
      "zs_2_PT = z.scores(project_PT, d = 1, K = 2)\n",
      "\n",
      "zs_1_PT_2 = z.scores(project_PT, d = 2, K = 1)\n",
      "zs_2_PT_2 = z.scores(project_PT, d = 2, K = 2)\n",
      "\n",
      "# Combine the z-scores using the Stouffer method\n",
      "zs_1.stouffer_PT = apply(zs_1_PT, MARGIN = 1, median)\n",
      "zs_2.stouffer_PT = apply(zs_2_PT, MARGIN = 1, median)\n",
      "\n",
      "zs_1.stouffer_PT_2 = apply(zs_1_PT, MARGIN = 1, median)\n",
      "zs_2.stouffer_PT_2 = apply(zs_2_PT, MARGIN = 1, median)\n",
      "\n",
      "# calculate the inflation factor\n",
      "lambda_1_PT = median(zs_1.stouffer_PT^2)/.456\n",
      "lambda_2_PT = median(zs_2.stouffer_PT^2)/.456\n",
      "\n",
      "lambda_1_PT_2 = median(zs_1.stouffer_PT_2^2)/.456\n",
      "lambda_2_PT_2 = median(zs_2.stouffer_PT_2^2)/.456\n",
      "\n",
      "# calculate adjusted p-values\n",
      "cp_1.values_PT = pchisq(zs_1.stouffer_PT^2/lambda_1_PT, df = 1, lower = FALSE)\n",
      "cp_2.values_PT = pchisq(zs_2.stouffer_PT^2/lambda_2_PT, df = 1, lower = FALSE)\n",
      "\n",
      "cp_1.values_PT_2 = pchisq(zs_1.stouffer_PT_2^2/lambda_1_PT_2, df = 1, lower = FALSE)\n",
      "cp_2.values_PT_2 = pchisq(zs_2.stouffer_PT_2^2/lambda_2_PT_2, df = 1, lower = FALSE)\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 1 expected FDR:\", alpha))\n",
      "  L = length(cp_1.values_PT)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_1.values_PT) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_1.values_PT)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"k = 1 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_PT)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_PT) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_2.values_PT)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 2 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 1 expected FDR:\", alpha))\n",
      "  L = length(cp_1.values_PT_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_1.values_PT_2) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_1.values_PT_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"k = 1 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_PT_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_PT_2) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_2.values_PT_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 2 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Performing LFMM analyis on population data\n",
      "###    using the package LEA from http://www.bioconductor.org/packages/release/bioc/html/LEA.html\n",
      "### Carolyn Tarpey | October 2015 \n",
      "### ---------------------------------------\n",
      "library(LEA)\n",
      "\n",
      "#The lfmm function returns a project object containing all lfmm runs. \n",
      "#When performing additional runs, the function enables the project to be included as a parameter \n",
      "#to add more runs. Performing several runs for various values of the number of latent factors (K) \n",
      "#is recommended. \n",
      "#these are the steps listed in the manual for post-processing the LFMM runs: \n",
      "setwd(\"C:/Users/ctarpey/Desktop/LFMM_sm_runs/ASO\")\n",
      "\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ LATITUDE and LONGITUDE\n",
      "\n",
      "#to load project, use:\n",
      "project_LL <- load.lfmmProject(\"ASO_lfmm_ASO_lat_long.lfmmProject\")\n",
      "\n",
      "# show the project\n",
      "show(project_LL)\n",
      "\n",
      "# summary of the project\n",
      "summary(project_LL)\n",
      "\n",
      "# get the zscores of each run for K \n",
      "zs_1_LL = z.scores(project_LL, d = 1, K = 1)\n",
      "zs_2_LL = z.scores(project_LL, d = 1, K = 2)\n",
      "\n",
      "zs_1_LL_2 = z.scores(project_LL, d = 2, K = 1)\n",
      "zs_2_LL_2 = z.scores(project_LL, d = 2, K = 2)\n",
      "\n",
      "# Combine the z-scores using the Stouffer method\n",
      "zs_1.stouffer_LL = apply(zs_1_LL, MARGIN = 1, median)\n",
      "zs_2.stouffer_LL = apply(zs_2_LL, MARGIN = 1, median)\n",
      "\n",
      "zs_1.stouffer_LL_2 = apply(zs_1_LL, MARGIN = 1, median)\n",
      "zs_2.stouffer_LL_2 = apply(zs_2_LL, MARGIN = 1, median)\n",
      "\n",
      "# calculate the inflation factor\n",
      "lambda_1_LL = median(zs_1.stouffer_LL^2)/.456\n",
      "lambda_2_LL = median(zs_2.stouffer_LL^2)/.456\n",
      "\n",
      "lambda_1_LL_2 = median(zs_1.stouffer_LL_2^2)/.456\n",
      "lambda_2_LL_2 = median(zs_2.stouffer_LL_2^2)/.456\n",
      "\n",
      "# calculate adjusted p-values\n",
      "cp_1.values_LL = pchisq(zs_1.stouffer_LL^2/lambda_1_LL, df = 1, lower = FALSE)\n",
      "cp_2.values_LL = pchisq(zs_2.stouffer_LL^2/lambda_2_LL, df = 1, lower = FALSE)\n",
      "\n",
      "cp_1.values_LL_2 = pchisq(zs_1.stouffer_LL_2^2/lambda_1_LL_2, df = 1, lower = FALSE)\n",
      "cp_2.values_LL_2 = pchisq(zs_2.stouffer_LL_2^2/lambda_2_LL_2, df = 1, lower = FALSE)\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 4 expected FDR:\", alpha))\n",
      "  L = length(cp_4.values_LL)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_4.values_LL) < alpha * (1:L) / L)\n",
      "  candidates_LL = order(cp_4.values_LL)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates_LL <= 350))/length(candidates_LL)\n",
      "  estimated.TP_LL = length(which(candidates_LL > 350))/50\n",
      "  print(paste(\"k = 4 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 1 expected FDR:\", alpha))\n",
      "  L = length(cp_1.values_LL)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_1.values_LL) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_1.values_LL)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 1 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 1 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_LL)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_LL) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_2.values_LL)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 2 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_1.values_LL_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_1.values_LL_2) < alpha * (1:L) / L)\n",
      "  candidates_LL = order(cp_1.values_LL_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates_LL <= 350))/length(candidates_LL)\n",
      "  estimated.TP_LL = length(which(candidates_LL > 350))/50\n",
      "  print(paste(\"k = 1 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_LL_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_LL_2) < alpha * (1:L) / L)\n",
      "  candidates_LL = order(cp_2.values_LL_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates_LL <= 350))/length(candidates_LL)\n",
      "  estimated.TP_LL = length(which(candidates_LL > 350))/50\n",
      "  print(paste(\"k = 2 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ PRECIPITATION and TEMPERATURE\n",
      "#to load project, use:\n",
      "project_PT <- load.lfmmProject(\"ASO_lfmm_ASO_PT.lfmmProject\")\n",
      "\n",
      "# show the project\n",
      "show(project_PT)\n",
      "\n",
      "# summary of the project\n",
      "summary(project_PT)\n",
      "\n",
      "# get the zscores of each run for K \n",
      "zs_1_PT = z.scores(project_PT, d = 1, K = 1)\n",
      "zs_2_PT = z.scores(project_PT, d = 1, K = 2)\n",
      "\n",
      "zs_1_PT_2 = z.scores(project_PT, d = 2, K = 1)\n",
      "zs_2_PT_2 = z.scores(project_PT, d = 2, K = 2)\n",
      "\n",
      "# Combine the z-scores using the Stouffer method\n",
      "zs_1.stouffer_PT = apply(zs_1_PT, MARGIN = 1, median)\n",
      "zs_2.stouffer_PT = apply(zs_2_PT, MARGIN = 1, median)\n",
      "\n",
      "zs_1.stouffer_PT_2 = apply(zs_1_PT, MARGIN = 1, median)\n",
      "zs_2.stouffer_PT_2 = apply(zs_2_PT, MARGIN = 1, median)\n",
      "\n",
      "# calculate the inflation factor\n",
      "lambda_1_PT = median(zs_1.stouffer_PT^2)/.456\n",
      "lambda_2_PT = median(zs_2.stouffer_PT^2)/.456\n",
      "\n",
      "lambda_1_PT_2 = median(zs_1.stouffer_PT_2^2)/.456\n",
      "lambda_2_PT_2 = median(zs_2.stouffer_PT_2^2)/.456\n",
      "\n",
      "# calculate adjusted p-values\n",
      "cp_1.values_PT = pchisq(zs_1.stouffer_PT^2/lambda_1_PT, df = 1, lower = FALSE)\n",
      "cp_2.values_PT = pchisq(zs_2.stouffer_PT^2/lambda_2_PT, df = 1, lower = FALSE)\n",
      "\n",
      "cp_1.values_PT_2 = pchisq(zs_1.stouffer_PT_2^2/lambda_1_PT_2, df = 1, lower = FALSE)\n",
      "cp_2.values_PT_2 = pchisq(zs_2.stouffer_PT_2^2/lambda_2_PT_2, df = 1, lower = FALSE)\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 1 expected FDR:\", alpha))\n",
      "  L = length(cp_1.values_PT)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_1.values_PT) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_1.values_PT)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"k = 1 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_PT)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_PT) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_2.values_PT)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 2 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 1 expected FDR:\", alpha))\n",
      "  L = length(cp_1.values_PT_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_1.values_PT_2) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_1.values_PT_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"k = 1 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_PT_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_PT_2) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_2.values_PT_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 2 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Performing LFMM analyis on population data\n",
      "###    using the package LEA from http://www.bioconductor.org/packages/release/bioc/html/LEA.html\n",
      "### Carolyn Tarpey | October 2015 \n",
      "### ---------------------------------------\n",
      "library(LEA)\n",
      "\n",
      "#The lfmm function returns a project object containing all lfmm runs. \n",
      "#When performing additional runs, the function enables the project to be included as a parameter \n",
      "#to add more runs. Performing several runs for various values of the number of latent factors (K) \n",
      "#is recommended. \n",
      "#these are the steps listed in the manual for post-processing the LFMM runs: \n",
      "\n",
      "setwd(\"C:/Users/ctarpey/Desktop/LFMM_sm_runs/NAE\")\n",
      "\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ LATITUDE and LONGITUDE\n",
      "\n",
      "#to load project, use:\n",
      "project_LL <- load.lfmmProject(\"NAE_lfmm_NAE_long_lat_PT_2.lfmmProject\")\n",
      "\n",
      "# show the project\n",
      "show(project_LL)\n",
      "\n",
      "# summary of the project\n",
      "summary(project_LL)\n",
      "\n",
      "# get the zscores of each run for K \n",
      "zs_1_LL = z.scores(project_LL, d = 1, K = 1)\n",
      "zs_2_LL = z.scores(project_LL, d = 1, K = 2)\n",
      "\n",
      "zs_1_LL_2 = z.scores(project_LL, d = 2, K = 1)\n",
      "zs_2_LL_2 = z.scores(project_LL, d = 2, K = 2)\n",
      "\n",
      "# Combine the z-scores using the Stouffer method\n",
      "zs_1.stouffer_LL = apply(zs_1_LL, MARGIN = 1, median)\n",
      "zs_2.stouffer_LL = apply(zs_2_LL, MARGIN = 1, median)\n",
      "\n",
      "zs_1.stouffer_LL_2 = apply(zs_1_LL, MARGIN = 1, median)\n",
      "zs_2.stouffer_LL_2 = apply(zs_2_LL, MARGIN = 1, median)\n",
      "\n",
      "# calculate the inflation factor\n",
      "lambda_1_LL = median(zs_1.stouffer_LL^2)/.456\n",
      "lambda_2_LL = median(zs_2.stouffer_LL^2)/.456\n",
      "\n",
      "lambda_1_LL_2 = median(zs_1.stouffer_LL_2^2)/.456\n",
      "lambda_2_LL_2 = median(zs_2.stouffer_LL_2^2)/.456\n",
      "\n",
      "# calculate adjusted p-values\n",
      "cp_1.values_LL = pchisq(zs_1.stouffer_LL^2/lambda_1_LL, df = 1, lower = FALSE)\n",
      "cp_2.values_LL = pchisq(zs_2.stouffer_LL^2/lambda_2_LL, df = 1, lower = FALSE)\n",
      "\n",
      "cp_1.values_LL_2 = pchisq(zs_1.stouffer_LL_2^2/lambda_1_LL_2, df = 1, lower = FALSE)\n",
      "cp_2.values_LL_2 = pchisq(zs_2.stouffer_LL_2^2/lambda_2_LL_2, df = 1, lower = FALSE)\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 1 expected FDR:\", alpha))\n",
      "  L = length(cp_1.values_LL)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_1.values_LL) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_1.values_LL)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 1 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_LL)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_LL) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_2.values_LL)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 2 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 1 expected FDR:\", alpha))\n",
      "  L = length(cp_1.values_LL_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_1.values_LL_2) < alpha * (1:L) / L)\n",
      "  candidates_LL = order(cp_1.values_LL_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates_LL <= 350))/length(candidates_LL)\n",
      "  estimated.TP_LL = length(which(candidates_LL > 350))/50\n",
      "  print(paste(\"k = 1 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_LL_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_LL_2) < alpha * (1:L) / L)\n",
      "  candidates_LL = order(cp_2.values_LL_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates_LL <= 350))/length(candidates_LL)\n",
      "  estimated.TP_LL = length(which(candidates_LL > 350))/50\n",
      "  print(paste(\"k = 2 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ PRECIPITATION and TEMPERATURE\n",
      "#to load project, use:\n",
      "project_PT <- load.lfmmProject(\"NAE_lfmm_NAE_PT_2.lfmmProject\")\n",
      "\n",
      "# show the project\n",
      "show(project_PT)\n",
      "\n",
      "# summary of the project\n",
      "summary(project_PT)\n",
      "\n",
      "# get the zscores of each run for K \n",
      "zs_1_PT = z.scores(project_PT, d = 1, K = 1)\n",
      "zs_2_PT = z.scores(project_PT, d = 1, K = 2)\n",
      "\n",
      "zs_1_PT_2 = z.scores(project_PT, d = 2, K = 1)\n",
      "zs_2_PT_2 = z.scores(project_PT, d = 2, K = 2)\n",
      "\n",
      "# Combine the z-scores using the Stouffer method\n",
      "zs_1.stouffer_PT = apply(zs_1_PT, MARGIN = 1, median)\n",
      "zs_2.stouffer_PT = apply(zs_2_PT, MARGIN = 1, median)\n",
      "\n",
      "zs_1.stouffer_PT_2 = apply(zs_1_PT, MARGIN = 1, median)\n",
      "zs_2.stouffer_PT_2 = apply(zs_2_PT, MARGIN = 1, median)\n",
      "\n",
      "# calculate the inflation factor\n",
      "lambda_1_PT = median(zs_1.stouffer_PT^2)/.456\n",
      "lambda_2_PT = median(zs_2.stouffer_PT^2)/.456\n",
      "\n",
      "lambda_1_PT_2 = median(zs_1.stouffer_PT_2^2)/.456\n",
      "lambda_2_PT_2 = median(zs_2.stouffer_PT_2^2)/.456\n",
      "\n",
      "# calculate adjusted p-values\n",
      "cp_1.values_PT = pchisq(zs_1.stouffer_PT^2/lambda_1_PT, df = 1, lower = FALSE)\n",
      "cp_2.values_PT = pchisq(zs_2.stouffer_PT^2/lambda_2_PT, df = 1, lower = FALSE)\n",
      "\n",
      "cp_1.values_PT_2 = pchisq(zs_1.stouffer_PT_2^2/lambda_1_PT_2, df = 1, lower = FALSE)\n",
      "cp_2.values_PT_2 = pchisq(zs_2.stouffer_PT_2^2/lambda_2_PT_2, df = 1, lower = FALSE)\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 1 expected FDR:\", alpha))\n",
      "  L = length(cp_1.values_PT)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_1.values_PT) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_1.values_PT)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"k = 1 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_PT)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_PT) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_2.values_PT)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 2 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 1 expected FDR:\", alpha))\n",
      "  L = length(cp_1.values_PT_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_1.values_PT_2) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_1.values_PT_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"k = 1 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_PT_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_PT_2) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_2.values_PT_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 2 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Performing LFMM analyis on population data\n",
      "###    using the package LEA from http://www.bioconductor.org/packages/release/bioc/html/LEA.html\n",
      "### Carolyn Tarpey | October 2015 \n",
      "### ---------------------------------------\n",
      "library(LEA)\n",
      "#The lfmm function returns a project object containing all lfmm runs. \n",
      "#When performing additional runs, the function enables the project to be included as a parameter \n",
      "#to add more runs. Performing several runs for various values of the number of latent factors (K) \n",
      "#is recommended. \n",
      "#these are the steps listed in the manual for post-processing the LFMM runs: \n",
      "setwd(\"C:/Users/ctarpey/Desktop/LFMM_sm_runs/NAO\")\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ LATITUDE and LONGITUDE\n",
      "\n",
      "#to load project, use:\n",
      "project_LL <- load.lfmmProject(\"NAO_lfmm_NAO_long_lat_PT.lfmmProject\")\n",
      "\n",
      "# show the project\n",
      "show(project_LL)\n",
      "\n",
      "# summary of the project\n",
      "summary(project_LL)\n",
      "\n",
      "# get the zscores of each run for K \n",
      "zs_3_LL = z.scores(project_LL, d = 1, K = 3)\n",
      "zs_2_LL = z.scores(project_LL, d = 1, K = 2)\n",
      "\n",
      "zs_3_LL_2 = z.scores(project_LL, d = 2, K = 3)\n",
      "zs_2_LL_2 = z.scores(project_LL, d = 2, K = 2)\n",
      "\n",
      "# Combine the z-scores using the Stouffer method\n",
      "zs_3.stouffer_LL = apply(zs_3_LL, MARGIN = 1, median)\n",
      "zs_2.stouffer_LL = apply(zs_2_LL, MARGIN = 1, median)\n",
      "\n",
      "zs_3.stouffer_LL_2 = apply(zs_3_LL, MARGIN = 1, median)\n",
      "zs_2.stouffer_LL_2 = apply(zs_2_LL, MARGIN = 1, median)\n",
      "\n",
      "# calculate the inflation factor\n",
      "lambda_3_LL = median(zs_3.stouffer_LL^2)/.456\n",
      "lambda_2_LL = median(zs_2.stouffer_LL^2)/.456\n",
      "\n",
      "lambda_3_LL_2 = median(zs_3.stouffer_LL_2^2)/.456\n",
      "lambda_2_LL_2 = median(zs_2.stouffer_LL_2^2)/.456\n",
      "\n",
      "# calculate adjusted p-values\n",
      "cp_3.values_LL = pchisq(zs_3.stouffer_LL^2/lambda_3_LL, df = 1, lower = FALSE)\n",
      "cp_2.values_LL = pchisq(zs_2.stouffer_LL^2/lambda_2_LL, df = 1, lower = FALSE)\n",
      "\n",
      "cp_3.values_LL_2 = pchisq(zs_3.stouffer_LL_2^2/lambda_3_LL_2, df = 1, lower = FALSE)\n",
      "cp_2.values_LL_2 = pchisq(zs_2.stouffer_LL_2^2/lambda_2_LL_2, df = 1, lower = FALSE)\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 3 expected FDR:\", alpha))\n",
      "  L = length(cp_3.values_LL)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_3.values_LL) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_3.values_LL)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 3 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_LL)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_LL) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_2.values_LL)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 2 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 3 expected FDR:\", alpha))\n",
      "  L = length(cp_3.values_LL_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_3.values_LL_2) < alpha * (1:L) / L)\n",
      "  candidates_LL = order(cp_3.values_LL_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates_LL <= 350))/length(candidates_LL)\n",
      "  estimated.TP_LL = length(which(candidates_LL > 350))/50\n",
      "  print(paste(\"k = 3 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_LL_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_LL_2) < alpha * (1:L) / L)\n",
      "  candidates_LL = order(cp_2.values_LL_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR_LL = length(which(candidates_LL <= 350))/length(candidates_LL)\n",
      "  estimated.TP_LL = length(which(candidates_LL > 350))/50\n",
      "  print(paste(\"k = 2 FDR:\", estimated.FDR_LL, \"True Positive:\", estimated.TP_LL))\n",
      "}\n",
      "\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ PRECIPITATION and TEMPERATURE\n",
      "\n",
      "#to load project, use:\n",
      "project_PT <- load.lfmmProject(\"NAO_lfmm_NAO_PT.lfmmProject\")\n",
      "\n",
      "# show the project\n",
      "show(project_PT)\n",
      "\n",
      "# summary of the project\n",
      "summary(project_PT)\n",
      "\n",
      "# get the zscores of each run for K \n",
      "zs_3_PT = z.scores(project_PT, d = 1, K = 3)\n",
      "zs_2_PT = z.scores(project_PT, d = 1, K = 2)\n",
      "\n",
      "zs_3_PT_2 = z.scores(project_PT, d = 2, K = 3)\n",
      "zs_2_PT_2 = z.scores(project_PT, d = 2, K = 2)\n",
      "\n",
      "# Combine the z-scores using the Stouffer method\n",
      "zs_3.stouffer_PT = apply(zs_3_PT, MARGIN = 1, median)\n",
      "zs_2.stouffer_PT = apply(zs_2_PT, MARGIN = 1, median)\n",
      "\n",
      "zs_3.stouffer_PT_2 = apply(zs_3_PT, MARGIN = 1, median)\n",
      "zs_2.stouffer_PT_2 = apply(zs_2_PT, MARGIN = 1, median)\n",
      "\n",
      "# calculate the inflation factor\n",
      "lambda_3_PT = median(zs_3.stouffer_PT^2)/.456\n",
      "lambda_2_PT = median(zs_2.stouffer_PT^2)/.456\n",
      "\n",
      "lambda_3_PT_2 = median(zs_3.stouffer_PT_2^2)/.456\n",
      "lambda_2_PT_2 = median(zs_2.stouffer_PT_2^2)/.456\n",
      "\n",
      "# calculate adjusted p-values\n",
      "cp_3.values_PT = pchisq(zs_3.stouffer_PT^2/lambda_3_PT, df = 1, lower = FALSE)\n",
      "cp_2.values_PT = pchisq(zs_2.stouffer_PT^2/lambda_2_PT, df = 1, lower = FALSE)\n",
      "\n",
      "cp_3.values_PT_2 = pchisq(zs_3.stouffer_PT_2^2/lambda_3_PT_2, df = 1, lower = FALSE)\n",
      "cp_2.values_PT_2 = pchisq(zs_2.stouffer_PT_2^2/lambda_2_PT_2, df = 1, lower = FALSE)\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 3 expected FDR:\", alpha))\n",
      "  L = length(cp_3.values_PT)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_3.values_PT) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_3.values_PT)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"k = 3 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_PT)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_PT) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_2.values_PT)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 2 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 3 expected FDR:\", alpha))\n",
      "  L = length(cp_3.values_PT_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_3.values_PT_2) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_3.values_PT_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"k = 3 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}\n",
      "\n",
      "for (alpha in c(.05,.1,.15,.2)) {\n",
      "  # expected FDR\n",
      "  print(paste(\"K = 2 expected FDR:\", alpha))\n",
      "  L = length(cp_2.values_PT_2)\n",
      "  # return a list of candidates with an expected FDR of alpha.\n",
      "  w = which(sort(cp_2.values_PT_2) < alpha * (1:L) / L)\n",
      "  candidates = order(cp_2.values_PT_2)[w]\n",
      "  \n",
      "  # estimated FDR and True Positif\n",
      "  estimated.FDR = length(which(candidates <= 350))/length(candidates)\n",
      "  estimated.TP = length(which(candidates > 350))/50\n",
      "  print(paste(\"K = 2 FDR:\", estimated.FDR, \"True Positive:\", estimated.TP))\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For all these runs, I captured the console output when I ran the code. Im not sure what to do with it next.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Did the program run the variables in the way that I expected it to? "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looking at the class files in the program folders of the individual runs, I am wondering LFMM really ran the way that I thought it was going. I expected the command to have it take both the variables and runs them together at the same time. But looking at the output of the program, all those falses down at the bottom are concerning. If the program had run them the way that I expected, combining the variables, some of those should be TRUE. I have to assume that it didnt work."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lfmmProject file:                      C:/Users/ctarpey/Desktop/LFMM_sm_runs/NAO/NAO_lfmm_NAO_long_lat_PT.lfmmProject \n",
      "directory:                             C:/Users/ctarpey/Desktop/LFMM_sm_runs/NAO/NAO_lfmm_NAO_long_lat_PT.lfmm/ \n",
      "date of creation:                      1445288963 \n",
      "input file:                            C:\\Users\\ctarpey\\Desktop\\LFMM_sm_runs\\NAO\\NAO_lfmm.lfmm \n",
      "variable file:                         C:\\Users\\ctarpey\\Desktop\\LFMM_sm_runs\\NAO\\NAO_long_lat_PT.env \n",
      "number of individuals:                 73 \n",
      "number of loci:                        16681 \n",
      "number of environmental variables:     4 \n",
      "run for the latent factors:            2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 \n",
      "run for the environmental variables:   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 \n",
      "variables separately or together:      FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}