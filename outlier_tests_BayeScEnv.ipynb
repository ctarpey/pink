{
 "metadata": {
  "name": "",
  "signature": "sha256:c3bfa6d69712194b6edfbe3abe9261fff2857ff807c3656063cacd78c4160e24"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Outlier tests"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#BayeScEnv"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "September 3 \n",
      "\n",
      "Ok, moved the Bayescan files over to the BayeSCenv file, along with the env data. The individual files are all in order of how thepopulations are in the popinfo file, so I have to do the same thing with the environmental data to match them up if I want to run them, but I may not have to run them all, I need to think about exactly which tests I want. \n",
      "\n",
      "First ill run the whole dataset, to see if I can get the program to work. \n",
      "\n",
      "\n",
      "OK, it looks like its starting to work, I have the 16681_80_bayescan.txt as the input file and stand_lat.txt as the environmental input file and the results are output to the BayeSCenv file. So far Im just using the defaults, there arent any details about the parameters that they used for the Bayenv2, the closest program to this that they ran in pink paper one, but for bayescan they used 50,000 iterations and the default settings, so I just left the default settings for this. its beginning the pilot runs. Its at 100% or cpu- using half and lepmap is splitting the other half between the two ordering commands, and together they are using 80% of thememory, but holding steady. Its probably just going to take a long time. \n",
      "\n",
      "There is a command line version that if this works i might set up to run the rest of the comparisons in the background of someone elses computer. I think ill make the files for it, and maybe plan on running it on Ryans computer over the weekend? \n",
      "\n",
      "Also the manual for the BayeScEnv is really helpful: https://github.com/devillemereuil/bayescenv/wiki/5.-How-to-calibrate-the-MCMC\n",
      "it has a lot of good information regarding the model and what is actually happening. \n",
      "\n",
      "Here are two points: \n",
      "\n",
      "However, you should always check that the acceptance rates displayed in \"out_AccRte.txt\" (where \"out\" is the output prefix of your choice) are between 0.2 and 0.4.\n",
      "\n",
      "The \"trace\" of the successive iterations are stocked in the \"out.sel\" file (where \"out\" is the output prefix of your choice), which can be read in R and transformed into a MCMC object using the \"coda\" package. (I put the code that he gives out into a script in R)\n",
      "\n",
      "\n",
      "We recommend effective sizes of at least the Fst's to be reported in Supplementary Material when using the method.\n",
      "\n",
      "\n",
      "here is the command to run it through the command line with the default parameters at the back. \n",
      "./bayescenv data_codominantSNP.txt -env env.txt -o test -nbp 20 -pilot 5000 -thin 10 -n 5000 -burn 50000 \n",
      "\n",
      "Here are the environmental data that I built the files for each of the runs out of. the single numbers in between the names and the numbers with all the digits are the index numbers of the populations that were used. \n",
      "\n",
      "asia_odd_lat\t\t\t2\t3\t8\t13\t\t-0.3001785\t0.3445463\t-1.6735799\t0.609963\n",
      "asia_even_lat\t\t\t1\t4\t7\t14\t\t-0.3001785\t0.3445463\t-1.6735799\t0.609963\n",
      "NA_odd_lat\t\t\t5\t9\t11\t\t\t0.7452322\t1.2606949\t-0.986678\t\n",
      "NA_even_lat\t\t\t6\t10\t12\t\t\t0.7452322\t1.2606949\t-0.986678\t\n",
      "\n",
      "\n",
      "\n",
      "asia_odd_long\t\t\t2\t3\t8\t13\t\t0.7767843\t0.9189846\t0.7993947\t0.8294541\n",
      "asia_even_long\t\t\t1\t4\t7\t14\t\t0.7767843\t0.9189846\t0.7993947\t0.8294541\n",
      "NA_odd_long\t\t\t5\t9\t11\t\t\t-1.1177044\t-1.2458492\t-0.9610641\t\n",
      "NA_even_long\t\t\t6\t10\t12\t\t\t-1.1177044\t-1.2458492\t-0.9610641\t\n",
      "\n",
      "This is what Im going to run on Ryans computer over the long weekend: \n",
      "\n",
      "./bayescenv 16681_80_bayescan.txt -env stand_lat.txt -o out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >16681_80_bayescan_log.txt 2>&1\n",
      "./bayescenv asia_odd_bayescan.txt -env asia_odd_lat.txt -o out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >asia_odd_bayescan_log.txt 2>&1\n",
      "./bayescenv asia_even_bayescan.txt -env asia_even_lat.txt -o out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >asia_even_bayescan_log.txt 2>&1\n",
      "./bayescenv NA_odd_bayescan.txt -env NA_odd_lat.txt\t-o out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NA_odd_bayescan_log.txt 2>&1\n",
      "./bayescenv NA_even_bayescan.txt -env NA_even_lat.txt -o out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NA_even_bayescan_log.txt 2>&1\n",
      "\n",
      "./bayescenv 16681_80_bayescan.txt -env stand_long.txt -o out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >16681_80_bayescan_log.txt 2>&1\n",
      "./bayescenv asia_odd_bayescan.txt -env asia_odd_long.txt -o out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >asia_odd_bayescan_log.txt 2>&1\n",
      "./bayescenv asia_even_bayescan.txt -env asia_even_long.txt -o out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >asia_even_bayescan_log.txt 2>&1\n",
      "./bayescenv NA_odd_bayescan.txt -env NA_odd_long.txt -o out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NA_odd_bayescan_log.txt 2>&1\n",
      "./bayescenv NA_even_bayescan.txt -env NA_even_long.txt -o out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NA_even_bayescan_log.txt 2>&1\n",
      "\n",
      "\n",
      "Sep 8 \n",
      "\n",
      "I came in this morning and realized that I had not actually specified the output files for the bayesenv runs, though they had all run on ryans computer because the logs were there. So the last one to run, and the only one that i actually got any results for was: NA_even_bayescan_log.txt \n",
      "\n",
      "So I remade the batch file to have the proper output file names and restarted it on Garretts computer. I also got rid of this one: Y:\\WORK\\TARPEY\\BayeScEnv\\bin\\win32\\bayescenv.exe  16681_80_bayescan.txt -env stand_lat.txt -o out_16681_80_bayescan.txt -threads 5 -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >16681_80_bayescan_log.txt 2>&1\n",
      "because it had already finished running on my computer the week before. \n",
      "\n",
      "\n",
      "So here is the new batch file: \n",
      "\n",
      "Y:\\WORK\\TARPEY\\BayeScEnv\\bin\\win32\\bayescenv.exe asia_odd_bayescan.txt -env asia_odd_lat.txt -threads 5 -o out_asia_odd_bayescan.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >asia_odd_bayescan_log.txt 2>&1\n",
      "Y:\\WORK\\TARPEY\\BayeScEnv\\bin\\win32\\bayescenv.exe  asia_even_bayescan.txt -env asia_even_lat.txt -threads 5 -o out_asia_even_bayescan.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >asia_even_bayescan_log.txt 2>&1\n",
      "Y:\\WORK\\TARPEY\\BayeScEnv\\bin\\win32\\bayescenv.exe  NA_odd_bayescan.txt -env NA_odd_lat.txt -threads 5 -o out_NA_odd_bayescan.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NA_odd_bayescan_log.txt 2>&1\n",
      "\n",
      "It seems to be running OK. \n",
      "\n",
      "\n",
      "         $$ September 9 2015\n",
      "==================================================================\n",
      "\n",
      "The Bayescenv runs finished on Garretts computer, so now I have all those runs done for the latitude. \n",
      "\n",
      "Sep 23\n",
      "\n",
      "#BayeScEnv_Sep15.bat\n",
      "\n",
      "Y:\\WORK\\TARPEY\\BayeScEnv\\bin\\win32\\bayescenv.exe asia_odd_bayescan.txt -env asia_odd_long.txt -threads 5 -out out_asia_odd_long.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >asia_odd_long_log.txt 2>&1\n",
      "Y:\\WORK\\TARPEY\\BayeScEnv\\bin\\win32\\bayescenv.exe  asia_even_bayescan.txt -env asia_even_long.txt -threads 5 -out out_asia_even_long.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >asia_even_long_log.txt 2>&1\n",
      "Y:\\WORK\\TARPEY\\BayeScEnv\\bin\\win32\\bayescenv.exe  NA_odd_bayescan.txt -env NA_odd_long.txt -threads 5 -out out_NA_odd_long.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NA_odd_long_log.txt 2>&1\n",
      "Y:\\WORK\\TARPEY\\BayeScEnv\\bin\\win32\\bayescenv.exe  NA_even_bayescan.txt -env NA_even_long.txt -threads 5 -out out_NA_even_long.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NA_even_long_log.txt 2>&1\n",
      "Y:\\WORK\\TARPEY\\BayeScEnv\\bin\\win32\\bayescenv.exe  16681_80_bayescan.txt -env stand_long.txt -out out_16681_80_long.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >16681_80__long_log.txt 2>&1\n",
      "\n",
      "\n",
      "\n",
      "         $$ October 12  2015\n",
      "==================================================================\n",
      "\n",
      "The BayeScEnv finished running on Saturday morning, so thats good news. Its done the latitude and longitude. \n",
      "\n",
      "\n",
      "I was looking back at the results of the previous bayescenv runs and they dont really follow the instructions on the manual, that sayus that in order to calibarate the pilot runs and yield informative results, the acceptance rates in the _AccRte.txt file should be between 0.2 and 0.4\n",
      " \n",
      " So there are two columns in that txt file, the first is labeled beta and the second is labled ances. \n",
      " \n",
      " There have been 5 runs of this program with the lat and the long file. \n",
      " \n",
      " Oct 18 \n",
      "    \n",
      " \n",
      " UGH I Cant figure out what to do with the bayescenv files, I dont think that they ran correctly, and Im not sure how to fix them except to start over and try again. \n",
      " \n",
      " This is the batch file that I made: it could take a long time to run. \n",
      " \n",
      " \n",
      ".\\bayescenv.exe asia_odd_bayescan.txt -env AS_LAT.env -out ASO_LAT_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASO_LAT_out_log.txt 2>&1\n",
      ".\\bayescenv.exe asia_even_bayescan.txt -env AS_LAT.env -out ASE_LAT_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASE_LAT_out_log.txt 2>&1\n",
      ".\\bayescenv.exe NA_odd_bayescan.txt -env NA_LAT.env -out NAO_LAT_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAO_LAT_out_log.txt 2>&1\n",
      ".\\bayescenv.exe NA_even_bayescan.txt -env NA_LAT.env -out NAE_LAT_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAE_LAT_out_log.txt 2>&1\n",
      ".\\bayescenv.exe 16681_80_bayescan.txt -env ALL_LAT.env -out 16681_LAT_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >16681_LAT_out_log.txt 2>&1\n",
      "\n",
      ".\\bayescenv.exe asia_odd_bayescan.txt -env AS_LONG.env -out ASO_LONG_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASO_LONG_out_log.txt 2>&1\n",
      ".\\bayescenv.exe asia_even_bayescan.txt -env AS_LONG.env -out ASE_LONG_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASE_LONG_out_log.txt 2>&1\n",
      ".\\bayescenv.exe NA_odd_bayescan.txt -env NA_LONG.env -out NAO_LONG_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAO_LONG_out_log.txt 2>&1\n",
      ".\\bayescenv.exe NA_even_bayescan.txt -env NA_LONG.env -out NAE_LONG_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAE_LONG_out_log.txt 2>&1\n",
      ".\\bayescenv.exe 16681_80_bayescan.txt -env ALL_LONG.env -out 16681_LONG_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >16681_LONG_out_log.txt 2>&1\n",
      "\n",
      ".\\bayescenv.exe asia_odd_bayescan.txt -env AS_PT1.env -out ASO_PT1_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASO_PT1_out_log.txt 2>&1\n",
      ".\\bayescenv.exe asia_even_bayescan.txt -env AS_PT1.env -out ASE_PT1_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASE_PT1_out_log.txt 2>&1\n",
      ".\\bayescenv.exe NA_odd_bayescan.txt -env NA_PT1.env -out NAO_PT1_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAO_PT1_out_log.txt 2>&1\n",
      ".\\bayescenv.exe NA_even_bayescan.txt -env NA_PT1.env -out NAE_PT1_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAE_PT1_out_log.txt 2>&1\n",
      ".\\bayescenv.exe 16681_80_bayescan.txt -env ALL_PT1.env -out 16681_PT1_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >16681_PT1_out_log.txt 2>&1\n",
      "\n",
      ".\\bayescenv.exe asia_odd_bayescan.txt -env AS_PT2.env -out ASO_PT2_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASO_PT2_out_log.txt 2>&1\n",
      ".\\bayescenv.exe asia_even_bayescan.txt -env AS_PT2.env -out ASE_PT2_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASE_PT2_out_log.txt 2>&1\n",
      ".\\bayescenv.exe NA_odd_bayescan.txt -env NA_PT2.env -out NAO_PT2_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAO_PT2_out_log.txt 2>&1\n",
      ".\\bayescenv.exe NA_even_bayescan.txt -env NA_PT2.env -out NAE_PT2_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAE_PT2_out_log.txt 2>&1\n",
      ".\\bayescenv.exe 16681_80_bayescan.txt -env ALL_PT2.env -out 16681_PT2_out -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >16681_PT2_out_log.txt 2>&1\n",
      "\n",
      "\n",
      "          $$ October 27  2015\n",
      "==================================================================\n",
      "\n",
      "\n",
      "Talked to ryan about a host of issues. \n",
      "\n",
      "\n",
      "BAYESCENV\n",
      "calibrating the pilot runs: \n",
      "\t1. what are the beta and ances mentioned at the top of the file? \n",
      "\t2. are my acceptance rates between .2 and .4? \n",
      "General BAYES questions: \n",
      "When running programs and trying to up the number of iterations is it better to increase the length of a run or add more runs? \n",
      "\n",
      "\n",
      "\n",
      "the beta he thinks means the correlation with the variable\n",
      "the ances is like an ancestry thing, and has to do with the variation that is attributed to the structure of the populations, or the covariance matrix, so the non environmental\n",
      "\n",
      "when you are increasing the length of the runs, the best way to do it is to increase the length of the runs, so add iterations to the runs instead of add more runs. that will let them run longer and get closer to convergence. \n",
      "\n",
      "he isnt sure what the two columns mean, but he said that its a good sign that they are steadily decreasing but it might not be ok that they havent plateaued or reached a steady state. So he doesnt know what the instructions about the .2 or .4 mean in the context but these runs were probably not run long enough to reach convergence, though they certainly seem to be going in the right direction. Also he said that if I have a basic question that I should think about emailing the developer. If its basic enough he might answer. there are instructions for how to look at the convergence, doing a trace in R with the program Coda etc, and that i should do that and look at what its like. Maybe they are reaching convergence and theres no good obvious answer for what is happening in the two columns? \n",
      "So at the end of it. i need to redo the standardization of the environmental variables,\n",
      "And increase the number of iterations per run for the bayescenv- it doesnt seem to be getting to the convergence. do the coda in R to test the convergence. \n",
      "\n",
      "\n",
      "to bayescenv- trying to figure out if the acceptance rates that I have are ok, but skipping the step where i look because I dont know how to tell, and actually just going to the part where I plot them in R with coda to see if I have reached convergence. \n",
      "\n",
      "https://github.com/devillemereuil/bayescenv/wiki/5.-How-to-calibrate-the-MCMC\n",
      "\n",
      "\n",
      "### Check whether the MCMC has reached convergence\n",
      "###    using the package coda, and code from: https://github.com/devillemereuil/bayescenv/wiki/5.-How-to-calibrate-the-MCMC\n",
      "### Carolyn Tarpey | October 2015 \n",
      "### ---------------------------------------\n",
      "\n",
      "\n",
      "install.packages(\"coda\")\n",
      "\n",
      "library(coda)\n",
      "\n",
      "\n",
      "#set the working directory \n",
      "setwd(\"G:/Analysis/Pop_analysis/Populations_b3_may/BayeScEnv\")\n",
      "\n",
      "### 16681_80_bayescan.sel\n",
      "\n",
      "chain_16681 <-read.table(\"16681_80_bayescan.sel\",header=TRUE)\n",
      "chain_16681 <-mcmc(chain_16681, thin=10)     #Adapt thin to its actual value (10 is the default)\n",
      "heidel.diag(chain_16681)             #To test for convergence\n",
      "effectiveSize(chain_16681)           #To compute effective sample size\n",
      "autocorr.diag(chain_16681)           #To look for auto-correlation\n",
      "plot(chain_16681)                    #To plot the \"trace\" and the posterior distribution\n",
      "\n",
      "### NA_even_bayescan.sel\n",
      "\n",
      "chain_NAE <-read.table(\"NA_even_bayescan.sel\",header=TRUE)\n",
      "chain_NAE <-mcmc(chain_NAE, thin=10)     #Adapt thin to its actual value (10 is the default)\n",
      "heidel.diag(chain_NAE)             #To test for convergence\n",
      "effectiveSize(chain_NAE)           #To compute effective sample size\n",
      "autocorr.diag(chain_NAE)           #To look for auto-correlation\n",
      "plot(chain_NAE)                    #To plot the \"trace\" and the posterior distribution\n",
      "\n",
      "### NA_odd_bayescan.sel\n",
      "\n",
      "chain_NAO <-read.table(\"NA_odd_bayescan.sel\",header=TRUE)\n",
      "chain_NAO <-mcmc(chain_NAO, thin=10)     #Adapt thin to its actual value (10 is the default)\n",
      "heidel.diag(chain_NAO)             #To test for convergence\n",
      "effectiveSize(chain_NAO)           #To compute effective sample size\n",
      "autocorr.diag(chain_NAO)           #To look for auto-correlation\n",
      "plot(chain_NAO)                    #To plot the \"trace\" and the posterior distribution\n",
      "\n",
      "### asia_even_bayescan.sel\n",
      "\n",
      "chain_ASE <-read.table(\"asia_even_bayescan.sel\",header=TRUE)\n",
      "chain_ASE <-mcmc(chain_ASE ,thin=10)     #Adapt thin to its actual value (10 is the default)\n",
      "heidel.diag(chain_ASE)             #To test for convergence\n",
      "effectiveSize(chain_ASE)           #To compute effective sample size\n",
      "autocorr.diag(chain_ASE)           #To look for auto-correlation\n",
      "plot(chain_ASE)                    #To plot the \"trace\" and the posterior distribution\n",
      "\n",
      "### asia_odd_bayescan.sel\n",
      "\n",
      "chain_ASO <-read.table(\"asia_odd_bayescan.sel\",header=TRUE)\n",
      "chain_ASO <-mcmc(chain_ASO ,thin=10)     #Adapt thin to its actual value (10 is the default)\n",
      "heidel.diag(chain_ASO)             #To test for convergence\n",
      "effectiveSize(chain_ASO)           #To compute effective sample size\n",
      "autocorr.diag(chain_ASO)           #To look for auto-correlation\n",
      "plot(chain_ASO)                    #To plot the \"trace\" and the posterior distribution\n",
      "\n",
      "\n",
      "These are the results:\n",
      "\n",
      "> setwd(\"G:/Analysis/Pop_analysis/Populations_b3_may/BayeScEnv\")\n",
      "\n",
      "\n",
      "> chain_16681 <-read.table(\"16681_80_bayescan.sel\",header=TRUE)\n",
      "> chain_16681 <-mcmc(chain_16681 ,thin=10)     #Adapt thin to its actual value (10 is the default)\n",
      "> heidel.diag(chain_16681)             #To test for convergence\n",
      "                                    \n",
      "      Stationarity start     p-value\n",
      "      test         iteration        \n",
      "Iter  failed        NA           NA \n",
      "logL  passed         1       0.6950 \n",
      "Fst1  passed         1       0.8364 \n",
      "Fst2  passed         1       0.6883 \n",
      "Fst3  passed         1       0.6946 \n",
      "Fst4  passed         1       0.7177 \n",
      "Fst5  passed       501       0.0543 \n",
      "Fst6  passed         1       0.7774 \n",
      "Fst7  passed         1       0.1122 \n",
      "Fst8  passed         1       0.1052 \n",
      "Fst9  passed         1       0.9889 \n",
      "Fst10 passed         1       0.8628 \n",
      "Fst11 passed         1       0.0892 \n",
      "Fst12 passed         1       0.7511 \n",
      "Fst13 passed         1       0.8116 \n",
      "Fst14 passed         1       0.6060 \n",
      "                                   \n",
      "      Halfwidth Mean      Halfwidth\n",
      "      test                         \n",
      "Iter  <NA>             NA       NA \n",
      "logL  passed    -5.13e+05 5.05e+00 \n",
      "Fst1  passed     5.07e-02 2.97e-05 \n",
      "Fst2  passed     2.40e-02 2.21e-05 \n",
      "Fst3  passed     2.14e-02 2.08e-05 \n",
      "Fst4  passed     5.47e-02 3.51e-05 \n",
      "Fst5  passed     6.99e-02 3.55e-05 \n",
      "Fst6  passed     8.29e-02 4.36e-05 \n",
      "Fst7  passed     8.15e-02 3.98e-05 \n",
      "Fst8  passed     4.96e-02 2.98e-05 \n",
      "Fst9  passed     2.18e-02 2.21e-05 \n",
      "Fst10 passed     6.09e-02 4.00e-05 \n",
      "Fst11 passed     1.46e-01 6.08e-05 \n",
      "Fst12 passed     1.20e-01 5.33e-05 \n",
      "Fst13 passed     2.20e-02 2.20e-05 \n",
      "Fst14 passed     5.10e-02 3.22e-05 \n",
      "\n",
      "\n",
      "> effectiveSize(chain_16681)           #To compute effective sample size\n",
      "    Iter     logL     Fst1     Fst2     Fst3     Fst4     Fst5     Fst6     Fst7     Fst8     Fst9   Fst10    Fst11    Fst12    Fst13    Fst14 \n",
      "   0.000 2680.730 3486.337 2816.921 2808.690 3049.141 4288.851 3602.023 3743.843 3311.436 3055.559   3527.474 4023.342 4193.153 2810.235 3363.913\n",
      "\n",
      "\n",
      "\n",
      "> autocorr.diag(chain_16681)           #To look for auto-correlation\n",
      "             Iter         logL        Fst1         Fst2         Fst3        Fst4        Fst5       Fst6         Fst7         Fst8         Fst9        Fst10        Fst11        Fst12    Fst13        Fst14\n",
      "Lag 0   1.0000000  1.000000000 1.000000000  1.000000000  1.000000000 1.000000000 1.000000000  1.000000000  1.000000000  1.000000000  1.000000000  1.000000000  1.000000000  1.000000000  1.000000000  1.000000000\n",
      "Lag 10  0.9993999  0.203075959 0.137381894  0.207437318  0.226476093 0.159784698 0.076360490  0.110748138  0.143465925  0.151334693  0.193029453  0.137916228  0.108039087  0.087567583  0.205124317  0.132901445\n",
      "Lag 50  0.9969994  0.002491573 0.007357094  0.021197866  0.007996474 0.006693156 0.011191450 -0.016902719 -0.007761888  0.004310425  0.011689438 -0.016370899 -0.008531449  0.013982392  0.007435516  0.011494994\n",
      "Lag 100 0.9939988 -0.002780925 0.007080503 -0.014579255 -0.011326658 0.014043647 0.012038672  0.002185866 -0.001858880 -0.006620472 -0.001598554 -0.017215710  0.019290685  0.006978431  0.016497166 -0.004957534\n",
      "Lag 500 0.9699960 -0.005492100 0.027893915 -0.004382463 -0.010277262 0.003387921 0.002425106  0.020133634  0.006855558 -0.007160937  0.005565154 -0.004661507  0.013566505 -0.007772530 -0.013759333 -0.014639419\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "> chain_NAE <-read.table(\"NA_even_bayescan.sel\",header=TRUE)\n",
      "> chain_NAE <-mcmc(chain_NAE, thin=10)     #Adapt thin to its actual value (10 is the default)\n",
      "> heidel.diag(chain_NAE)             #To test for convergence\n",
      "                                   \n",
      "     Stationarity start     p-value\n",
      "     test         iteration        \n",
      "Iter failed         NA          NA \n",
      "logL passed          1      0.1865 \n",
      "Fst1 passed          1      0.4132 \n",
      "Fst2 passed          1      0.3811 \n",
      "Fst3 passed       1001      0.0543 \n",
      "                                   \n",
      "     Halfwidth Mean      Halfwidth\n",
      "     test                         \n",
      "Iter <NA>             NA       NA \n",
      "logL passed    -9.38e+04 8.16e+00 \n",
      "Fst1 passed     3.96e-02 5.50e-05 \n",
      "Fst2 passed     5.52e-02 5.61e-05 \n",
      "Fst3 passed     7.44e-02 7.11e-05 \n",
      "\n",
      "\n",
      "> effectiveSize(chain_NAE)           #To compute effective sample size\n",
      "    Iter     logL     Fst1     Fst2     Fst3 \n",
      "   0.000 1265.716 1889.918 2401.221 2364.421 \n",
      "   \n",
      "> autocorr.diag(chain_NAE)           #To look for auto-correlation\n",
      "             Iter        logL         Fst1       Fst2        Fst3\n",
      "Lag 0   1.0000000  1.00000000  1.000000000 1.00000000 1.000000000\n",
      "Lag 10  0.9993999  0.49332356  0.391244882 0.26193295 0.280934086\n",
      "Lag 50  0.9969994  0.10226455  0.026328447 0.03550004 0.018988467\n",
      "Lag 100 0.9939988  0.02767923 -0.001010564 0.00215506 0.006419806\n",
      "Lag 500 0.9699960 -0.01864821 -0.019293639 0.01066389 0.012390068\n",
      "\n",
      "\n",
      "\n",
      "> chain_NAO <-read.table(\"NA_odd_bayescan.sel\",header=TRUE)\n",
      "> chain_NAO <-mcmc(chain_NAO, thin=10)     #Adapt thin to its actual value (10 is the default)\n",
      "> heidel.diag(chain_NAO)             #To test for convergence\n",
      "                                   \n",
      "     Stationarity start     p-value\n",
      "     test         iteration        \n",
      "Iter failed       NA            NA \n",
      "logL passed        1        0.3949 \n",
      "Fst1 passed        1        0.1340 \n",
      "Fst2 passed        1        0.7236 \n",
      "Fst3 passed        1        0.0667 \n",
      "                                  \n",
      "     Halfwidth Mean      Halfwidth\n",
      "     test                         \n",
      "Iter <NA>             NA       NA \n",
      "logL passed    -1.06e+05 7.50e+00 \n",
      "Fst1 passed     5.20e-02 6.14e-05 \n",
      "Fst2 passed     4.99e-02 5.45e-05 \n",
      "Fst3 passed     1.23e-01 7.87e-05 \n",
      "\n",
      "\n",
      "> effectiveSize(chain_NAO)           #To compute effective sample size\n",
      "    Iter     logL     Fst1     Fst2     Fst3 \n",
      "   0.000 1410.830 1859.693 1997.089 2803.935 \n",
      "   \n",
      "> autocorr.diag(chain_NAO)           #To look for auto-correlation\n",
      "             Iter         logL         Fst1        Fst2        Fst3\n",
      "Lag 0   1.0000000  1.000000000  1.000000000 1.000000000  1.00000000\n",
      "Lag 10  0.9993999  0.489099728  0.371123355 0.339880282  0.22084625\n",
      "Lag 50  0.9969994  0.073779919  0.024298106 0.042282189  0.01691076\n",
      "Lag 100 0.9939988  0.014452505 -0.004130594 0.017762678  0.01254567\n",
      "Lag 500 0.9699960 -0.001702757 -0.014337181 0.007602119 -0.02884206\n",
      "\n",
      "\n",
      "> chain_ASE <-read.table(\"asia_even_bayescan.sel\",header=TRUE)\n",
      "> chain_ASE <-mcmc(chain_ASE ,thin=10)     #Adapt thin to its actual value (10 is the default)\n",
      "> heidel.diag(chain_ASE)             #To test for convergence\n",
      "                                   \n",
      "     Stationarity start     p-value\n",
      "     test         iteration        \n",
      "Iter failed        NA           NA \n",
      "logL passed         1       0.0749 \n",
      "Fst1 passed         1       0.7549 \n",
      "Fst2 passed       501       0.1942 \n",
      "Fst3 passed         1       0.4883 \n",
      "Fst4 passed         1       0.2275 \n",
      "                                  \n",
      "     Halfwidth Mean      Halfwidth\n",
      "     test                         \n",
      "Iter <NA>             NA       NA \n",
      "logL passed    -1.25e+05 8.06e+00 \n",
      "Fst1 passed     5.09e-03 1.41e-05 \n",
      "Fst2 passed     1.47e-02 2.43e-05 \n",
      "Fst3 passed     3.16e-02 2.39e-05 \n",
      "Fst4 passed     7.94e-03 1.74e-05 \n",
      "\n",
      "> effectiveSize(chain_ASE)           #To compute effective sample size\n",
      "    Iter     logL     Fst1     Fst2     Fst3     Fst4 \n",
      "   0.000  963.803 2306.599 1501.853 3380.094 2285.886 \n",
      "   \n",
      "   \n",
      "> autocorr.diag(chain_ASE)           #To look for auto-correlation\n",
      "             Iter        logL         Fst1        Fst2          Fst3        Fst4\n",
      "Lag 0   1.0000000  1.00000000  1.000000000  1.00000000  1.0000000000  1.00000000\n",
      "Lag 10  0.9993999  0.43715007  0.310163436  0.27637469  0.1644703270  0.26121172\n",
      "Lag 50  0.9969994  0.09393317 -0.009081315  0.09008163 -0.0003398159  0.02209232\n",
      "Lag 100 0.9939988  0.09752206 -0.019605112  0.06463454  0.0204274331  0.01297151\n",
      "Lag 500 0.9699960 -0.01544757 -0.002718811 -0.01426701  0.0136205273 -0.01728628\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "> chain_ASO <-read.table(\"asia_odd_bayescan.sel\",header=TRUE)\n",
      "> chain_ASO <-mcmc(chain_ASO ,thin=10)     #Adapt thin to its actual value (10 is the default)\n",
      "> heidel.diag(chain_ASO)             #To test for convergence\n",
      "                                   \n",
      "     Stationarity start     p-value\n",
      "     test         iteration        \n",
      "Iter failed       NA           NA  \n",
      "logL passed        1        0.381  \n",
      "Fst1 passed        1        0.355  \n",
      "Fst2 passed        1        0.591  \n",
      "Fst3 passed        1        0.627  \n",
      "Fst4 passed        1        0.850  \n",
      "                                  \n",
      "     Halfwidth Mean      Halfwidth\n",
      "     test                         \n",
      "Iter <NA>             NA       NA \n",
      "logL passed    -1.31e+05 7.50e+00 \n",
      "Fst1 passed     2.24e-03 1.17e-05 \n",
      "Fst2 passed     6.98e-03 1.80e-05 \n",
      "Fst3 passed     2.56e-02 1.94e-05 \n",
      "Fst4 passed     4.44e-03 1.45e-05 \n",
      "\n",
      "> effectiveSize(chain_ASO)           #To compute effective sample size\n",
      "    Iter     logL     Fst1     Fst2     Fst3     Fst4 \n",
      "   0.000 1017.142 1611.504 1526.173 3766.636 2034.358 \n",
      "   \n",
      "> autocorr.diag(chain_ASO)           #To look for auto-correlation\n",
      "             Iter       logL         Fst1        Fst2        Fst3        Fst4\n",
      "Lag 0   1.0000000 1.00000000  1.000000000  1.00000000  1.00000000 1.000000000\n",
      "Lag 10  0.9993999 0.45701381  0.413129743  0.35287801  0.13856561 0.290415919\n",
      "Lag 50  0.9969994 0.11654447  0.068301253  0.10033099 -0.01670955 0.048854526\n",
      "Lag 100 0.9939988 0.08042511  0.022772941  0.04302075  0.02812568 0.017050368\n",
      "Lag 500 0.9699960 0.01471647 -0.005711867 -0.01162968 -0.01763041 0.005880016\n",
      "\n",
      "\n",
      "\n",
      "Im not sure how to interpret these results. But theres this little tidbit in the manual: \n",
      "Also, since the parameters g and alpha are submitted to the Reversible Jump, many iterations are set to 0 in the chain, which can inflate auto-correlation. Null values can be removed to study to the chain when the parameters are actually included in the model by using:\n",
      "\n",
      ">effectiveSize(chain[chain[,'g256']!=0,'g256'])\n",
      "\n",
      "Note that performing these diagnostics might be daunting, but they are essential for the method to be trusted! We recommend effective sizes of at least the Fst's to be reported in Supplementary Material when using the method.\n",
      "\n",
      "and I dont know what to make of that either. SO. great start. I saved all the plots, and I rember that I have seen something like it in the course materials from the first year of the SISG courses. Ill look back through the handouts to see if Im doing it right. \n",
      "\n",
      "this is what this website says about it http://www.johnmyleswhite.com/notebook/2010/08/29/mcmc-diagnostics-in-r-with-the-coda-package/: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In this image, you can see that the trajectory of the chain is consistent over time and that its distribution looks appropriately normal. So the first takeaway message is simple: check the traces and distributions of your variables using plot() to make sure that they are reasonable and don\u2019t indicate clear deficiencies in the length of your adaptation period. When you know the distributional form of your posteriors, this is particularly effective, as in our example here, where we know to expect normal distributions.\n",
      "\n",
      "Oct 29 \n",
      "\n",
      "\n",
      "i dont think that the output of the bayescenv is really working- i think that the log is different each time but the actual output files are getting overwritten. which sucks. so i have a snapshot of the first four or so runs and I have a copy of right now, so maybe I can piece together somehtign and figure out what worked and what didnt and then get them started on separate computers or something like that so the problem doesnt happen again. \n",
      "\n",
      "The good news is that I remember that when you dont mess with the length of the iterations, it runs really fast, like all of them in three days fast on that computer over there, so that i could figure this out tomorrow and restart them. \n",
      "\n",
      "I may need to anyway, thinking about how the values need to be standardized individually. so thats cool\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         $$ October 30  2015\n",
      "==================================================================\n",
      "\n",
      "just looked back at the code for testing the convergence of the MCMC chain for the bayescenv results and using some tips i found at this website: https://theoreticalecology.wordpress.com/2011/12/09/mcmc-chain-analysis-and-convergence-diagnostics-with-coda-in-r/ \n",
      "Im pretty sure that it looks good, like there was convergence. \n",
      "\n",
      "they really recommend doing some other things to tell for sure, but I cant figure out what they are and Im pretty sure they need more than one chain to complete, and i dont have more than one chain, i think. \n",
      "\n",
      "i tried this: \n",
      "pairs(data.frame(chain_16681))\n",
      "\n",
      "and it worked, like R ran and it finished and there were no errors, but it didnt print anything and im not sure what it does? So i assigned it into a variable and am going to look at the variable when its done running. x <- pairs(data.frame(chain_16681)) it doesnt know. wait jk it did work but i have no idea what the plots are showing. it makes absolutely no sense to me. at all. so im moving on. ok ok i read more: \n",
      "\n",
      "\t\"Marginal densities are an average over the values a parameter takes with all other parameters \u201cmarginalized\u201d, i.e. other parameters having any values according to their posterior probabilities. Often, marginal densities are treated as the main output of a Bayesian analysis (e.g. by reporting their mean and sd of), but I strongly advice against this practice without further analysis. The reason is that marginal densities \u201chide\u201d correlations between parameters, and if there are correlations, parameter uncertainties appear to be much greater in the marginals that they actually are. To check for pairwise correlations is quite easy \u2013 just use pairs on the MCMC chain: pairs(data.frame(chain_16681)) \"\n",
      "\n",
      "Since we dont have anything but tons of huge blobs, i dont think that is evidence of correlation. if they were correlated there would be distinct patterns- lines up or down or whatever. \n",
      "\n",
      "Other things i want to look into: \n",
      "\t\n",
      "\trestandardizing the env variables for LFMM? \n",
      "\trestandardizing the bayescenv env factors?\n",
      "\trestandardizing the bayenv env factors - def have to do. \n",
      "\tlook at the input files for bayenv2- theyre not right, the covariance matrix is whack. \n",
      "\t\n",
      "So the Bayescenv runs that im checking the convergence is the one that was the very first- the early october ones. \n",
      "\n",
      "When i look at the doubled ones, they look really good too- but even cleaner. \n",
      "\n",
      "So I think the defaults are fine. \n",
      "\n",
      "this is what the Bayescenv manual says about the environmental variables: \n",
      "\n",
      "Environmental data\n",
      "\n",
      "As explained in the related article, the environmental variable must be passed to the software in the form of an environmental differentiation. Thus, it should be computed as a contrast to a reference (usually the average environment, but not obligatory), and as a distance. BayeScEnv only makes sure this latter point is satisfied by taking the absolute value of the environmental variable. It is also strongly advised to standardise the environmental values (i.e. dividing by the standard deviation) so that the extreme values never are much bigger than 2 or 3.\n",
      "\n",
      "Regarding the input format, a value for each population must be provided in a separate text file and in one row, so that the content of the file must look like (16 populations in this example):\n",
      "\n",
      " -0.639230879683183 -0.995733945140612 -0.263228407909816 0.478694676547254 1.35474025903925 1.85405875486584 0.837131353114318 0.104061927522223 -0.103841631873915 -0.760901719688793 -1.82819181353382 -1.33847104010839 -0.495277642473072 0.216938433143385 0.954037642263244 0.625214033916083\n",
      "\n",
      " \n",
      " this is what the related article says: \n",
      " \n",
      " Implementation of the statistical model\n",
      "Our method uses two types of data: (i) the allele counts a for each locus in each population sample, and (ii) observed values E of an environmental variable (one value per population), which are transformed into environmental differentiation using an appropriate function. We chose the absolute-value distance, because it allows to weigh down the effect of outlier (i.e. strongly differentiated) environmental values and, therefore, makes the method more conservative. Note that measuring an environmental distance requires to define a reference. The most natural reference would be the average of the environmental values, but this would not be always the case (see the example of adaptation to altitude in humans presented below). Also, it is strongly advised to standardise the environmental values by dividing by the standard deviation, in order to avoid effect size issues regarding the inference of the parameter g. As stated in the previous section, there are three alternative models:\n",
      "\n",
      "M1 Neutral model: Bj \n",
      "M2 Local adaptation model with environmental differentiation Ej : Bj + giEj \\\n",
      "M3 Locus-specific model: ai + Bj\n",
      "\n",
      "\n",
      "##########################################################\n",
      "\n",
      "REstandardizing the environmental variables for the Bayescenv program \n",
      "\n",
      "\n",
      "i also think that im going to rename the input files for each of the runs so that the resulting output files are all different names, and there isnt the risk of them getting over written. \n",
      "\n",
      "\n",
      "\t\t\t\tPC1_temp_precip\tPC2_temp_precip\tadjusted_X\t\tY\n",
      "all\t\tKushiro\t-3.218451422\t-0.516398134\t144.378062\t42.980725\n",
      "\t\tAmur\t1.689167829\t\t-1.473602978\t139.727554\t52.938669\n",
      "\t\tTauy\t3.889188789\t\t-0.049769325\t148.929489\t59.714924\n",
      "\t\tHaylyluya\t2.205190255\t0.100932262\t\t162.485706\t57.769904\n",
      "\t\tNome\t3.861457466\t\t0.374320184\t\t194.6983\t64.4836\n",
      "\t\tKoppen-3.471874259\t\t4.791198571\t\t214.1013\t60.7062\n",
      "\t\tSnohomish-4.954678659\t-3.226680581\t237.8189\t48.014461\n",
      "\t\t\t\t\t\n",
      "ASE/ASO\tKushiro\t-3.218451422\t-0.516398134\t144.378062\t42.980725\n",
      "\t\tAmur\t1.689167829\t\t-1.473602978\t139.727554\t52.938669\n",
      "\t\tTauy\t3.889188789\t\t-0.049769325\t148.929489\t59.714924\n",
      "\t\tHaylyluya\t2.205190255\t\t0.100932262\t162.485706\t57.769904\n",
      "\t\t\t\t\t\t\n",
      "NAE/ASO\tNome\t3.861457466\t\t0.374320184\t\t194.6983\t64.4836\n",
      "\t\tKoppen\t-3.471874259\t4.791198571\t\t214.1013\t60.7062\n",
      "\t\tSnohomish-4.954678659\t-3.226680581\t237.8189\t48.014461\n",
      "\t\t\t\t\t\n",
      "added this section to the code to get the standardized values\n",
      "\n",
      "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "#  O C T O B E R 3 0\n",
      "\n",
      "all_env <- read.table (\"G:/Analysis/Pop_analysis/Populations_b3_may/EnvData/RestandBayescenv/all.txt\", header = FALSE, sep = \"\\t\")\n",
      "all_env <- as.data.frame(all_env) \n",
      "colsall_env <- c(names(all_env))\n",
      "all_env.dat <- scale(all_env)\n",
      "all_env.dat\n",
      "write.table(all_env.dat, file = \"G:/Analysis/Pop_analysis/Populations_b3_may/EnvData/RestandBayescenv/all_stand.txt\", sep =\"\\t\", row.names = TRUE, col.names = TRUE)\n",
      "\n",
      "\n",
      "#########  S T A N D A R D I Z E  T H E  ASIA AND NA seperately\n",
      "\n",
      "AS_env <- read.table (\"G:/Analysis/Pop_analysis/Populations_b3_may/EnvData/RestandBayescenv/asial.txt\", header = FALSE, sep = \"\\t\")\n",
      "AS_env <- as.data.frame(AS_env) \n",
      "colsAS_env <- c(names(AS_env))\n",
      "AS_env.dat <- scale(AS_env)\n",
      "AS_env.dat\n",
      "write.table(AS_env.dat, file = \"G:/Analysis/Pop_analysis/Populations_b3_may/EnvData/RestandBayescenv/asial_stand.txt\", sep =\"\\t\", row.names = TRUE, col.names = TRUE)\n",
      "\n",
      "NA_env <- read.table (\"G:/Analysis/Pop_analysis/Populations_b3_may/EnvData/RestandBayescenv/NA.txt\", header = FALSE, sep = \"\\t\")\n",
      "NA_env <- as.data.frame(NA_env) \n",
      "colsNA_env <- c(names(NA_env))\n",
      "NA_env.dat <- scale(NA_env)\n",
      "NA_env.dat\n",
      "write.table(NA_env.dat, file = \"G:/Analysis/Pop_analysis/Populations_b3_may/EnvData/RestandBayescenv/NA_stand.txt\", sep =\"\\t\", row.names = TRUE, col.names = TRUE)\n",
      "\n",
      "Here are the results \n",
      "\n",
      "> all_env.dat\n",
      "             V1          V2         V3         V4\n",
      "[1,] -0.8565349 -0.21094173 -0.8616006 -1.6048275\n",
      "[2,]  0.4495426 -0.60194710 -0.9827627 -0.3001735\n",
      "[3,]  1.0350400 -0.02033010 -0.7430199  0.5876270\n",
      "[4,]  0.5868730  0.04122948 -0.3898328  0.3327975\n",
      "[5,]  1.0276598  0.15290479  0.4494187  1.2124017\n",
      "[6,] -0.9239790  1.95714052  0.9549352  0.7175004\n",
      "[7,] -1.3186016 -1.31805585  1.5728621 -0.9453255\n",
      "attr(,\"scaled:center\")\n",
      "           V1            V2            V3            V4 \n",
      "-1.428570e-10 -1.428572e-10  1.774485e+02  5.522978e+01 \n",
      "attr(,\"scaled:scale\")\n",
      "       V1        V2        V3        V4 \n",
      " 3.757525  2.448061 38.382529  7.632633 \n",
      "\n",
      "> AS_env.dat\n",
      "             V1          V2           V3          V4\n",
      "[1,] -1.4273011 -0.04465007 -0.458581253 -1.38687200\n",
      "[2,]  0.1793713 -1.39337731 -0.932274969 -0.05515034\n",
      "[3,]  0.8996214  0.61284240  0.005020223  0.85106941\n",
      "[4,]  0.3483084  0.82518497  1.385835998  0.59095293\n",
      "attr(,\"scaled:center\")\n",
      "         V1          V2          V3          V4 \n",
      "  1.1412739  -0.4847095 148.8802027  53.3510555 \n",
      "attr(,\"scaled:scale\")\n",
      "       V1        V2        V3        V4 \n",
      "3.0545238 0.7097097 9.8175421 7.4774965 \n",
      "\n",
      "> NA_env.dat\n",
      "             V1          V2          V3         V4\n",
      "[1,]  1.1403698 -0.06772142 -0.96503808  0.7822666\n",
      "[2,] -0.4131260  1.03213941 -0.06659491  0.3444238\n",
      "[3,] -0.7272438 -0.96441799  1.03163299 -1.1266904\n",
      "attr(,\"scaled:center\")\n",
      "         V1          V2          V3          V4 \n",
      " -1.5216985   0.6462794 215.5395000  57.7347537 \n",
      "attr(,\"scaled:scale\")\n",
      "       V1        V2        V3        V4 \n",
      " 4.720535  4.015852 21.596246  8.627297 \n",
      " \n",
      " \n",
      " i put the results in excel and then from each of the columns, or variables I added the absolute value of the largest negative value to get them to all be positive. so that the scale would start at zero. \n",
      " \n",
      " what order are the samples in in the input files? \n",
      " \n",
      " I think these are in a different order and i dont want to mess it up. this is the order of these environmental variables: \n",
      " \n",
      " \n",
      " all\tKushiro\n",
      "\t\tAmur\n",
      "\t\tTauy\n",
      "\t\tHaylyluya\n",
      "\t\tNome\n",
      "\t\tKoppen\n",
      "\t\tSnohomish\n",
      "\t\n",
      "ASE/ASO\tKushiro\n",
      "\t\tAmur\n",
      "\t\tTauy\n",
      "\t\tHaylyluya\n",
      "\t\n",
      "NAE/ASO\tNome\n",
      "\t\tKoppen\n",
      "\t\tSnohomish\n",
      "\n",
      " \n",
      "OK so i put them into the file that I used to make the input files the time before and i made the input files for all the samples, the asia and the north america, and within each of those categories i had the four differnt types of environmental data, the LA LO and the two PC axies for the P and T. SO those were all calculated with all the samples, they are not individual. I have those calculations, but i dont want to run those this weekend. \n",
      "\n",
      ".\\bayescenv.exe 16681_bayescenv_LA.txt -env  ALL_LA_All_POS.txt -out 16681_bayescenv_LA_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >16681_bayescenv_LA_log.txt 2>&1\n",
      ".\\bayescenv.exe 16681_bayescenv_LO.txt -env  ALL_LO_All_POS.txt -out 16681_bayescenv_LO_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >16681_bayescenv_LO_log.txt 2>&1\n",
      ".\\bayescenv.exe 16681_bayescenv_PT1.txt -env  ALL_PT1_All_POS.txt -out 16681_bayescenv_PT1_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >16681_bayescenv_PT1_log.txt 2>&1\n",
      ".\\bayescenv.exe 16681_bayescenv_PT2.txt -env  ALL_PT2_All_POS.txt -out 16681_bayescenv_PT2_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >16681_bayescenv_PT2_log.txt 2>&1\n",
      "\n",
      ".\\bayescenv.exe ASE_bayescenv_LA.txt -env  AS_LA_All_POS.txt -out ASE_bayescenv_LA_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASE_bayescenv_LA_log.txt 2>&1\n",
      ".\\bayescenv.exe ASE_bayescenv_LO.txt -env  AS_LO_All_POS.txt -out ASE_bayescenv_LO_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASE_bayescenv_LO_log.txt 2>&1\n",
      ".\\bayescenv.exe ASE_bayescenv_PT1.txt -env  AS_PT1_All_POS.txt -out ASE_bayescenv_PT1_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASE_bayescenv_PT1_log.txt 2>&1\n",
      ".\\bayescenv.exe ASE_bayescenv_PT2.txt -env  AS_PT2_All_POS.txt -out ASE_bayescenv_PT2_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASE_bayescenv_PT2_log.txt 2>&1\n",
      "\n",
      ".\\bayescenv.exe ASO_bayescenv_LA.txt -env  AS_LA_All_POS.txt -out ASO_bayescenv_LA_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASO_bayescenv_LA_log.txt 2>&1\n",
      ".\\bayescenv.exe ASO_bayescenv_LO.txt -env  AS_LO_All_POS.txt -out ASO_bayescenv_LO_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASO_bayescenv_LO_log.txt 2>&1\n",
      ".\\bayescenv.exe ASO_bayescenv_PT1.txt -env  AS_PT1_All_POS.txt -out ASO_bayescenv_PT1_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASO_bayescenv_PT1_log.txt 2>&1\n",
      ".\\bayescenv.exe ASO_bayescenv_PT2.txt -env  AS_PT2_All_POS.txt -out ASO_bayescenv_PT2_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >ASO_bayescenv_PT2_log.txt 2>&1\n",
      "\n",
      ".\\bayescenv.exe NAE_bayescenv_LA.txt -env  NA_LA_All_POS.txt -out NAE_bayescenv_LA_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAE_bayescenv_LA_log.txt 2>&1\n",
      ".\\bayescenv.exe NAE_bayescenv_LO.txt -env  NA_LO_All_POS.txt -out NAE_bayescenv_LO_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAE_bayescenv_LO_log.txt 2>&1\n",
      ".\\bayescenv.exe NAE_bayescenv_PT1.txt -env  NA_PT1_All_POS.txt -out NAE_bayescenv_PT1_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAE_bayescenv_PT1_log.txt 2>&1\n",
      ".\\bayescenv.exe NAE_bayescenv_PT2.txt -env  NA_PT2_All_POS.txt -out NAE_bayescenv_PT2_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAE_bayescenv_PT2_log.txt 2>&1\n",
      "\n",
      ".\\bayescenv.exe NAO_bayescenv_LA.txt -env  NA_LA_All_POS.txt -out NAO_bayescenv_LA_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAO_bayescenv_LA_log.txt 2>&1\n",
      ".\\bayescenv.exe NAO_bayescenv_LO.txt -env  NA_LO_All_POS.txt -out NAO_bayescenv_LO_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAO_bayescenv_LO_log.txt 2>&1\n",
      ".\\bayescenv.exe NAO_bayescenv_PT1.txt -env  NA_PT1_All_POS.txt -out NAO_bayescenv_PT1_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAO_bayescenv_PT1_log.txt 2>&1\n",
      ".\\bayescenv.exe NAO_bayescenv_PT2.txt -env  NA_PT2_All_POS.txt -out NAO_bayescenv_PT2_out.txt -n 5000 -thin 10 -nbp 20 -pilot 5000 -burn 50000 >NAO_bayescenv_PT2_log.txt 2>&1\n",
      "\n",
      "\n",
      "Im going over and run them now. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}